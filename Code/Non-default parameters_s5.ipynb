{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tsfresh\n",
    "import os\n",
    "import json\n",
    "import scapy\n",
    "import numpy as np\n",
    "import warnings\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from scapy.all import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") #ignore warnings caused by \n",
    "\n",
    "\n",
    "#################################################################\n",
    "#                                                               #\n",
    "#               malicious csv files import                      #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "\n",
    "df1 = pd.read_csv('../Data/malicious/WebOS_binary.csv') #\n",
    "df2 = pd.read_csv('../Data/malicious/Server_Binary.csv') #\n",
    "df3 = pd.read_csv('../Data/malicious/Raspberry_Webmine_Robust.csv')\n",
    "df4 = pd.read_csv('../Data/malicious/Raspberry_Binary.csv') #\n",
    "df5 = pd.read_csv('../Data/malicious/Raspberry_Webmine_Aggressive.csv')\n",
    "df6 = pd.read_csv('../Data/malicious/Raspberry_WebminePool_Aggressive.csv')\n",
    "df7 = pd.read_csv('../Data/malicious/Server_WebminePool_Aggressive.csv') #\n",
    "df32 = pd.read_csv('../Data/malicious/Server_WebminePool_Robust.csv') #\n",
    "df33 = pd.read_csv('../Data/malicious/Raspberry_WebminePool_Stealthy.csv') #\n",
    "df34 = pd.read_csv('../Data/malicious/Raspberry_WebminePool_Robust.csv') #\n",
    "df35 = pd.read_csv('../Data/malicious/Desktop_WebminePool_Aggressive.csv') #\n",
    "\n",
    "\n",
    "#################################################################\n",
    "#                                                               #\n",
    "#               benign-1 csv files import                         #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "df8 = pd.read_csv('../Data/benign-1/interactive_01.csv') #\n",
    "df9 = pd.read_csv('../Data/benign-1/interactive_02.csv') #\n",
    "df10 = pd.read_csv('../Data/benign-1/interactive_03.csv') #\n",
    "df11 = pd.read_csv('../Data/benign-1/interactive_04.csv') #\n",
    "df12 = pd.read_csv('../Data/benign-1/interactive_05.csv') #\n",
    "df13 = pd.read_csv('../Data/benign-1/interactive_06.csv') #\n",
    "df14 = pd.read_csv('../Data/benign-1/web_1page_01.csv') #\n",
    "df15 = pd.read_csv('../Data/benign-1/web_1page_02.csv') #\n",
    "df16 = pd.read_csv('../Data/benign-1/web_1page_03.csv') #\n",
    "df17 = pd.read_csv('../Data/benign-1/web_1page_04.csv') #\n",
    "df18 = pd.read_csv('../Data/benign-1/web_1page_05.csv') #\n",
    "df19 = pd.read_csv('../Data/benign-1/bulk_xs_04.csv') #\n",
    "df20 = pd.read_csv('../Data/benign-1/bulk_xs_05.csv') #\n",
    "df21 = pd.read_csv('../Data/benign-1/video_180s480p_01.csv') #\n",
    "df22 = pd.read_csv('../Data/benign-1/video_180s480p_02.csv') #\n",
    "df23 = pd.read_csv('../Data/benign-1/video_x1_04.csv') #\n",
    "df24 = pd.read_csv('../Data/benign-1/web_multiple_04.csv') #\n",
    "df25 = pd.read_csv('../Data/benign-1/bulk_xs_01.csv') #\n",
    "df26 = pd.read_csv('../Data/benign-1/bulk_xs_09.csv') #\n",
    "df27 = pd.read_csv('../Data/benign-1/bulk_xs_06.csv') #\n",
    "df28 = pd.read_csv('../Data/benign-1/bulk_xs_03.csv') #\n",
    "df29 = pd.read_csv('../Data/benign-1/web_multiple_03.csv') #\n",
    "df30 = pd.read_csv('../Data/benign-1/web_multiple_05.csv') #\n",
    "df31 = pd.read_csv('../Data/benign-1/web_multiple_06.csv') #\n",
    "\n",
    "df_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 -->> 43173\n",
      "df2 -->> 1213354\n",
      "df3 -->> 3621\n",
      "df4 -->> 22111\n",
      "df5 -->> 14156\n",
      "df6 -->> 24476\n",
      "df7 -->> 3106\n",
      "df32 -->> 18460\n",
      "df33 -->> 10285\n",
      "df34 -->> 7708\n",
      "df35 -->> 234892\n",
      "/////////////////////////////////////////////////\n",
      "df8 -->> 4550\n",
      "df9 -->> 3869\n",
      "df10 -->> 5327\n",
      "df11 -->> 4727\n",
      "df12 -->> 4190\n",
      "df13 -->> 3481\n",
      "df14 -->> 38576\n",
      "df15 -->> 5961\n",
      "df16 -->> 1803\n",
      "df17 -->> 7029\n",
      "df18 -->> 1012\n",
      "df19 -->> 96545\n",
      "df20 -->> 108065\n",
      "df21 -->> 25138\n",
      "df22 -->> 91274\n",
      "df23 -->> 23597\n",
      "df24 -->> 59635\n",
      "df25 -->> 625216\n",
      "df26 -->> 266935\n",
      "df27 -->> 453471\n",
      "df28 -->> 654495\n",
      "df29 -->> 6764\n",
      "df30 -->> 25300\n",
      "df31 -->> 3689\n"
     ]
    }
   ],
   "source": [
    "print(\"df1 -->> {}\".format(len(df1)))\n",
    "print(\"df2 -->> {}\".format(len(df2)))\n",
    "print(\"df3 -->> {}\".format(len(df3)))\n",
    "print(\"df4 -->> {}\".format(len(df4)))\n",
    "print(\"df5 -->> {}\".format(len(df5)))\n",
    "print(\"df6 -->> {}\".format(len(df6)))\n",
    "print(\"df7 -->> {}\".format(len(df7)))\n",
    "print(\"df32 -->> {}\".format(len(df32)))\n",
    "print(\"df33 -->> {}\".format(len(df33)))\n",
    "print(\"df34 -->> {}\".format(len(df34)))\n",
    "print(\"df35 -->> {}\".format(len(df35)))\n",
    "print(\"/////////////////////////////////////////////////\")\n",
    "\n",
    "\n",
    "print(\"df8 -->> {}\".format(len(df8)))\n",
    "print(\"df9 -->> {}\".format(len(df9)))\n",
    "print(\"df10 -->> {}\".format(len(df10)))\n",
    "print(\"df11 -->> {}\".format(len(df11)))\n",
    "print(\"df12 -->> {}\".format(len(df12)))\n",
    "print(\"df13 -->> {}\".format(len(df13)))\n",
    "print(\"df14 -->> {}\".format(len(df14)))\n",
    "print(\"df15 -->> {}\".format(len(df15)))\n",
    "print(\"df16 -->> {}\".format(len(df16)))\n",
    "print(\"df17 -->> {}\".format(len(df17)))\n",
    "print(\"df18 -->> {}\".format(len(df18)))\n",
    "print(\"df19 -->> {}\".format(len(df19)))\n",
    "print(\"df20 -->> {}\".format(len(df20)))\n",
    "print(\"df21 -->> {}\".format(len(df21)))\n",
    "print(\"df22 -->> {}\".format(len(df22)))\n",
    "print(\"df23 -->> {}\".format(len(df23)))\n",
    "print(\"df24 -->> {}\".format(len(df24)))\n",
    "print(\"df25 -->> {}\".format(len(df25)))\n",
    "print(\"df26 -->> {}\".format(len(df26)))\n",
    "print(\"df27 -->> {}\".format(len(df27)))\n",
    "print(\"df28 -->> {}\".format(len(df28)))\n",
    "print(\"df29 -->> {}\".format(len(df29)))\n",
    "print(\"df30 -->> {}\".format(len(df30)))\n",
    "print(\"df31 -->> {}\".format(len(df31)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#                                                               #\n",
    "#                     Filtering                                 #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "# For WebOS = 18:56:80:17:d0:ef\n",
    "index_names = df1[((df1['HW_dst'] != '18:56:80:17:d0:ef') & (df1['Hw_src'] != '18:56:80:17:d0:ef'))].index\n",
    "df1.drop(index_names, inplace = True)\n",
    "\n",
    "# Big_Server_Monero_mining_data = a4:bb:6d:ac:e1:fd\n",
    "\n",
    "index_names = df2[((df2['HW_dst'] != 'a4:bb:6d:ac:e1:fd') & (df2['Hw_src'] != 'a4:bb:6d:ac:e1:fd'))].index\n",
    "df2.drop(index_names, inplace = True)\n",
    "\n",
    "# ege_data_rasberry = dc:a6:32:67:66:4b\t\n",
    "\n",
    "index_names = df3[((df3['HW_dst'] != 'dc:a6:32:67:66:4b') & (df3['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df3.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_binary_monero_mining = dc:a6:32:68:35:8a\n",
    "\n",
    "index_names = df4[((df4['HW_dst'] != 'dc:a6:32:68:35:8a') & (df4['Hw_src'] != 'dc:a6:32:68:35:8a'))].index\n",
    "df4.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_network_data_2 = dc:a6:32:67:66:4b\n",
    "\n",
    "index_names = df5[((df5['HW_dst'] != 'dc:a6:32:67:66:4b') & (df5['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df5.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry-Webmine = dc:a6:32:67:66:4b\n",
    "index_names = df6[((df6['HW_dst'] != 'dc:a6:32:67:66:4b') & (df6['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df6.drop(index_names, inplace = True)\n",
    "\n",
    "# Server_Webmine_Network_data = a4:bb:6d:ac:e1:fd\n",
    "\n",
    "index_names = df7[((df7['HW_dst'] != 'a4:bb:6d:ac:e1:fd') & (df7['Hw_src'] != 'a4:bb:6d:ac:e1:fd'))].index\n",
    "df7.drop(index_names, inplace = True)\n",
    "\n",
    "# Server_%50_Mining = a4:bb:6d:ac:e1:fd\n",
    "\n",
    "index_names = df32[((df32['HW_dst'] != 'a4:bb:6d:ac:e1:fd') & (df32['Hw_src'] != 'a4:bb:6d:ac:e1:fd'))].index\n",
    "df32.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_webmine_%10 = dc:a6:32:67:66:4b\n",
    "\n",
    "index_names = df33[((df33['HW_dst'] != 'dc:a6:32:67:66:4b') & (df33['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df33.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_webmine_%50 = dc:a6:32:68:35:8a\n",
    "\n",
    "index_names = df34[((df34['HW_dst'] != 'dc:a6:32:68:35:8a') & (df34['Hw_src'] != 'dc:a6:32:68:35:8a'))].index\n",
    "df34.drop(index_names, inplace = True)\n",
    "\n",
    "# Desktop_Webmine_%100 = dc:a6:32:68:35:8a\n",
    "\n",
    "index_names = df35[((df35['HW_dst'] != 'd8:3b:bf:8f:ba:ba') & (df35['Hw_src'] != 'd8:3b:bf:8f:ba:ba'))].index\n",
    "df35.drop(index_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#                                                               #\n",
    "#      Labeling Features for further calculations               #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "df1.insert(7, \"Is_malicious\", 1)\n",
    "df2.insert(7, \"Is_malicious\", 1)\n",
    "df3.insert(7, \"Is_malicious\", 1)\n",
    "df4.insert(7, \"Is_malicious\", 1)\n",
    "df5.insert(7, \"Is_malicious\", 1)\n",
    "df6.insert(7, \"Is_malicious\", 1)\n",
    "df7.insert(7, \"Is_malicious\", 1)\n",
    "\n",
    "# ========================================================\n",
    "\n",
    "df8.insert(7, \"Is_malicious\", 0)\n",
    "df9.insert(7, \"Is_malicious\", 0)\n",
    "df10.insert(7, \"Is_malicious\", 0)\n",
    "df11.insert(7, \"Is_malicious\", 0)\n",
    "df12.insert(7, \"Is_malicious\", 0)\n",
    "df13.insert(7, \"Is_malicious\", 0)\n",
    "df14.insert(7, \"Is_malicious\", 0)\n",
    "df15.insert(7, \"Is_malicious\", 0)\n",
    "df16.insert(7, \"Is_malicious\", 0)\n",
    "df17.insert(7, \"Is_malicious\", 0)\n",
    "df18.insert(7, \"Is_malicious\", 0)\n",
    "df19.insert(7, \"Is_malicious\", 0)\n",
    "df20.insert(7, \"Is_malicious\", 0)\n",
    "df21.insert(7, \"Is_malicious\", 0)\n",
    "df22.insert(7, \"Is_malicious\", 0)\n",
    "df23.insert(7, \"Is_malicious\", 0)\n",
    "df24.insert(7, \"Is_malicious\", 0)\n",
    "\n",
    "\n",
    "# ========================================================\n",
    "\n",
    "df25.insert(7, \"Is_malicious\", 0)\n",
    "df26.insert(7, \"Is_malicious\", 0)\n",
    "df27.insert(7, \"Is_malicious\", 0)\n",
    "df28.insert(7, \"Is_malicious\", 0)\n",
    "df29.insert(7, \"Is_malicious\", 0)\n",
    "df30.insert(7, \"Is_malicious\", 0)\n",
    "df31.insert(7, \"Is_malicious\", 0)\n",
    "\n",
    "df32.insert(7, \"Is_malicious\", 1)\n",
    "df33.insert(7, \"Is_malicious\", 1)\n",
    "df34.insert(7, \"Is_malicious\", 1)\n",
    "df35.insert(7, \"Is_malicious\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 -->> 41572\n",
      "df2 -->> 1198039\n",
      "df3 -->> 3519\n",
      "df4 -->> 11745\n",
      "df5 -->> 12871\n",
      "df6 -->> 19643\n",
      "df7 -->> 2539\n",
      "df8 -->> 4550\n",
      "df9 -->> 3869\n",
      "df10 -->> 5327\n",
      "df11 -->> 4727\n",
      "df12 -->> 4190\n",
      "df13 -->> 3481\n",
      "df14 -->> 38576\n",
      "df15 -->> 5961\n",
      "df16 -->> 1803\n",
      "df17 -->> 7029\n",
      "df18 -->> 1012\n",
      "df19 -->> 96545\n",
      "df20 -->> 108065\n",
      "df21 -->> 25138\n",
      "df22 -->> 91274\n",
      "df23 -->> 23597\n",
      "df24 -->> 59619\n",
      "df25 -->> 625194\n",
      "df26 -->> 266935\n",
      "df27 -->> 453466\n",
      "df28 -->> 654479\n",
      "df29 -->> 6764\n",
      "df30 -->> 25288\n",
      "df31 -->> 3689\n",
      "df32 -->> 16744\n",
      "df33 -->> 9880\n",
      "df34 -->> 6406\n",
      "df35 -->> 234272\n"
     ]
    }
   ],
   "source": [
    "print(\"df1 -->> {}\".format(len(df1.dropna())))\n",
    "print(\"df2 -->> {}\".format(len(df2.dropna())))\n",
    "print(\"df3 -->> {}\".format(len(df3.dropna())))\n",
    "print(\"df4 -->> {}\".format(len(df4.dropna())))\n",
    "print(\"df5 -->> {}\".format(len(df5.dropna())))\n",
    "print(\"df6 -->> {}\".format(len(df6.dropna())))\n",
    "print(\"df7 -->> {}\".format(len(df7.dropna())))\n",
    "print(\"df8 -->> {}\".format(len(df8.dropna())))\n",
    "print(\"df9 -->> {}\".format(len(df9.dropna())))\n",
    "print(\"df10 -->> {}\".format(len(df10.dropna())))\n",
    "print(\"df11 -->> {}\".format(len(df11.dropna())))\n",
    "print(\"df12 -->> {}\".format(len(df12.dropna())))\n",
    "print(\"df13 -->> {}\".format(len(df13.dropna())))\n",
    "print(\"df14 -->> {}\".format(len(df14.dropna())))\n",
    "print(\"df15 -->> {}\".format(len(df15.dropna())))\n",
    "print(\"df16 -->> {}\".format(len(df16.dropna())))\n",
    "print(\"df17 -->> {}\".format(len(df17.dropna())))\n",
    "print(\"df18 -->> {}\".format(len(df18.dropna())))\n",
    "print(\"df19 -->> {}\".format(len(df19.dropna())))\n",
    "print(\"df20 -->> {}\".format(len(df20.dropna())))\n",
    "print(\"df21 -->> {}\".format(len(df21.dropna())))\n",
    "print(\"df22 -->> {}\".format(len(df22.dropna())))\n",
    "print(\"df23 -->> {}\".format(len(df23.dropna())))\n",
    "print(\"df24 -->> {}\".format(len(df24.dropna())))\n",
    "print(\"df25 -->> {}\".format(len(df25.dropna())))\n",
    "print(\"df26 -->> {}\".format(len(df26.dropna())))\n",
    "print(\"df27 -->> {}\".format(len(df27.dropna())))\n",
    "print(\"df28 -->> {}\".format(len(df28.dropna())))\n",
    "print(\"df29 -->> {}\".format(len(df29.dropna())))\n",
    "print(\"df30 -->> {}\".format(len(df30.dropna())))\n",
    "print(\"df31 -->> {}\".format(len(df31.dropna())))\n",
    "print(\"df32 -->> {}\".format(len(df32.dropna())))\n",
    "print(\"df33 -->> {}\".format(len(df33.dropna())))\n",
    "print(\"df34 -->> {}\".format(len(df34.dropna())))\n",
    "print(\"df35 -->> {}\".format(len(df35.dropna())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_process(a,b,x):\n",
    "    \n",
    "    df_malicious = a.copy()\n",
    "    df_benign    = b.copy()\n",
    "    \n",
    "    from tsfresh import extract_features, select_features\n",
    "    from tsfresh.utilities.dataframe_functions import impute\n",
    "    from tsfresh import extract_features\n",
    "    from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "\n",
    "\n",
    "    df_malicious.reset_index(drop=True, inplace=True) #reset index\n",
    "    df_malicious['id']= np.floor(df_malicious.index.array/10)\n",
    "    df_benign.reset_index(drop=True, inplace=True) #reset index\n",
    "    df_benign['id']= np.floor(df_benign.index.array/10)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    tf1=tsfresh.extract_features(df_malicious,impute_function=impute, column_kind='Is_malicious',\n",
    "                                 column_id='id',column_sort=\"Time\",column_value = \"Length\")\n",
    "    tf1['class']= 1\n",
    "\n",
    "    \n",
    "    \n",
    "    tf2=tsfresh.extract_features(df_benign,impute_function=impute, column_kind='Is_malicious',\n",
    "                                 column_id='id',column_sort=\"Time\",column_value = \"Length\")\n",
    "    tf2['class']= 0\n",
    "\n",
    "\n",
    "    tf2.columns = tf1.columns\n",
    "\n",
    "    features=pd.concat([tf1,tf2])\n",
    "\n",
    "\n",
    "    features2 = features.copy()\n",
    "    features2.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    y = pd.Series(data = features2['class'], index=features2.index)\n",
    "    \n",
    "    from tsfresh.examples import load_robot_execution_failures\n",
    "    from tsfresh import extract_features, select_features\n",
    "    from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "\n",
    "    relevance_table = calculate_relevance_table(features2, y)\n",
    "    relevance_table = relevance_table[relevance_table.relevant]\n",
    "    relevance_table.sort_values(\"p_value\", inplace=True)\n",
    "\n",
    "    relevance_table\n",
    "    \n",
    "    best_features = relevance_table[relevance_table['p_value'] <= 0.05]\n",
    "\n",
    "    df_ML = pd.DataFrame()\n",
    "\n",
    "    for pkt in best_features:\n",
    "        df_ML[best_features.feature] = features[best_features.feature]\n",
    "\n",
    "    final = ML_Process(df_ML,x)\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_Process(df_ML,x):\n",
    "    df_results = x.copy() \n",
    "    print('let the ml starts')\n",
    "  \n",
    "    from sklearn import neighbors, metrics\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    #X = df_finalized[['Time', 'Length','Protocol']].values\n",
    "    X = df_ML.drop('class',axis=1).to_numpy()\n",
    "    #y = df_finalized[['Is_malicious']]\n",
    "    y = df_ML['class'].to_numpy()\n",
    "\n",
    "\n",
    "    #print(X,y)\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    Le = LabelEncoder()\n",
    "    for i in range(len(X[0])):\n",
    "        X[:, i] = Le.fit_transform(X[:, i])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=8675309)\n",
    "\n",
    "    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    #from xgboost import XGBClassifier\n",
    "    from sklearn import model_selection\n",
    "    from sklearn.utils import class_weight\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    y_train = y_train.ravel()\n",
    "    dfs = []\n",
    "    models = [\n",
    "        ('SVM-linear-scale-1', SVC(C = 1, kernel = 'linear',gamma ='scale')),\n",
    "        ('SVM-poly-scale-1', SVC(C = 1, kernel = 'poly',gamma ='scale')),\n",
    "        ('SVM-rbf-scale-1', SVC(C = 1, kernel = 'rbf',gamma ='scale')),\n",
    "        ('SVM-sigmoid-scale-1', SVC(C = 1, kernel = 'sigmoid',gamma ='scale')),\n",
    "        ('SVM-linear-auto-1', SVC(C = 1, kernel = 'linear',gamma ='auto')),\n",
    "        ('SVM-poly-auto-1', SVC(C = 1, kernel = 'poly',gamma ='auto')),\n",
    "        ('SVM-rbf-auto-1', SVC(C = 1, kernel = 'rbf',gamma ='auto')),\n",
    "        ('SVM-sigmoid-auto-1', SVC(C = 1, kernel = 'sigmoid',gamma ='auto')),\n",
    "        ('SVM-linear-scale-2', SVC(C = 2, kernel = 'linear',gamma ='scale')),\n",
    "        ('SVM-poly-scale-2', SVC(C = 2, kernel = 'poly',gamma ='scale')),\n",
    "        ('SVM-rbf-scale-2', SVC(C = 2, kernel = 'rbf',gamma ='scale')),\n",
    "        ('SVM-sigmoid-scale-2', SVC(C = 2, kernel = 'sigmoid',gamma ='scale')),\n",
    "        ('SVM-linear-auto-2', SVC(C = 2, kernel = 'linear',gamma ='auto')),\n",
    "        ('SVM-poly-auto-2', SVC(C = 2, kernel = 'poly',gamma ='auto')),\n",
    "        ('SVM-rbf-auto-2', SVC(C = 2, kernel = 'rbf',gamma ='auto')),\n",
    "        ('SVM-sigmoid-auto-2', SVC(C = 2, kernel = 'sigmoid',gamma ='auto'))\n",
    "            ]\n",
    "    results = []\n",
    "    names = []\n",
    "    scoring = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted', 'roc_auc']\n",
    "    target_names = ['malignant', 'benign']\n",
    "    for name, model in models:\n",
    "        kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state=90210)\n",
    "        cv_results = model_selection.cross_validate(model, X_train, y_train, cv=kfold, \n",
    "                                                    scoring=scoring)\n",
    "\n",
    "        clf = model.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(name)\n",
    "        print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        this_df = pd.DataFrame(cv_results)\n",
    "        this_df['model'] = name\n",
    "        dfs.append(this_df)\n",
    "        final = pd.concat(dfs, ignore_index=True)\n",
    "        print(final)\n",
    "\n",
    "    return(final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 247143\n",
      "benign: 246001\n",
      "0 NAN in malicious!\n",
      "0 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 247143\n",
      "benign: 246001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 160/160 [00:37<00:00,  4.24it/s]\n",
      "Feature Extraction: 100%|█████████████████████| 160/160 [00:38<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let the ml starts\n",
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.97      0.98      0.98      6074\n",
      "      benign       0.98      0.97      0.98      6255\n",
      "\n",
      "    accuracy                           0.98     12329\n",
      "   macro avg       0.98      0.98      0.98     12329\n",
      "weighted avg       0.98      0.98      0.98     12329\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  1.083015    0.025859       0.973506                 0.973511   \n",
      "1  0.946127    0.023898       0.979995                 0.979995   \n",
      "2  1.000458    0.022815       0.976612                 0.976629   \n",
      "3  1.068167    0.022077       0.977694                 0.977694   \n",
      "4  0.943920    0.024133       0.978099                 0.978101   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.973506          0.973506      0.996737  LogReg  \n",
      "1              0.979995          0.979995      0.997823  LogReg  \n",
      "2              0.976612          0.976613      0.997288  LogReg  \n",
      "3              0.977694          0.977694      0.997514  LogReg  \n",
      "4              0.978099          0.978099      0.997517  LogReg  \n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.97      0.97      0.97      6074\n",
      "      benign       0.97      0.97      0.97      6255\n",
      "\n",
      "    accuracy                           0.97     12329\n",
      "   macro avg       0.97      0.97      0.97     12329\n",
      "weighted avg       0.97      0.97      0.97     12329\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  1.083015    0.025859       0.973506                 0.973511   \n",
      "1  0.946127    0.023898       0.979995                 0.979995   \n",
      "2  1.000458    0.022815       0.976612                 0.976629   \n",
      "3  1.068167    0.022077       0.977694                 0.977694   \n",
      "4  0.943920    0.024133       0.978099                 0.978101   \n",
      "5  0.043693    9.521030       0.967288                 0.967297   \n",
      "6  0.044969    9.578156       0.969181                 0.969181   \n",
      "7  0.034971    9.559942       0.970393                 0.970396   \n",
      "8  0.047522    9.329350       0.972286                 0.972288   \n",
      "9  0.036972    9.746725       0.969312                 0.969313   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.973506          0.973506      0.996737  LogReg  \n",
      "1              0.979995          0.979995      0.997823  LogReg  \n",
      "2              0.976612          0.976613      0.997288  LogReg  \n",
      "3              0.977694          0.977694      0.997514  LogReg  \n",
      "4              0.978099          0.978099      0.997517  LogReg  \n",
      "5              0.967288          0.967288      0.990634     KNN  \n",
      "6              0.969181          0.969181      0.990803     KNN  \n",
      "7              0.970393          0.970394      0.992727     KNN  \n",
      "8              0.972286          0.972286      0.992656     KNN  \n",
      "9              0.969312          0.969311      0.991639     KNN  \n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.98      0.98      6074\n",
      "      benign       0.99      0.98      0.98      6255\n",
      "\n",
      "    accuracy                           0.98     12329\n",
      "   macro avg       0.98      0.98      0.98     12329\n",
      "weighted avg       0.98      0.98      0.98     12329\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0    1.083015    0.025859       0.973506                 0.973511   \n",
      "1    0.946127    0.023898       0.979995                 0.979995   \n",
      "2    1.000458    0.022815       0.976612                 0.976629   \n",
      "3    1.068167    0.022077       0.977694                 0.977694   \n",
      "4    0.943920    0.024133       0.978099                 0.978101   \n",
      "5    0.043693    9.521030       0.967288                 0.967297   \n",
      "6    0.044969    9.578156       0.969181                 0.969181   \n",
      "7    0.034971    9.559942       0.970393                 0.970396   \n",
      "8    0.047522    9.329350       0.972286                 0.972288   \n",
      "9    0.036972    9.746725       0.969312                 0.969313   \n",
      "10  22.245659   10.879345       0.977697                 0.977701   \n",
      "11  22.270937   10.921839       0.980806                 0.980806   \n",
      "12  21.959669   10.907224       0.981209                 0.981229   \n",
      "13  22.300447   10.912856       0.981885                 0.981890   \n",
      "14  22.395262   10.926249       0.981344                 0.981344   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.973506          0.973506      0.996737  LogReg  \n",
      "1               0.979995          0.979995      0.997823  LogReg  \n",
      "2               0.976612          0.976613      0.997288  LogReg  \n",
      "3               0.977694          0.977694      0.997514  LogReg  \n",
      "4               0.978099          0.978099      0.997517  LogReg  \n",
      "5               0.967288          0.967288      0.990634     KNN  \n",
      "6               0.969181          0.969181      0.990803     KNN  \n",
      "7               0.970393          0.970394      0.992727     KNN  \n",
      "8               0.972286          0.972286      0.992656     KNN  \n",
      "9               0.969312          0.969311      0.991639     KNN  \n",
      "10              0.977697          0.977697      0.996433     SVM  \n",
      "11              0.980806          0.980806      0.997480     SVM  \n",
      "12              0.981209          0.981209      0.997349     SVM  \n",
      "13              0.981885          0.981885      0.997415     SVM  \n",
      "14              0.981344          0.981344      0.997225     SVM  \n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      1.00      1.00      6074\n",
      "      benign       1.00      1.00      1.00      6255\n",
      "\n",
      "    accuracy                           1.00     12329\n",
      "   macro avg       1.00      1.00      1.00     12329\n",
      "weighted avg       1.00      1.00      1.00     12329\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0    1.083015    0.025859       0.973506                 0.973511   \n",
      "1    0.946127    0.023898       0.979995                 0.979995   \n",
      "2    1.000458    0.022815       0.976612                 0.976629   \n",
      "3    1.068167    0.022077       0.977694                 0.977694   \n",
      "4    0.943920    0.024133       0.978099                 0.978101   \n",
      "5    0.043693    9.521030       0.967288                 0.967297   \n",
      "6    0.044969    9.578156       0.969181                 0.969181   \n",
      "7    0.034971    9.559942       0.970393                 0.970396   \n",
      "8    0.047522    9.329350       0.972286                 0.972288   \n",
      "9    0.036972    9.746725       0.969312                 0.969313   \n",
      "10  22.245659   10.879345       0.977697                 0.977701   \n",
      "11  22.270937   10.921839       0.980806                 0.980806   \n",
      "12  21.959669   10.907224       0.981209                 0.981229   \n",
      "13  22.300447   10.912856       0.981885                 0.981890   \n",
      "14  22.395262   10.926249       0.981344                 0.981344   \n",
      "15   0.141468    0.050237       0.999594                 0.999595   \n",
      "16   0.127383    0.044898       0.999865                 0.999865   \n",
      "17   0.126644    0.048108       0.999594                 0.999595   \n",
      "18   0.126853    0.044586       0.999594                 0.999595   \n",
      "19   0.126793    0.043990       0.999865                 0.999865   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.973506          0.973506      0.996737  LogReg  \n",
      "1               0.979995          0.979995      0.997823  LogReg  \n",
      "2               0.976612          0.976613      0.997288  LogReg  \n",
      "3               0.977694          0.977694      0.997514  LogReg  \n",
      "4               0.978099          0.978099      0.997517  LogReg  \n",
      "5               0.967288          0.967288      0.990634     KNN  \n",
      "6               0.969181          0.969181      0.990803     KNN  \n",
      "7               0.970393          0.970394      0.992727     KNN  \n",
      "8               0.972286          0.972286      0.992656     KNN  \n",
      "9               0.969312          0.969311      0.991639     KNN  \n",
      "10              0.977697          0.977697      0.996433     SVM  \n",
      "11              0.980806          0.980806      0.997480     SVM  \n",
      "12              0.981209          0.981209      0.997349     SVM  \n",
      "13              0.981885          0.981885      0.997415     SVM  \n",
      "14              0.981344          0.981344      0.997225     SVM  \n",
      "15              0.999594          0.999594      0.999594     GNB  \n",
      "16              0.999865          0.999865      0.999866     GNB  \n",
      "17              0.999594          0.999594      0.999600     GNB  \n",
      "18              0.999594          0.999594      0.999599     GNB  \n",
      "19              0.999865          0.999865      0.999862     GNB  \n",
      "435.41981793698505\n"
     ]
    }
   ],
   "source": [
    "## S5: Partially compromised (IoT + Laptop)\n",
    " \n",
    "df_malicious = pd.concat([df5,df35])\n",
    " \n",
    "df_benign = pd.concat([df14,df16,df18,df19,df20])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_all_combined_s0 = run_process(df_malicious,df_benign,df_results)\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 12871\n",
      "benign: 13746\n",
      "0 NAN in malicious!\n",
      "0 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 12871\n",
      "benign: 13746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 144/144 [00:02<00:00, 48.00it/s]\n",
      "Feature Extraction: 100%|█████████████████████| 153/153 [00:03<00:00, 50.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let the ml starts\n",
      "SVM-linear-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.96      0.93      0.95       363\n",
      "      benign       0.92      0.96      0.94       303\n",
      "\n",
      "    accuracy                           0.94       666\n",
      "   macro avg       0.94      0.94      0.94       666\n",
      "weighted avg       0.94      0.94      0.94       666\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  46.181343    0.011134       0.942500                 0.942484   \n",
      "1   6.304723    0.009347       0.942500                 0.942634   \n",
      "2  43.386375    0.010828       0.939850                 0.939862   \n",
      "3  25.759007    0.009978       0.944862                 0.944923   \n",
      "4  13.542591    0.008832       0.922306                 0.922311   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0              0.942500          0.942486      0.984359  SVM-linear-scale-1  \n",
      "1              0.942500          0.942514      0.979167  SVM-linear-scale-1  \n",
      "2              0.939850          0.939832      0.977198  SVM-linear-scale-1  \n",
      "3              0.944862          0.944796      0.970842  SVM-linear-scale-1  \n",
      "4              0.922306          0.922303      0.968136  SVM-linear-scale-1  \n",
      "SVM-poly-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.96      0.97       363\n",
      "      benign       0.95      0.98      0.96       303\n",
      "\n",
      "    accuracy                           0.97       666\n",
      "   macro avg       0.96      0.97      0.97       666\n",
      "weighted avg       0.97      0.97      0.97       666\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  46.181343    0.011134       0.942500                 0.942484   \n",
      "1   6.304723    0.009347       0.942500                 0.942634   \n",
      "2  43.386375    0.010828       0.939850                 0.939862   \n",
      "3  25.759007    0.009978       0.944862                 0.944923   \n",
      "4  13.542591    0.008832       0.922306                 0.922311   \n",
      "5   0.088870    0.022612       0.922500                 0.923278   \n",
      "6   0.088983    0.023686       0.930000                 0.930228   \n",
      "7   0.091771    0.022799       0.942356                 0.942411   \n",
      "8   0.090027    0.022798       0.949875                 0.949948   \n",
      "9   0.086144    0.021468       0.919799                 0.920150   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0              0.942500          0.942486      0.984359  SVM-linear-scale-1  \n",
      "1              0.942500          0.942514      0.979167  SVM-linear-scale-1  \n",
      "2              0.939850          0.939832      0.977198  SVM-linear-scale-1  \n",
      "3              0.944862          0.944796      0.970842  SVM-linear-scale-1  \n",
      "4              0.922306          0.922303      0.968136  SVM-linear-scale-1  \n",
      "5              0.922500          0.922606      0.981458    SVM-poly-scale-1  \n",
      "6              0.930000          0.930021      0.967698    SVM-poly-scale-1  \n",
      "7              0.942356          0.942330      0.986117    SVM-poly-scale-1  \n",
      "8              0.949875          0.949815      0.983807    SVM-poly-scale-1  \n",
      "9              0.919799          0.919766      0.959893    SVM-poly-scale-1  \n",
      "SVM-rbf-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.95      0.93      0.94       363\n",
      "      benign       0.92      0.94      0.93       303\n",
      "\n",
      "    accuracy                           0.94       666\n",
      "   macro avg       0.94      0.94      0.94       666\n",
      "weighted avg       0.94      0.94      0.94       666\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   46.181343    0.011134       0.942500                 0.942484   \n",
      "1    6.304723    0.009347       0.942500                 0.942634   \n",
      "2   43.386375    0.010828       0.939850                 0.939862   \n",
      "3   25.759007    0.009978       0.944862                 0.944923   \n",
      "4   13.542591    0.008832       0.922306                 0.922311   \n",
      "5    0.088870    0.022612       0.922500                 0.923278   \n",
      "6    0.088983    0.023686       0.930000                 0.930228   \n",
      "7    0.091771    0.022799       0.942356                 0.942411   \n",
      "8    0.090027    0.022798       0.949875                 0.949948   \n",
      "9    0.086144    0.021468       0.919799                 0.920150   \n",
      "10   0.095671    0.089227       0.917500                 0.917471   \n",
      "11   0.096820    0.084331       0.915000                 0.915000   \n",
      "12   0.101153    0.087032       0.924812                 0.924815   \n",
      "13   0.098781    0.087209       0.937343                 0.937546   \n",
      "14   0.093754    0.082441       0.899749                 0.899749   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               0.942500          0.942486      0.984359  SVM-linear-scale-1  \n",
      "1               0.942500          0.942514      0.979167  SVM-linear-scale-1  \n",
      "2               0.939850          0.939832      0.977198  SVM-linear-scale-1  \n",
      "3               0.944862          0.944796      0.970842  SVM-linear-scale-1  \n",
      "4               0.922306          0.922303      0.968136  SVM-linear-scale-1  \n",
      "5               0.922500          0.922606      0.981458    SVM-poly-scale-1  \n",
      "6               0.930000          0.930021      0.967698    SVM-poly-scale-1  \n",
      "7               0.942356          0.942330      0.986117    SVM-poly-scale-1  \n",
      "8               0.949875          0.949815      0.983807    SVM-poly-scale-1  \n",
      "9               0.919799          0.919766      0.959893    SVM-poly-scale-1  \n",
      "10              0.917500          0.917480      0.975378     SVM-rbf-scale-1  \n",
      "11              0.915000          0.915000      0.966772     SVM-rbf-scale-1  \n",
      "12              0.924812          0.924790      0.982212     SVM-rbf-scale-1  \n",
      "13              0.937343          0.937391      0.982816     SVM-rbf-scale-1  \n",
      "14              0.899749          0.899749      0.959868     SVM-rbf-scale-1  \n",
      "SVM-sigmoid-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.72      0.63      0.67       363\n",
      "      benign       0.61      0.71      0.66       303\n",
      "\n",
      "    accuracy                           0.66       666\n",
      "   macro avg       0.67      0.67      0.66       666\n",
      "weighted avg       0.67      0.66      0.66       666\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   46.181343    0.011134       0.942500                 0.942484   \n",
      "1    6.304723    0.009347       0.942500                 0.942634   \n",
      "2   43.386375    0.010828       0.939850                 0.939862   \n",
      "3   25.759007    0.009978       0.944862                 0.944923   \n",
      "4   13.542591    0.008832       0.922306                 0.922311   \n",
      "5    0.088870    0.022612       0.922500                 0.923278   \n",
      "6    0.088983    0.023686       0.930000                 0.930228   \n",
      "7    0.091771    0.022799       0.942356                 0.942411   \n",
      "8    0.090027    0.022798       0.949875                 0.949948   \n",
      "9    0.086144    0.021468       0.919799                 0.920150   \n",
      "10   0.095671    0.089227       0.917500                 0.917471   \n",
      "11   0.096820    0.084331       0.915000                 0.915000   \n",
      "12   0.101153    0.087032       0.924812                 0.924815   \n",
      "13   0.098781    0.087209       0.937343                 0.937546   \n",
      "14   0.093754    0.082441       0.899749                 0.899749   \n",
      "15   0.123241    0.054576       0.655000                 0.661889   \n",
      "16   0.125698    0.055018       0.682500                 0.682932   \n",
      "17   0.124899    0.054710       0.704261                 0.704029   \n",
      "18   0.120419    0.052448       0.649123                 0.660864   \n",
      "19   0.132873    0.056724       0.719298                 0.720137   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.942500          0.942486      0.984359   SVM-linear-scale-1  \n",
      "1               0.942500          0.942514      0.979167   SVM-linear-scale-1  \n",
      "2               0.939850          0.939832      0.977198   SVM-linear-scale-1  \n",
      "3               0.944862          0.944796      0.970842   SVM-linear-scale-1  \n",
      "4               0.922306          0.922303      0.968136   SVM-linear-scale-1  \n",
      "5               0.922500          0.922606      0.981458     SVM-poly-scale-1  \n",
      "6               0.930000          0.930021      0.967698     SVM-poly-scale-1  \n",
      "7               0.942356          0.942330      0.986117     SVM-poly-scale-1  \n",
      "8               0.949875          0.949815      0.983807     SVM-poly-scale-1  \n",
      "9               0.919799          0.919766      0.959893     SVM-poly-scale-1  \n",
      "10              0.917500          0.917480      0.975378      SVM-rbf-scale-1  \n",
      "11              0.915000          0.915000      0.966772      SVM-rbf-scale-1  \n",
      "12              0.924812          0.924790      0.982212      SVM-rbf-scale-1  \n",
      "13              0.937343          0.937391      0.982816      SVM-rbf-scale-1  \n",
      "14              0.899749          0.899749      0.959868      SVM-rbf-scale-1  \n",
      "15              0.655000          0.655673      0.739322  SVM-sigmoid-scale-1  \n",
      "16              0.682500          0.682609      0.781976  SVM-sigmoid-scale-1  \n",
      "17              0.704261          0.704074      0.783321  SVM-sigmoid-scale-1  \n",
      "18              0.649123          0.649678      0.772688  SVM-sigmoid-scale-1  \n",
      "19              0.719298          0.718828      0.773936  SVM-sigmoid-scale-1  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-linear-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.96      0.93      0.95       363\n",
      "      benign       0.92      0.96      0.94       303\n",
      "\n",
      "    accuracy                           0.94       666\n",
      "   macro avg       0.94      0.94      0.94       666\n",
      "weighted avg       0.94      0.94      0.94       666\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   46.181343    0.011134       0.942500                 0.942484   \n",
      "1    6.304723    0.009347       0.942500                 0.942634   \n",
      "2   43.386375    0.010828       0.939850                 0.939862   \n",
      "3   25.759007    0.009978       0.944862                 0.944923   \n",
      "4   13.542591    0.008832       0.922306                 0.922311   \n",
      "5    0.088870    0.022612       0.922500                 0.923278   \n",
      "6    0.088983    0.023686       0.930000                 0.930228   \n",
      "7    0.091771    0.022799       0.942356                 0.942411   \n",
      "8    0.090027    0.022798       0.949875                 0.949948   \n",
      "9    0.086144    0.021468       0.919799                 0.920150   \n",
      "10   0.095671    0.089227       0.917500                 0.917471   \n",
      "11   0.096820    0.084331       0.915000                 0.915000   \n",
      "12   0.101153    0.087032       0.924812                 0.924815   \n",
      "13   0.098781    0.087209       0.937343                 0.937546   \n",
      "14   0.093754    0.082441       0.899749                 0.899749   \n",
      "15   0.123241    0.054576       0.655000                 0.661889   \n",
      "16   0.125698    0.055018       0.682500                 0.682932   \n",
      "17   0.124899    0.054710       0.704261                 0.704029   \n",
      "18   0.120419    0.052448       0.649123                 0.660864   \n",
      "19   0.132873    0.056724       0.719298                 0.720137   \n",
      "20  45.977869    0.010632       0.942500                 0.942484   \n",
      "21   6.266010    0.008849       0.942500                 0.942634   \n",
      "22  43.089100    0.010611       0.939850                 0.939862   \n",
      "23  25.747722    0.009287       0.944862                 0.944923   \n",
      "24  13.513739    0.009616       0.922306                 0.922311   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.942500          0.942486      0.984359   SVM-linear-scale-1  \n",
      "1               0.942500          0.942514      0.979167   SVM-linear-scale-1  \n",
      "2               0.939850          0.939832      0.977198   SVM-linear-scale-1  \n",
      "3               0.944862          0.944796      0.970842   SVM-linear-scale-1  \n",
      "4               0.922306          0.922303      0.968136   SVM-linear-scale-1  \n",
      "5               0.922500          0.922606      0.981458     SVM-poly-scale-1  \n",
      "6               0.930000          0.930021      0.967698     SVM-poly-scale-1  \n",
      "7               0.942356          0.942330      0.986117     SVM-poly-scale-1  \n",
      "8               0.949875          0.949815      0.983807     SVM-poly-scale-1  \n",
      "9               0.919799          0.919766      0.959893     SVM-poly-scale-1  \n",
      "10              0.917500          0.917480      0.975378      SVM-rbf-scale-1  \n",
      "11              0.915000          0.915000      0.966772      SVM-rbf-scale-1  \n",
      "12              0.924812          0.924790      0.982212      SVM-rbf-scale-1  \n",
      "13              0.937343          0.937391      0.982816      SVM-rbf-scale-1  \n",
      "14              0.899749          0.899749      0.959868      SVM-rbf-scale-1  \n",
      "15              0.655000          0.655673      0.739322  SVM-sigmoid-scale-1  \n",
      "16              0.682500          0.682609      0.781976  SVM-sigmoid-scale-1  \n",
      "17              0.704261          0.704074      0.783321  SVM-sigmoid-scale-1  \n",
      "18              0.649123          0.649678      0.772688  SVM-sigmoid-scale-1  \n",
      "19              0.719298          0.718828      0.773936  SVM-sigmoid-scale-1  \n",
      "20              0.942500          0.942486      0.984359    SVM-linear-auto-1  \n",
      "21              0.942500          0.942514      0.979167    SVM-linear-auto-1  \n",
      "22              0.939850          0.939832      0.977198    SVM-linear-auto-1  \n",
      "23              0.944862          0.944796      0.970842    SVM-linear-auto-1  \n",
      "24              0.922306          0.922303      0.968136    SVM-linear-auto-1  \n",
      "SVM-poly-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.97      0.94      0.96       363\n",
      "      benign       0.93      0.97      0.95       303\n",
      "\n",
      "    accuracy                           0.95       666\n",
      "   macro avg       0.95      0.95      0.95       666\n",
      "weighted avg       0.95      0.95      0.95       666\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   46.181343    0.011134       0.942500                 0.942484   \n",
      "1    6.304723    0.009347       0.942500                 0.942634   \n",
      "2   43.386375    0.010828       0.939850                 0.939862   \n",
      "3   25.759007    0.009978       0.944862                 0.944923   \n",
      "4   13.542591    0.008832       0.922306                 0.922311   \n",
      "5    0.088870    0.022612       0.922500                 0.923278   \n",
      "6    0.088983    0.023686       0.930000                 0.930228   \n",
      "7    0.091771    0.022799       0.942356                 0.942411   \n",
      "8    0.090027    0.022798       0.949875                 0.949948   \n",
      "9    0.086144    0.021468       0.919799                 0.920150   \n",
      "10   0.095671    0.089227       0.917500                 0.917471   \n",
      "11   0.096820    0.084331       0.915000                 0.915000   \n",
      "12   0.101153    0.087032       0.924812                 0.924815   \n",
      "13   0.098781    0.087209       0.937343                 0.937546   \n",
      "14   0.093754    0.082441       0.899749                 0.899749   \n",
      "15   0.123241    0.054576       0.655000                 0.661889   \n",
      "16   0.125698    0.055018       0.682500                 0.682932   \n",
      "17   0.124899    0.054710       0.704261                 0.704029   \n",
      "18   0.120419    0.052448       0.649123                 0.660864   \n",
      "19   0.132873    0.056724       0.719298                 0.720137   \n",
      "20  45.977869    0.010632       0.942500                 0.942484   \n",
      "21   6.266010    0.008849       0.942500                 0.942634   \n",
      "22  43.089100    0.010611       0.939850                 0.939862   \n",
      "23  25.747722    0.009287       0.944862                 0.944923   \n",
      "24  13.513739    0.009616       0.922306                 0.922311   \n",
      "25   0.083364    0.014358       0.912500                 0.912968   \n",
      "26   0.077085    0.014958       0.930000                 0.930116   \n",
      "27   0.086191    0.014195       0.947368                 0.947394   \n",
      "28   0.090906    0.014297       0.934837                 0.934837   \n",
      "29   0.084215    0.013920       0.929825                 0.930015   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.942500          0.942486      0.984359   SVM-linear-scale-1  \n",
      "1               0.942500          0.942514      0.979167   SVM-linear-scale-1  \n",
      "2               0.939850          0.939832      0.977198   SVM-linear-scale-1  \n",
      "3               0.944862          0.944796      0.970842   SVM-linear-scale-1  \n",
      "4               0.922306          0.922303      0.968136   SVM-linear-scale-1  \n",
      "5               0.922500          0.922606      0.981458     SVM-poly-scale-1  \n",
      "6               0.930000          0.930021      0.967698     SVM-poly-scale-1  \n",
      "7               0.942356          0.942330      0.986117     SVM-poly-scale-1  \n",
      "8               0.949875          0.949815      0.983807     SVM-poly-scale-1  \n",
      "9               0.919799          0.919766      0.959893     SVM-poly-scale-1  \n",
      "10              0.917500          0.917480      0.975378      SVM-rbf-scale-1  \n",
      "11              0.915000          0.915000      0.966772      SVM-rbf-scale-1  \n",
      "12              0.924812          0.924790      0.982212      SVM-rbf-scale-1  \n",
      "13              0.937343          0.937391      0.982816      SVM-rbf-scale-1  \n",
      "14              0.899749          0.899749      0.959868      SVM-rbf-scale-1  \n",
      "15              0.655000          0.655673      0.739322  SVM-sigmoid-scale-1  \n",
      "16              0.682500          0.682609      0.781976  SVM-sigmoid-scale-1  \n",
      "17              0.704261          0.704074      0.783321  SVM-sigmoid-scale-1  \n",
      "18              0.649123          0.649678      0.772688  SVM-sigmoid-scale-1  \n",
      "19              0.719298          0.718828      0.773936  SVM-sigmoid-scale-1  \n",
      "20              0.942500          0.942486      0.984359    SVM-linear-auto-1  \n",
      "21              0.942500          0.942514      0.979167    SVM-linear-auto-1  \n",
      "22              0.939850          0.939832      0.977198    SVM-linear-auto-1  \n",
      "23              0.944862          0.944796      0.970842    SVM-linear-auto-1  \n",
      "24              0.922306          0.922303      0.968136    SVM-linear-auto-1  \n",
      "25              0.912500          0.912591      0.973259      SVM-poly-auto-1  \n",
      "26              0.930000          0.929965      0.970252      SVM-poly-auto-1  \n",
      "27              0.947368          0.947375      0.985034      SVM-poly-auto-1  \n",
      "28              0.934837          0.934837      0.979460      SVM-poly-auto-1  \n",
      "29              0.929825          0.929826      0.959014      SVM-poly-auto-1  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-rbf-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.61      1.00      0.76       363\n",
      "      benign       1.00      0.24      0.39       303\n",
      "\n",
      "    accuracy                           0.66       666\n",
      "   macro avg       0.81      0.62      0.58       666\n",
      "weighted avg       0.79      0.66      0.59       666\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   46.181343    0.011134       0.942500                 0.942484   \n",
      "1    6.304723    0.009347       0.942500                 0.942634   \n",
      "2   43.386375    0.010828       0.939850                 0.939862   \n",
      "3   25.759007    0.009978       0.944862                 0.944923   \n",
      "4   13.542591    0.008832       0.922306                 0.922311   \n",
      "5    0.088870    0.022612       0.922500                 0.923278   \n",
      "6    0.088983    0.023686       0.930000                 0.930228   \n",
      "7    0.091771    0.022799       0.942356                 0.942411   \n",
      "8    0.090027    0.022798       0.949875                 0.949948   \n",
      "9    0.086144    0.021468       0.919799                 0.920150   \n",
      "10   0.095671    0.089227       0.917500                 0.917471   \n",
      "11   0.096820    0.084331       0.915000                 0.915000   \n",
      "12   0.101153    0.087032       0.924812                 0.924815   \n",
      "13   0.098781    0.087209       0.937343                 0.937546   \n",
      "14   0.093754    0.082441       0.899749                 0.899749   \n",
      "15   0.123241    0.054576       0.655000                 0.661889   \n",
      "16   0.125698    0.055018       0.682500                 0.682932   \n",
      "17   0.124899    0.054710       0.704261                 0.704029   \n",
      "18   0.120419    0.052448       0.649123                 0.660864   \n",
      "19   0.132873    0.056724       0.719298                 0.720137   \n",
      "20  45.977869    0.010632       0.942500                 0.942484   \n",
      "21   6.266010    0.008849       0.942500                 0.942634   \n",
      "22  43.089100    0.010611       0.939850                 0.939862   \n",
      "23  25.747722    0.009287       0.944862                 0.944923   \n",
      "24  13.513739    0.009616       0.922306                 0.922311   \n",
      "25   0.083364    0.014358       0.912500                 0.912968   \n",
      "26   0.077085    0.014958       0.930000                 0.930116   \n",
      "27   0.086191    0.014195       0.947368                 0.947394   \n",
      "28   0.090906    0.014297       0.934837                 0.934837   \n",
      "29   0.084215    0.013920       0.929825                 0.930015   \n",
      "30   0.261639    0.242236       0.655000                 0.788361   \n",
      "31   0.260749    0.243577       0.670000                 0.798118   \n",
      "32   0.261511    0.260776       0.661654                 0.794050   \n",
      "33   0.260633    0.227832       0.601504                 0.789518   \n",
      "34   0.256737    0.258841       0.619048                 0.784964   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.942500          0.942486      0.984359   SVM-linear-scale-1  \n",
      "1               0.942500          0.942514      0.979167   SVM-linear-scale-1  \n",
      "2               0.939850          0.939832      0.977198   SVM-linear-scale-1  \n",
      "3               0.944862          0.944796      0.970842   SVM-linear-scale-1  \n",
      "4               0.922306          0.922303      0.968136   SVM-linear-scale-1  \n",
      "5               0.922500          0.922606      0.981458     SVM-poly-scale-1  \n",
      "6               0.930000          0.930021      0.967698     SVM-poly-scale-1  \n",
      "7               0.942356          0.942330      0.986117     SVM-poly-scale-1  \n",
      "8               0.949875          0.949815      0.983807     SVM-poly-scale-1  \n",
      "9               0.919799          0.919766      0.959893     SVM-poly-scale-1  \n",
      "10              0.917500          0.917480      0.975378      SVM-rbf-scale-1  \n",
      "11              0.915000          0.915000      0.966772      SVM-rbf-scale-1  \n",
      "12              0.924812          0.924790      0.982212      SVM-rbf-scale-1  \n",
      "13              0.937343          0.937391      0.982816      SVM-rbf-scale-1  \n",
      "14              0.899749          0.899749      0.959868      SVM-rbf-scale-1  \n",
      "15              0.655000          0.655673      0.739322  SVM-sigmoid-scale-1  \n",
      "16              0.682500          0.682609      0.781976  SVM-sigmoid-scale-1  \n",
      "17              0.704261          0.704074      0.783321  SVM-sigmoid-scale-1  \n",
      "18              0.649123          0.649678      0.772688  SVM-sigmoid-scale-1  \n",
      "19              0.719298          0.718828      0.773936  SVM-sigmoid-scale-1  \n",
      "20              0.942500          0.942486      0.984359    SVM-linear-auto-1  \n",
      "21              0.942500          0.942514      0.979167    SVM-linear-auto-1  \n",
      "22              0.939850          0.939832      0.977198    SVM-linear-auto-1  \n",
      "23              0.944862          0.944796      0.970842    SVM-linear-auto-1  \n",
      "24              0.922306          0.922303      0.968136    SVM-linear-auto-1  \n",
      "25              0.912500          0.912591      0.973259      SVM-poly-auto-1  \n",
      "26              0.930000          0.929965      0.970252      SVM-poly-auto-1  \n",
      "27              0.947368          0.947375      0.985034      SVM-poly-auto-1  \n",
      "28              0.934837          0.934837      0.979460      SVM-poly-auto-1  \n",
      "29              0.929825          0.929826      0.959014      SVM-poly-auto-1  \n",
      "30              0.655000          0.590056      0.643154       SVM-rbf-auto-1  \n",
      "31              0.670000          0.623316      0.673615       SVM-rbf-auto-1  \n",
      "32              0.661654          0.608819      0.661565       SVM-rbf-auto-1  \n",
      "33              0.601504          0.551074      0.650376       SVM-rbf-auto-1  \n",
      "34              0.619048          0.557184      0.639041       SVM-rbf-auto-1  \n",
      "SVM-sigmoid-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.55      1.00      0.71       363\n",
      "      benign       0.00      0.00      0.00       303\n",
      "\n",
      "    accuracy                           0.55       666\n",
      "   macro avg       0.27      0.50      0.35       666\n",
      "weighted avg       0.30      0.55      0.38       666\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   46.181343    0.011134       0.942500                 0.942484   \n",
      "1    6.304723    0.009347       0.942500                 0.942634   \n",
      "2   43.386375    0.010828       0.939850                 0.939862   \n",
      "3   25.759007    0.009978       0.944862                 0.944923   \n",
      "4   13.542591    0.008832       0.922306                 0.922311   \n",
      "5    0.088870    0.022612       0.922500                 0.923278   \n",
      "6    0.088983    0.023686       0.930000                 0.930228   \n",
      "7    0.091771    0.022799       0.942356                 0.942411   \n",
      "8    0.090027    0.022798       0.949875                 0.949948   \n",
      "9    0.086144    0.021468       0.919799                 0.920150   \n",
      "10   0.095671    0.089227       0.917500                 0.917471   \n",
      "11   0.096820    0.084331       0.915000                 0.915000   \n",
      "12   0.101153    0.087032       0.924812                 0.924815   \n",
      "13   0.098781    0.087209       0.937343                 0.937546   \n",
      "14   0.093754    0.082441       0.899749                 0.899749   \n",
      "15   0.123241    0.054576       0.655000                 0.661889   \n",
      "16   0.125698    0.055018       0.682500                 0.682932   \n",
      "17   0.124899    0.054710       0.704261                 0.704029   \n",
      "18   0.120419    0.052448       0.649123                 0.660864   \n",
      "19   0.132873    0.056724       0.719298                 0.720137   \n",
      "20  45.977869    0.010632       0.942500                 0.942484   \n",
      "21   6.266010    0.008849       0.942500                 0.942634   \n",
      "22  43.089100    0.010611       0.939850                 0.939862   \n",
      "23  25.747722    0.009287       0.944862                 0.944923   \n",
      "24  13.513739    0.009616       0.922306                 0.922311   \n",
      "25   0.083364    0.014358       0.912500                 0.912968   \n",
      "26   0.077085    0.014958       0.930000                 0.930116   \n",
      "27   0.086191    0.014195       0.947368                 0.947394   \n",
      "28   0.090906    0.014297       0.934837                 0.934837   \n",
      "29   0.084215    0.013920       0.929825                 0.930015   \n",
      "30   0.261639    0.242236       0.655000                 0.788361   \n",
      "31   0.260749    0.243577       0.670000                 0.798118   \n",
      "32   0.261511    0.260776       0.661654                 0.794050   \n",
      "33   0.260633    0.227832       0.601504                 0.789518   \n",
      "34   0.256737    0.258841       0.619048                 0.784964   \n",
      "35   0.223821    0.091820       0.452500                 0.204756   \n",
      "36   0.224150    0.091597       0.520000                 0.270400   \n",
      "37   0.224631    0.090979       0.526316                 0.277008   \n",
      "38   0.215457    0.087864       0.446115                 0.199019   \n",
      "39   0.220230    0.089959       0.493734                 0.243774   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.942500          0.942486      0.984359   SVM-linear-scale-1  \n",
      "1               0.942500          0.942514      0.979167   SVM-linear-scale-1  \n",
      "2               0.939850          0.939832      0.977198   SVM-linear-scale-1  \n",
      "3               0.944862          0.944796      0.970842   SVM-linear-scale-1  \n",
      "4               0.922306          0.922303      0.968136   SVM-linear-scale-1  \n",
      "5               0.922500          0.922606      0.981458     SVM-poly-scale-1  \n",
      "6               0.930000          0.930021      0.967698     SVM-poly-scale-1  \n",
      "7               0.942356          0.942330      0.986117     SVM-poly-scale-1  \n",
      "8               0.949875          0.949815      0.983807     SVM-poly-scale-1  \n",
      "9               0.919799          0.919766      0.959893     SVM-poly-scale-1  \n",
      "10              0.917500          0.917480      0.975378      SVM-rbf-scale-1  \n",
      "11              0.915000          0.915000      0.966772      SVM-rbf-scale-1  \n",
      "12              0.924812          0.924790      0.982212      SVM-rbf-scale-1  \n",
      "13              0.937343          0.937391      0.982816      SVM-rbf-scale-1  \n",
      "14              0.899749          0.899749      0.959868      SVM-rbf-scale-1  \n",
      "15              0.655000          0.655673      0.739322  SVM-sigmoid-scale-1  \n",
      "16              0.682500          0.682609      0.781976  SVM-sigmoid-scale-1  \n",
      "17              0.704261          0.704074      0.783321  SVM-sigmoid-scale-1  \n",
      "18              0.649123          0.649678      0.772688  SVM-sigmoid-scale-1  \n",
      "19              0.719298          0.718828      0.773936  SVM-sigmoid-scale-1  \n",
      "20              0.942500          0.942486      0.984359    SVM-linear-auto-1  \n",
      "21              0.942500          0.942514      0.979167    SVM-linear-auto-1  \n",
      "22              0.939850          0.939832      0.977198    SVM-linear-auto-1  \n",
      "23              0.944862          0.944796      0.970842    SVM-linear-auto-1  \n",
      "24              0.922306          0.922303      0.968136    SVM-linear-auto-1  \n",
      "25              0.912500          0.912591      0.973259      SVM-poly-auto-1  \n",
      "26              0.930000          0.929965      0.970252      SVM-poly-auto-1  \n",
      "27              0.947368          0.947375      0.985034      SVM-poly-auto-1  \n",
      "28              0.934837          0.934837      0.979460      SVM-poly-auto-1  \n",
      "29              0.929825          0.929826      0.959014      SVM-poly-auto-1  \n",
      "30              0.655000          0.590056      0.643154       SVM-rbf-auto-1  \n",
      "31              0.670000          0.623316      0.673615       SVM-rbf-auto-1  \n",
      "32              0.661654          0.608819      0.661565       SVM-rbf-auto-1  \n",
      "33              0.601504          0.551074      0.650376       SVM-rbf-auto-1  \n",
      "34              0.619048          0.557184      0.639041       SVM-rbf-auto-1  \n",
      "35              0.452500          0.281936      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.520000          0.355789      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.526316          0.362976      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.446115          0.275246      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.493734          0.326395      0.500000   SVM-sigmoid-auto-1  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-linear-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.96      0.93      0.95       363\n",
      "      benign       0.92      0.96      0.94       303\n",
      "\n",
      "    accuracy                           0.94       666\n",
      "   macro avg       0.94      0.94      0.94       666\n",
      "weighted avg       0.94      0.94      0.94       666\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   46.181343    0.011134       0.942500                 0.942484   \n",
      "1    6.304723    0.009347       0.942500                 0.942634   \n",
      "2   43.386375    0.010828       0.939850                 0.939862   \n",
      "3   25.759007    0.009978       0.944862                 0.944923   \n",
      "4   13.542591    0.008832       0.922306                 0.922311   \n",
      "5    0.088870    0.022612       0.922500                 0.923278   \n",
      "6    0.088983    0.023686       0.930000                 0.930228   \n",
      "7    0.091771    0.022799       0.942356                 0.942411   \n",
      "8    0.090027    0.022798       0.949875                 0.949948   \n",
      "9    0.086144    0.021468       0.919799                 0.920150   \n",
      "10   0.095671    0.089227       0.917500                 0.917471   \n",
      "11   0.096820    0.084331       0.915000                 0.915000   \n",
      "12   0.101153    0.087032       0.924812                 0.924815   \n",
      "13   0.098781    0.087209       0.937343                 0.937546   \n",
      "14   0.093754    0.082441       0.899749                 0.899749   \n",
      "15   0.123241    0.054576       0.655000                 0.661889   \n",
      "16   0.125698    0.055018       0.682500                 0.682932   \n",
      "17   0.124899    0.054710       0.704261                 0.704029   \n",
      "18   0.120419    0.052448       0.649123                 0.660864   \n",
      "19   0.132873    0.056724       0.719298                 0.720137   \n",
      "20  45.977869    0.010632       0.942500                 0.942484   \n",
      "21   6.266010    0.008849       0.942500                 0.942634   \n",
      "22  43.089100    0.010611       0.939850                 0.939862   \n",
      "23  25.747722    0.009287       0.944862                 0.944923   \n",
      "24  13.513739    0.009616       0.922306                 0.922311   \n",
      "25   0.083364    0.014358       0.912500                 0.912968   \n",
      "26   0.077085    0.014958       0.930000                 0.930116   \n",
      "27   0.086191    0.014195       0.947368                 0.947394   \n",
      "28   0.090906    0.014297       0.934837                 0.934837   \n",
      "29   0.084215    0.013920       0.929825                 0.930015   \n",
      "30   0.261639    0.242236       0.655000                 0.788361   \n",
      "31   0.260749    0.243577       0.670000                 0.798118   \n",
      "32   0.261511    0.260776       0.661654                 0.794050   \n",
      "33   0.260633    0.227832       0.601504                 0.789518   \n",
      "34   0.256737    0.258841       0.619048                 0.784964   \n",
      "35   0.223821    0.091820       0.452500                 0.204756   \n",
      "36   0.224150    0.091597       0.520000                 0.270400   \n",
      "37   0.224631    0.090979       0.526316                 0.277008   \n",
      "38   0.215457    0.087864       0.446115                 0.199019   \n",
      "39   0.220230    0.089959       0.493734                 0.243774   \n",
      "40  46.010785    0.010554       0.942500                 0.942484   \n",
      "41   6.266292    0.008838       0.942500                 0.942634   \n",
      "42  43.147571    0.010631       0.939850                 0.939862   \n",
      "43  25.692864    0.009347       0.944862                 0.944923   \n",
      "44  13.510476    0.009579       0.922306                 0.922311   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.942500          0.942486      0.984359   SVM-linear-scale-1  \n",
      "1               0.942500          0.942514      0.979167   SVM-linear-scale-1  \n",
      "2               0.939850          0.939832      0.977198   SVM-linear-scale-1  \n",
      "3               0.944862          0.944796      0.970842   SVM-linear-scale-1  \n",
      "4               0.922306          0.922303      0.968136   SVM-linear-scale-1  \n",
      "5               0.922500          0.922606      0.981458     SVM-poly-scale-1  \n",
      "6               0.930000          0.930021      0.967698     SVM-poly-scale-1  \n",
      "7               0.942356          0.942330      0.986117     SVM-poly-scale-1  \n",
      "8               0.949875          0.949815      0.983807     SVM-poly-scale-1  \n",
      "9               0.919799          0.919766      0.959893     SVM-poly-scale-1  \n",
      "10              0.917500          0.917480      0.975378      SVM-rbf-scale-1  \n",
      "11              0.915000          0.915000      0.966772      SVM-rbf-scale-1  \n",
      "12              0.924812          0.924790      0.982212      SVM-rbf-scale-1  \n",
      "13              0.937343          0.937391      0.982816      SVM-rbf-scale-1  \n",
      "14              0.899749          0.899749      0.959868      SVM-rbf-scale-1  \n",
      "15              0.655000          0.655673      0.739322  SVM-sigmoid-scale-1  \n",
      "16              0.682500          0.682609      0.781976  SVM-sigmoid-scale-1  \n",
      "17              0.704261          0.704074      0.783321  SVM-sigmoid-scale-1  \n",
      "18              0.649123          0.649678      0.772688  SVM-sigmoid-scale-1  \n",
      "19              0.719298          0.718828      0.773936  SVM-sigmoid-scale-1  \n",
      "20              0.942500          0.942486      0.984359    SVM-linear-auto-1  \n",
      "21              0.942500          0.942514      0.979167    SVM-linear-auto-1  \n",
      "22              0.939850          0.939832      0.977198    SVM-linear-auto-1  \n",
      "23              0.944862          0.944796      0.970842    SVM-linear-auto-1  \n",
      "24              0.922306          0.922303      0.968136    SVM-linear-auto-1  \n",
      "25              0.912500          0.912591      0.973259      SVM-poly-auto-1  \n",
      "26              0.930000          0.929965      0.970252      SVM-poly-auto-1  \n",
      "27              0.947368          0.947375      0.985034      SVM-poly-auto-1  \n",
      "28              0.934837          0.934837      0.979460      SVM-poly-auto-1  \n",
      "29              0.929825          0.929826      0.959014      SVM-poly-auto-1  \n",
      "30              0.655000          0.590056      0.643154       SVM-rbf-auto-1  \n",
      "31              0.670000          0.623316      0.673615       SVM-rbf-auto-1  \n",
      "32              0.661654          0.608819      0.661565       SVM-rbf-auto-1  \n",
      "33              0.601504          0.551074      0.650376       SVM-rbf-auto-1  \n",
      "34              0.619048          0.557184      0.639041       SVM-rbf-auto-1  \n",
      "35              0.452500          0.281936      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.520000          0.355789      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.526316          0.362976      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.446115          0.275246      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.493734          0.326395      0.500000   SVM-sigmoid-auto-1  \n",
      "40              0.942500          0.942486      0.984359   SVM-linear-scale-2  \n",
      "41              0.942500          0.942514      0.979167   SVM-linear-scale-2  \n",
      "42              0.939850          0.939832      0.977198   SVM-linear-scale-2  \n",
      "43              0.944862          0.944796      0.970842   SVM-linear-scale-2  \n",
      "44              0.922306          0.922303      0.968136   SVM-linear-scale-2  \n",
      "SVM-poly-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.99      0.96      0.97       363\n",
      "      benign       0.96      0.98      0.97       303\n",
      "\n",
      "    accuracy                           0.97       666\n",
      "   macro avg       0.97      0.97      0.97       666\n",
      "weighted avg       0.97      0.97      0.97       666\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   46.181343    0.011134       0.942500                 0.942484   \n",
      "1    6.304723    0.009347       0.942500                 0.942634   \n",
      "2   43.386375    0.010828       0.939850                 0.939862   \n",
      "3   25.759007    0.009978       0.944862                 0.944923   \n",
      "4   13.542591    0.008832       0.922306                 0.922311   \n",
      "5    0.088870    0.022612       0.922500                 0.923278   \n",
      "6    0.088983    0.023686       0.930000                 0.930228   \n",
      "7    0.091771    0.022799       0.942356                 0.942411   \n",
      "8    0.090027    0.022798       0.949875                 0.949948   \n",
      "9    0.086144    0.021468       0.919799                 0.920150   \n",
      "10   0.095671    0.089227       0.917500                 0.917471   \n",
      "11   0.096820    0.084331       0.915000                 0.915000   \n",
      "12   0.101153    0.087032       0.924812                 0.924815   \n",
      "13   0.098781    0.087209       0.937343                 0.937546   \n",
      "14   0.093754    0.082441       0.899749                 0.899749   \n",
      "15   0.123241    0.054576       0.655000                 0.661889   \n",
      "16   0.125698    0.055018       0.682500                 0.682932   \n",
      "17   0.124899    0.054710       0.704261                 0.704029   \n",
      "18   0.120419    0.052448       0.649123                 0.660864   \n",
      "19   0.132873    0.056724       0.719298                 0.720137   \n",
      "20  45.977869    0.010632       0.942500                 0.942484   \n",
      "21   6.266010    0.008849       0.942500                 0.942634   \n",
      "22  43.089100    0.010611       0.939850                 0.939862   \n",
      "23  25.747722    0.009287       0.944862                 0.944923   \n",
      "24  13.513739    0.009616       0.922306                 0.922311   \n",
      "25   0.083364    0.014358       0.912500                 0.912968   \n",
      "26   0.077085    0.014958       0.930000                 0.930116   \n",
      "27   0.086191    0.014195       0.947368                 0.947394   \n",
      "28   0.090906    0.014297       0.934837                 0.934837   \n",
      "29   0.084215    0.013920       0.929825                 0.930015   \n",
      "30   0.261639    0.242236       0.655000                 0.788361   \n",
      "31   0.260749    0.243577       0.670000                 0.798118   \n",
      "32   0.261511    0.260776       0.661654                 0.794050   \n",
      "33   0.260633    0.227832       0.601504                 0.789518   \n",
      "34   0.256737    0.258841       0.619048                 0.784964   \n",
      "35   0.223821    0.091820       0.452500                 0.204756   \n",
      "36   0.224150    0.091597       0.520000                 0.270400   \n",
      "37   0.224631    0.090979       0.526316                 0.277008   \n",
      "38   0.215457    0.087864       0.446115                 0.199019   \n",
      "39   0.220230    0.089959       0.493734                 0.243774   \n",
      "40  46.010785    0.010554       0.942500                 0.942484   \n",
      "41   6.266292    0.008838       0.942500                 0.942634   \n",
      "42  43.147571    0.010631       0.939850                 0.939862   \n",
      "43  25.692864    0.009347       0.944862                 0.944923   \n",
      "44  13.510476    0.009579       0.922306                 0.922311   \n",
      "45   0.089366    0.020880       0.932500                 0.933257   \n",
      "46   0.087524    0.021850       0.942500                 0.942500   \n",
      "47   0.092854    0.021654       0.954887                 0.955023   \n",
      "48   0.087491    0.021064       0.952381                 0.952539   \n",
      "49   0.082500    0.020168       0.927318                 0.927324   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.942500          0.942486      0.984359   SVM-linear-scale-1  \n",
      "1               0.942500          0.942514      0.979167   SVM-linear-scale-1  \n",
      "2               0.939850          0.939832      0.977198   SVM-linear-scale-1  \n",
      "3               0.944862          0.944796      0.970842   SVM-linear-scale-1  \n",
      "4               0.922306          0.922303      0.968136   SVM-linear-scale-1  \n",
      "5               0.922500          0.922606      0.981458     SVM-poly-scale-1  \n",
      "6               0.930000          0.930021      0.967698     SVM-poly-scale-1  \n",
      "7               0.942356          0.942330      0.986117     SVM-poly-scale-1  \n",
      "8               0.949875          0.949815      0.983807     SVM-poly-scale-1  \n",
      "9               0.919799          0.919766      0.959893     SVM-poly-scale-1  \n",
      "10              0.917500          0.917480      0.975378      SVM-rbf-scale-1  \n",
      "11              0.915000          0.915000      0.966772      SVM-rbf-scale-1  \n",
      "12              0.924812          0.924790      0.982212      SVM-rbf-scale-1  \n",
      "13              0.937343          0.937391      0.982816      SVM-rbf-scale-1  \n",
      "14              0.899749          0.899749      0.959868      SVM-rbf-scale-1  \n",
      "15              0.655000          0.655673      0.739322  SVM-sigmoid-scale-1  \n",
      "16              0.682500          0.682609      0.781976  SVM-sigmoid-scale-1  \n",
      "17              0.704261          0.704074      0.783321  SVM-sigmoid-scale-1  \n",
      "18              0.649123          0.649678      0.772688  SVM-sigmoid-scale-1  \n",
      "19              0.719298          0.718828      0.773936  SVM-sigmoid-scale-1  \n",
      "20              0.942500          0.942486      0.984359    SVM-linear-auto-1  \n",
      "21              0.942500          0.942514      0.979167    SVM-linear-auto-1  \n",
      "22              0.939850          0.939832      0.977198    SVM-linear-auto-1  \n",
      "23              0.944862          0.944796      0.970842    SVM-linear-auto-1  \n",
      "24              0.922306          0.922303      0.968136    SVM-linear-auto-1  \n",
      "25              0.912500          0.912591      0.973259      SVM-poly-auto-1  \n",
      "26              0.930000          0.929965      0.970252      SVM-poly-auto-1  \n",
      "27              0.947368          0.947375      0.985034      SVM-poly-auto-1  \n",
      "28              0.934837          0.934837      0.979460      SVM-poly-auto-1  \n",
      "29              0.929825          0.929826      0.959014      SVM-poly-auto-1  \n",
      "30              0.655000          0.590056      0.643154       SVM-rbf-auto-1  \n",
      "31              0.670000          0.623316      0.673615       SVM-rbf-auto-1  \n",
      "32              0.661654          0.608819      0.661565       SVM-rbf-auto-1  \n",
      "33              0.601504          0.551074      0.650376       SVM-rbf-auto-1  \n",
      "34              0.619048          0.557184      0.639041       SVM-rbf-auto-1  \n",
      "35              0.452500          0.281936      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.520000          0.355789      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.526316          0.362976      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.446115          0.275246      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.493734          0.326395      0.500000   SVM-sigmoid-auto-1  \n",
      "40              0.942500          0.942486      0.984359   SVM-linear-scale-2  \n",
      "41              0.942500          0.942514      0.979167   SVM-linear-scale-2  \n",
      "42              0.939850          0.939832      0.977198   SVM-linear-scale-2  \n",
      "43              0.944862          0.944796      0.970842   SVM-linear-scale-2  \n",
      "44              0.922306          0.922303      0.968136   SVM-linear-scale-2  \n",
      "45              0.932500          0.932592      0.983198     SVM-poly-scale-2  \n",
      "46              0.942500          0.942494      0.968850     SVM-poly-scale-2  \n",
      "47              0.954887          0.954859      0.988561     SVM-poly-scale-2  \n",
      "48              0.952381          0.952308      0.985663     SVM-poly-scale-2  \n",
      "49              0.927318          0.927316      0.969644     SVM-poly-scale-2  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-rbf-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.97      0.95      0.96       363\n",
      "      benign       0.94      0.97      0.96       303\n",
      "\n",
      "    accuracy                           0.96       666\n",
      "   macro avg       0.96      0.96      0.96       666\n",
      "weighted avg       0.96      0.96      0.96       666\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   46.181343    0.011134       0.942500                 0.942484   \n",
      "1    6.304723    0.009347       0.942500                 0.942634   \n",
      "2   43.386375    0.010828       0.939850                 0.939862   \n",
      "3   25.759007    0.009978       0.944862                 0.944923   \n",
      "4   13.542591    0.008832       0.922306                 0.922311   \n",
      "5    0.088870    0.022612       0.922500                 0.923278   \n",
      "6    0.088983    0.023686       0.930000                 0.930228   \n",
      "7    0.091771    0.022799       0.942356                 0.942411   \n",
      "8    0.090027    0.022798       0.949875                 0.949948   \n",
      "9    0.086144    0.021468       0.919799                 0.920150   \n",
      "10   0.095671    0.089227       0.917500                 0.917471   \n",
      "11   0.096820    0.084331       0.915000                 0.915000   \n",
      "12   0.101153    0.087032       0.924812                 0.924815   \n",
      "13   0.098781    0.087209       0.937343                 0.937546   \n",
      "14   0.093754    0.082441       0.899749                 0.899749   \n",
      "15   0.123241    0.054576       0.655000                 0.661889   \n",
      "16   0.125698    0.055018       0.682500                 0.682932   \n",
      "17   0.124899    0.054710       0.704261                 0.704029   \n",
      "18   0.120419    0.052448       0.649123                 0.660864   \n",
      "19   0.132873    0.056724       0.719298                 0.720137   \n",
      "20  45.977869    0.010632       0.942500                 0.942484   \n",
      "21   6.266010    0.008849       0.942500                 0.942634   \n",
      "22  43.089100    0.010611       0.939850                 0.939862   \n",
      "23  25.747722    0.009287       0.944862                 0.944923   \n",
      "24  13.513739    0.009616       0.922306                 0.922311   \n",
      "25   0.083364    0.014358       0.912500                 0.912968   \n",
      "26   0.077085    0.014958       0.930000                 0.930116   \n",
      "27   0.086191    0.014195       0.947368                 0.947394   \n",
      "28   0.090906    0.014297       0.934837                 0.934837   \n",
      "29   0.084215    0.013920       0.929825                 0.930015   \n",
      "30   0.261639    0.242236       0.655000                 0.788361   \n",
      "31   0.260749    0.243577       0.670000                 0.798118   \n",
      "32   0.261511    0.260776       0.661654                 0.794050   \n",
      "33   0.260633    0.227832       0.601504                 0.789518   \n",
      "34   0.256737    0.258841       0.619048                 0.784964   \n",
      "35   0.223821    0.091820       0.452500                 0.204756   \n",
      "36   0.224150    0.091597       0.520000                 0.270400   \n",
      "37   0.224631    0.090979       0.526316                 0.277008   \n",
      "38   0.215457    0.087864       0.446115                 0.199019   \n",
      "39   0.220230    0.089959       0.493734                 0.243774   \n",
      "40  46.010785    0.010554       0.942500                 0.942484   \n",
      "41   6.266292    0.008838       0.942500                 0.942634   \n",
      "42  43.147571    0.010631       0.939850                 0.939862   \n",
      "43  25.692864    0.009347       0.944862                 0.944923   \n",
      "44  13.510476    0.009579       0.922306                 0.922311   \n",
      "45   0.089366    0.020880       0.932500                 0.933257   \n",
      "46   0.087524    0.021850       0.942500                 0.942500   \n",
      "47   0.092854    0.021654       0.954887                 0.955023   \n",
      "48   0.087491    0.021064       0.952381                 0.952539   \n",
      "49   0.082500    0.020168       0.927318                 0.927324   \n",
      "50   0.089105    0.074795       0.917500                 0.917476   \n",
      "51   0.091143    0.074924       0.917500                 0.917644   \n",
      "52   0.092662    0.084401       0.949875                 0.950205   \n",
      "53   0.091640    0.084092       0.947368                 0.947351   \n",
      "54   0.088725    0.083277       0.909774                 0.909917   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.942500          0.942486      0.984359   SVM-linear-scale-1  \n",
      "1               0.942500          0.942514      0.979167   SVM-linear-scale-1  \n",
      "2               0.939850          0.939832      0.977198   SVM-linear-scale-1  \n",
      "3               0.944862          0.944796      0.970842   SVM-linear-scale-1  \n",
      "4               0.922306          0.922303      0.968136   SVM-linear-scale-1  \n",
      "5               0.922500          0.922606      0.981458     SVM-poly-scale-1  \n",
      "6               0.930000          0.930021      0.967698     SVM-poly-scale-1  \n",
      "7               0.942356          0.942330      0.986117     SVM-poly-scale-1  \n",
      "8               0.949875          0.949815      0.983807     SVM-poly-scale-1  \n",
      "9               0.919799          0.919766      0.959893     SVM-poly-scale-1  \n",
      "10              0.917500          0.917480      0.975378      SVM-rbf-scale-1  \n",
      "11              0.915000          0.915000      0.966772      SVM-rbf-scale-1  \n",
      "12              0.924812          0.924790      0.982212      SVM-rbf-scale-1  \n",
      "13              0.937343          0.937391      0.982816      SVM-rbf-scale-1  \n",
      "14              0.899749          0.899749      0.959868      SVM-rbf-scale-1  \n",
      "15              0.655000          0.655673      0.739322  SVM-sigmoid-scale-1  \n",
      "16              0.682500          0.682609      0.781976  SVM-sigmoid-scale-1  \n",
      "17              0.704261          0.704074      0.783321  SVM-sigmoid-scale-1  \n",
      "18              0.649123          0.649678      0.772688  SVM-sigmoid-scale-1  \n",
      "19              0.719298          0.718828      0.773936  SVM-sigmoid-scale-1  \n",
      "20              0.942500          0.942486      0.984359    SVM-linear-auto-1  \n",
      "21              0.942500          0.942514      0.979167    SVM-linear-auto-1  \n",
      "22              0.939850          0.939832      0.977198    SVM-linear-auto-1  \n",
      "23              0.944862          0.944796      0.970842    SVM-linear-auto-1  \n",
      "24              0.922306          0.922303      0.968136    SVM-linear-auto-1  \n",
      "25              0.912500          0.912591      0.973259      SVM-poly-auto-1  \n",
      "26              0.930000          0.929965      0.970252      SVM-poly-auto-1  \n",
      "27              0.947368          0.947375      0.985034      SVM-poly-auto-1  \n",
      "28              0.934837          0.934837      0.979460      SVM-poly-auto-1  \n",
      "29              0.929825          0.929826      0.959014      SVM-poly-auto-1  \n",
      "30              0.655000          0.590056      0.643154       SVM-rbf-auto-1  \n",
      "31              0.670000          0.623316      0.673615       SVM-rbf-auto-1  \n",
      "32              0.661654          0.608819      0.661565       SVM-rbf-auto-1  \n",
      "33              0.601504          0.551074      0.650376       SVM-rbf-auto-1  \n",
      "34              0.619048          0.557184      0.639041       SVM-rbf-auto-1  \n",
      "35              0.452500          0.281936      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.520000          0.355789      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.526316          0.362976      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.446115          0.275246      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.493734          0.326395      0.500000   SVM-sigmoid-auto-1  \n",
      "40              0.942500          0.942486      0.984359   SVM-linear-scale-2  \n",
      "41              0.942500          0.942514      0.979167   SVM-linear-scale-2  \n",
      "42              0.939850          0.939832      0.977198   SVM-linear-scale-2  \n",
      "43              0.944862          0.944796      0.970842   SVM-linear-scale-2  \n",
      "44              0.922306          0.922303      0.968136   SVM-linear-scale-2  \n",
      "45              0.932500          0.932592      0.983198     SVM-poly-scale-2  \n",
      "46              0.942500          0.942494      0.968850     SVM-poly-scale-2  \n",
      "47              0.954887          0.954859      0.988561     SVM-poly-scale-2  \n",
      "48              0.952381          0.952308      0.985663     SVM-poly-scale-2  \n",
      "49              0.927318          0.927316      0.969644     SVM-poly-scale-2  \n",
      "50              0.917500          0.917436      0.982265      SVM-rbf-scale-2  \n",
      "51              0.917500          0.917520      0.970853      SVM-rbf-scale-2  \n",
      "52              0.949875          0.949823      0.988108      SVM-rbf-scale-2  \n",
      "53              0.947368          0.947354      0.985383      SVM-rbf-scale-2  \n",
      "54              0.909774          0.909754      0.964844      SVM-rbf-scale-2  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-sigmoid-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.71      0.62      0.66       363\n",
      "      benign       0.60      0.70      0.65       303\n",
      "\n",
      "    accuracy                           0.65       666\n",
      "   macro avg       0.66      0.66      0.65       666\n",
      "weighted avg       0.66      0.65      0.66       666\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   46.181343    0.011134       0.942500                 0.942484   \n",
      "1    6.304723    0.009347       0.942500                 0.942634   \n",
      "2   43.386375    0.010828       0.939850                 0.939862   \n",
      "3   25.759007    0.009978       0.944862                 0.944923   \n",
      "4   13.542591    0.008832       0.922306                 0.922311   \n",
      "5    0.088870    0.022612       0.922500                 0.923278   \n",
      "6    0.088983    0.023686       0.930000                 0.930228   \n",
      "7    0.091771    0.022799       0.942356                 0.942411   \n",
      "8    0.090027    0.022798       0.949875                 0.949948   \n",
      "9    0.086144    0.021468       0.919799                 0.920150   \n",
      "10   0.095671    0.089227       0.917500                 0.917471   \n",
      "11   0.096820    0.084331       0.915000                 0.915000   \n",
      "12   0.101153    0.087032       0.924812                 0.924815   \n",
      "13   0.098781    0.087209       0.937343                 0.937546   \n",
      "14   0.093754    0.082441       0.899749                 0.899749   \n",
      "15   0.123241    0.054576       0.655000                 0.661889   \n",
      "16   0.125698    0.055018       0.682500                 0.682932   \n",
      "17   0.124899    0.054710       0.704261                 0.704029   \n",
      "18   0.120419    0.052448       0.649123                 0.660864   \n",
      "19   0.132873    0.056724       0.719298                 0.720137   \n",
      "20  45.977869    0.010632       0.942500                 0.942484   \n",
      "21   6.266010    0.008849       0.942500                 0.942634   \n",
      "22  43.089100    0.010611       0.939850                 0.939862   \n",
      "23  25.747722    0.009287       0.944862                 0.944923   \n",
      "24  13.513739    0.009616       0.922306                 0.922311   \n",
      "25   0.083364    0.014358       0.912500                 0.912968   \n",
      "26   0.077085    0.014958       0.930000                 0.930116   \n",
      "27   0.086191    0.014195       0.947368                 0.947394   \n",
      "28   0.090906    0.014297       0.934837                 0.934837   \n",
      "29   0.084215    0.013920       0.929825                 0.930015   \n",
      "30   0.261639    0.242236       0.655000                 0.788361   \n",
      "31   0.260749    0.243577       0.670000                 0.798118   \n",
      "32   0.261511    0.260776       0.661654                 0.794050   \n",
      "33   0.260633    0.227832       0.601504                 0.789518   \n",
      "34   0.256737    0.258841       0.619048                 0.784964   \n",
      "35   0.223821    0.091820       0.452500                 0.204756   \n",
      "36   0.224150    0.091597       0.520000                 0.270400   \n",
      "37   0.224631    0.090979       0.526316                 0.277008   \n",
      "38   0.215457    0.087864       0.446115                 0.199019   \n",
      "39   0.220230    0.089959       0.493734                 0.243774   \n",
      "40  46.010785    0.010554       0.942500                 0.942484   \n",
      "41   6.266292    0.008838       0.942500                 0.942634   \n",
      "42  43.147571    0.010631       0.939850                 0.939862   \n",
      "43  25.692864    0.009347       0.944862                 0.944923   \n",
      "44  13.510476    0.009579       0.922306                 0.922311   \n",
      "45   0.089366    0.020880       0.932500                 0.933257   \n",
      "46   0.087524    0.021850       0.942500                 0.942500   \n",
      "47   0.092854    0.021654       0.954887                 0.955023   \n",
      "48   0.087491    0.021064       0.952381                 0.952539   \n",
      "49   0.082500    0.020168       0.927318                 0.927324   \n",
      "50   0.089105    0.074795       0.917500                 0.917476   \n",
      "51   0.091143    0.074924       0.917500                 0.917644   \n",
      "52   0.092662    0.084401       0.949875                 0.950205   \n",
      "53   0.091640    0.084092       0.947368                 0.947351   \n",
      "54   0.088725    0.083277       0.909774                 0.909917   \n",
      "55   0.116246    0.051308       0.652500                 0.659748   \n",
      "56   0.120689    0.052659       0.672500                 0.672935   \n",
      "57   0.121225    0.052711       0.696742                 0.696827   \n",
      "58   0.114120    0.050644       0.636591                 0.647717   \n",
      "59   0.128382    0.055509       0.699248                 0.699561   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.942500          0.942486      0.984359   SVM-linear-scale-1  \n",
      "1               0.942500          0.942514      0.979167   SVM-linear-scale-1  \n",
      "2               0.939850          0.939832      0.977198   SVM-linear-scale-1  \n",
      "3               0.944862          0.944796      0.970842   SVM-linear-scale-1  \n",
      "4               0.922306          0.922303      0.968136   SVM-linear-scale-1  \n",
      "5               0.922500          0.922606      0.981458     SVM-poly-scale-1  \n",
      "6               0.930000          0.930021      0.967698     SVM-poly-scale-1  \n",
      "7               0.942356          0.942330      0.986117     SVM-poly-scale-1  \n",
      "8               0.949875          0.949815      0.983807     SVM-poly-scale-1  \n",
      "9               0.919799          0.919766      0.959893     SVM-poly-scale-1  \n",
      "10              0.917500          0.917480      0.975378      SVM-rbf-scale-1  \n",
      "11              0.915000          0.915000      0.966772      SVM-rbf-scale-1  \n",
      "12              0.924812          0.924790      0.982212      SVM-rbf-scale-1  \n",
      "13              0.937343          0.937391      0.982816      SVM-rbf-scale-1  \n",
      "14              0.899749          0.899749      0.959868      SVM-rbf-scale-1  \n",
      "15              0.655000          0.655673      0.739322  SVM-sigmoid-scale-1  \n",
      "16              0.682500          0.682609      0.781976  SVM-sigmoid-scale-1  \n",
      "17              0.704261          0.704074      0.783321  SVM-sigmoid-scale-1  \n",
      "18              0.649123          0.649678      0.772688  SVM-sigmoid-scale-1  \n",
      "19              0.719298          0.718828      0.773936  SVM-sigmoid-scale-1  \n",
      "20              0.942500          0.942486      0.984359    SVM-linear-auto-1  \n",
      "21              0.942500          0.942514      0.979167    SVM-linear-auto-1  \n",
      "22              0.939850          0.939832      0.977198    SVM-linear-auto-1  \n",
      "23              0.944862          0.944796      0.970842    SVM-linear-auto-1  \n",
      "24              0.922306          0.922303      0.968136    SVM-linear-auto-1  \n",
      "25              0.912500          0.912591      0.973259      SVM-poly-auto-1  \n",
      "26              0.930000          0.929965      0.970252      SVM-poly-auto-1  \n",
      "27              0.947368          0.947375      0.985034      SVM-poly-auto-1  \n",
      "28              0.934837          0.934837      0.979460      SVM-poly-auto-1  \n",
      "29              0.929825          0.929826      0.959014      SVM-poly-auto-1  \n",
      "30              0.655000          0.590056      0.643154       SVM-rbf-auto-1  \n",
      "31              0.670000          0.623316      0.673615       SVM-rbf-auto-1  \n",
      "32              0.661654          0.608819      0.661565       SVM-rbf-auto-1  \n",
      "33              0.601504          0.551074      0.650376       SVM-rbf-auto-1  \n",
      "34              0.619048          0.557184      0.639041       SVM-rbf-auto-1  \n",
      "35              0.452500          0.281936      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.520000          0.355789      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.526316          0.362976      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.446115          0.275246      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.493734          0.326395      0.500000   SVM-sigmoid-auto-1  \n",
      "40              0.942500          0.942486      0.984359   SVM-linear-scale-2  \n",
      "41              0.942500          0.942514      0.979167   SVM-linear-scale-2  \n",
      "42              0.939850          0.939832      0.977198   SVM-linear-scale-2  \n",
      "43              0.944862          0.944796      0.970842   SVM-linear-scale-2  \n",
      "44              0.922306          0.922303      0.968136   SVM-linear-scale-2  \n",
      "45              0.932500          0.932592      0.983198     SVM-poly-scale-2  \n",
      "46              0.942500          0.942494      0.968850     SVM-poly-scale-2  \n",
      "47              0.954887          0.954859      0.988561     SVM-poly-scale-2  \n",
      "48              0.952381          0.952308      0.985663     SVM-poly-scale-2  \n",
      "49              0.927318          0.927316      0.969644     SVM-poly-scale-2  \n",
      "50              0.917500          0.917436      0.982265      SVM-rbf-scale-2  \n",
      "51              0.917500          0.917520      0.970853      SVM-rbf-scale-2  \n",
      "52              0.949875          0.949823      0.988108      SVM-rbf-scale-2  \n",
      "53              0.947368          0.947354      0.985383      SVM-rbf-scale-2  \n",
      "54              0.909774          0.909754      0.964844      SVM-rbf-scale-2  \n",
      "55              0.652500          0.653146      0.728298  SVM-sigmoid-scale-2  \n",
      "56              0.672500          0.672613      0.775716  SVM-sigmoid-scale-2  \n",
      "57              0.696742          0.696780      0.777072  SVM-sigmoid-scale-2  \n",
      "58              0.636591          0.637231      0.766841  SVM-sigmoid-scale-2  \n",
      "59              0.699248          0.698964      0.763985  SVM-sigmoid-scale-2  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-linear-auto-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.96      0.93      0.95       363\n",
      "      benign       0.92      0.96      0.94       303\n",
      "\n",
      "    accuracy                           0.94       666\n",
      "   macro avg       0.94      0.94      0.94       666\n",
      "weighted avg       0.94      0.94      0.94       666\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   46.181343    0.011134       0.942500                 0.942484   \n",
      "1    6.304723    0.009347       0.942500                 0.942634   \n",
      "2   43.386375    0.010828       0.939850                 0.939862   \n",
      "3   25.759007    0.009978       0.944862                 0.944923   \n",
      "4   13.542591    0.008832       0.922306                 0.922311   \n",
      "..        ...         ...            ...                      ...   \n",
      "60  45.901424    0.010624       0.942500                 0.942484   \n",
      "61   6.307388    0.009160       0.942500                 0.942634   \n",
      "62  43.155742    0.010664       0.939850                 0.939862   \n",
      "63  25.684432    0.010112       0.944862                 0.944923   \n",
      "64  13.522271    0.009664       0.922306                 0.922311   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               0.942500          0.942486      0.984359  SVM-linear-scale-1  \n",
      "1               0.942500          0.942514      0.979167  SVM-linear-scale-1  \n",
      "2               0.939850          0.939832      0.977198  SVM-linear-scale-1  \n",
      "3               0.944862          0.944796      0.970842  SVM-linear-scale-1  \n",
      "4               0.922306          0.922303      0.968136  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "60              0.942500          0.942486      0.984359   SVM-linear-auto-2  \n",
      "61              0.942500          0.942514      0.979167   SVM-linear-auto-2  \n",
      "62              0.939850          0.939832      0.977198   SVM-linear-auto-2  \n",
      "63              0.944862          0.944796      0.970842   SVM-linear-auto-2  \n",
      "64              0.922306          0.922303      0.968136   SVM-linear-auto-2  \n",
      "\n",
      "[65 rows x 8 columns]\n",
      "SVM-poly-auto-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.97      0.94      0.96       363\n",
      "      benign       0.93      0.97      0.95       303\n",
      "\n",
      "    accuracy                           0.95       666\n",
      "   macro avg       0.95      0.95      0.95       666\n",
      "weighted avg       0.95      0.95      0.95       666\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   46.181343    0.011134       0.942500                 0.942484   \n",
      "1    6.304723    0.009347       0.942500                 0.942634   \n",
      "2   43.386375    0.010828       0.939850                 0.939862   \n",
      "3   25.759007    0.009978       0.944862                 0.944923   \n",
      "4   13.542591    0.008832       0.922306                 0.922311   \n",
      "..        ...         ...            ...                      ...   \n",
      "65   0.083372    0.014378       0.912500                 0.912968   \n",
      "66   0.077464    0.014755       0.930000                 0.930116   \n",
      "67   0.085998    0.014179       0.947368                 0.947394   \n",
      "68   0.091285    0.014478       0.934837                 0.934837   \n",
      "69   0.085450    0.014077       0.929825                 0.930015   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               0.942500          0.942486      0.984359  SVM-linear-scale-1  \n",
      "1               0.942500          0.942514      0.979167  SVM-linear-scale-1  \n",
      "2               0.939850          0.939832      0.977198  SVM-linear-scale-1  \n",
      "3               0.944862          0.944796      0.970842  SVM-linear-scale-1  \n",
      "4               0.922306          0.922303      0.968136  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "65              0.912500          0.912591      0.973259     SVM-poly-auto-2  \n",
      "66              0.930000          0.929965      0.970252     SVM-poly-auto-2  \n",
      "67              0.947368          0.947375      0.985034     SVM-poly-auto-2  \n",
      "68              0.934837          0.934837      0.979460     SVM-poly-auto-2  \n",
      "69              0.929825          0.929826      0.959014     SVM-poly-auto-2  \n",
      "\n",
      "[70 rows x 8 columns]\n",
      "SVM-rbf-auto-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.61      1.00      0.76       363\n",
      "      benign       1.00      0.24      0.39       303\n",
      "\n",
      "    accuracy                           0.66       666\n",
      "   macro avg       0.81      0.62      0.58       666\n",
      "weighted avg       0.79      0.66      0.59       666\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   46.181343    0.011134       0.942500                 0.942484   \n",
      "1    6.304723    0.009347       0.942500                 0.942634   \n",
      "2   43.386375    0.010828       0.939850                 0.939862   \n",
      "3   25.759007    0.009978       0.944862                 0.944923   \n",
      "4   13.542591    0.008832       0.922306                 0.922311   \n",
      "..        ...         ...            ...                      ...   \n",
      "70   0.259884    0.227668       0.655000                 0.788361   \n",
      "71   0.260453    0.257884       0.670000                 0.798118   \n",
      "72   0.253305    0.237293       0.661654                 0.794050   \n",
      "73   0.257602    0.245082       0.601504                 0.789518   \n",
      "74   0.252234    0.233901       0.619048                 0.784964   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               0.942500          0.942486      0.984359  SVM-linear-scale-1  \n",
      "1               0.942500          0.942514      0.979167  SVM-linear-scale-1  \n",
      "2               0.939850          0.939832      0.977198  SVM-linear-scale-1  \n",
      "3               0.944862          0.944796      0.970842  SVM-linear-scale-1  \n",
      "4               0.922306          0.922303      0.968136  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "70              0.655000          0.590056      0.643154      SVM-rbf-auto-2  \n",
      "71              0.670000          0.623316      0.673615      SVM-rbf-auto-2  \n",
      "72              0.661654          0.608819      0.661565      SVM-rbf-auto-2  \n",
      "73              0.601504          0.551074      0.650376      SVM-rbf-auto-2  \n",
      "74              0.619048          0.557184      0.639041      SVM-rbf-auto-2  \n",
      "\n",
      "[75 rows x 8 columns]\n",
      "SVM-sigmoid-auto-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.55      1.00      0.71       363\n",
      "      benign       0.00      0.00      0.00       303\n",
      "\n",
      "    accuracy                           0.55       666\n",
      "   macro avg       0.27      0.50      0.35       666\n",
      "weighted avg       0.30      0.55      0.38       666\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   46.181343    0.011134       0.942500                 0.942484   \n",
      "1    6.304723    0.009347       0.942500                 0.942634   \n",
      "2   43.386375    0.010828       0.939850                 0.939862   \n",
      "3   25.759007    0.009978       0.944862                 0.944923   \n",
      "4   13.542591    0.008832       0.922306                 0.922311   \n",
      "..        ...         ...            ...                      ...   \n",
      "75   0.227059    0.091461       0.452500                 0.204756   \n",
      "76   0.225473    0.091357       0.520000                 0.270400   \n",
      "77   0.224463    0.091375       0.526316                 0.277008   \n",
      "78   0.215802    0.088098       0.446115                 0.199019   \n",
      "79   0.220964    0.089993       0.493734                 0.243774   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               0.942500          0.942486      0.984359  SVM-linear-scale-1  \n",
      "1               0.942500          0.942514      0.979167  SVM-linear-scale-1  \n",
      "2               0.939850          0.939832      0.977198  SVM-linear-scale-1  \n",
      "3               0.944862          0.944796      0.970842  SVM-linear-scale-1  \n",
      "4               0.922306          0.922303      0.968136  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "75              0.452500          0.281936      0.500000  SVM-sigmoid-auto-2  \n",
      "76              0.520000          0.355789      0.500000  SVM-sigmoid-auto-2  \n",
      "77              0.526316          0.362976      0.500000  SVM-sigmoid-auto-2  \n",
      "78              0.446115          0.275246      0.500000  SVM-sigmoid-auto-2  \n",
      "79              0.493734          0.326395      0.500000  SVM-sigmoid-auto-2  \n",
      "\n",
      "[80 rows x 8 columns]\n",
      "1205.643477513\n"
     ]
    }
   ],
   "source": [
    "## S6: Single compromised (IoT) (Raspberry)\n",
    " \n",
    "df_malicious = pd.concat([df5])\n",
    " \n",
    "df_benign = pd.concat([df8,df9,df10])\n",
    "\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_all_combined_s0 = run_process(df_malicious,df_benign,df_results)\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 47978\n",
      "benign: 47801\n",
      "0 NAN in malicious!\n",
      "0 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 47978\n",
      "benign: 47801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 160/160 [00:09<00:00, 16.86it/s]\n",
      "Feature Extraction: 100%|█████████████████████| 160/160 [00:09<00:00, 16.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let the ml starts\n",
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.92      0.92      0.92      1206\n",
      "      benign       0.92      0.92      0.92      1189\n",
      "\n",
      "    accuracy                           0.92      2395\n",
      "   macro avg       0.92      0.92      0.92      2395\n",
      "weighted avg       0.92      0.92      0.92      2395\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  0.239554    0.021149       0.915101                 0.915147   \n",
      "1  0.202220    0.009345       0.913709                 0.913709   \n",
      "2  0.188308    0.009803       0.905358                 0.905534   \n",
      "3  0.329162    0.009122       0.928323                 0.928429   \n",
      "4  0.259995    0.009196       0.919916                 0.919914   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.915101          0.915108      0.976453  LogReg  \n",
      "1              0.913709          0.913709      0.974774  LogReg  \n",
      "2              0.905358          0.905360      0.966887  LogReg  \n",
      "3              0.928323          0.928321      0.973413  LogReg  \n",
      "4              0.919916          0.919911      0.977326  LogReg  \n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.91      0.92      0.91      1206\n",
      "      benign       0.91      0.91      0.91      1189\n",
      "\n",
      "    accuracy                           0.91      2395\n",
      "   macro avg       0.91      0.91      0.91      2395\n",
      "weighted avg       0.91      0.91      0.91      2395\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  0.239554    0.021149       0.915101                 0.915147   \n",
      "1  0.202220    0.009345       0.913709                 0.913709   \n",
      "2  0.188308    0.009803       0.905358                 0.905534   \n",
      "3  0.329162    0.009122       0.928323                 0.928429   \n",
      "4  0.259995    0.009196       0.919916                 0.919914   \n",
      "5  0.091616    0.502946       0.901183                 0.901193   \n",
      "6  0.005744    0.377867       0.901879                 0.902076   \n",
      "7  0.005781    0.356251       0.897008                 0.897227   \n",
      "8  0.005549    0.364213       0.895616                 0.895776   \n",
      "9  0.005554    0.373682       0.905989                 0.905990   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.915101          0.915108      0.976453  LogReg  \n",
      "1              0.913709          0.913709      0.974774  LogReg  \n",
      "2              0.905358          0.905360      0.966887  LogReg  \n",
      "3              0.928323          0.928321      0.973413  LogReg  \n",
      "4              0.919916          0.919911      0.977326  LogReg  \n",
      "5              0.901183          0.901186      0.959952     KNN  \n",
      "6              0.901879          0.901904      0.959133     KNN  \n",
      "7              0.897008          0.896976      0.956774     KNN  \n",
      "8              0.895616          0.895611      0.952423     KNN  \n",
      "9              0.905989          0.905979      0.959363     KNN  \n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.93      0.90      0.91      1206\n",
      "      benign       0.90      0.93      0.92      1189\n",
      "\n",
      "    accuracy                           0.92      2395\n",
      "   macro avg       0.92      0.92      0.92      2395\n",
      "weighted avg       0.92      0.92      0.92      2395\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.239554    0.021149       0.915101                 0.915147   \n",
      "1   0.202220    0.009345       0.913709                 0.913709   \n",
      "2   0.188308    0.009803       0.905358                 0.905534   \n",
      "3   0.329162    0.009122       0.928323                 0.928429   \n",
      "4   0.259995    0.009196       0.919916                 0.919914   \n",
      "5   0.091616    0.502946       0.901183                 0.901193   \n",
      "6   0.005744    0.377867       0.901879                 0.902076   \n",
      "7   0.005781    0.356251       0.897008                 0.897227   \n",
      "8   0.005549    0.364213       0.895616                 0.895776   \n",
      "9   0.005554    0.373682       0.905989                 0.905990   \n",
      "10  1.506358    1.261569       0.887961                 0.888612   \n",
      "11  1.462340    1.286884       0.899791                 0.899800   \n",
      "12  1.491945    1.272983       0.902575                 0.903063   \n",
      "13  1.483206    1.251711       0.896312                 0.897903   \n",
      "14  1.489936    1.306814       0.900418                 0.900625   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.915101          0.915108      0.976453  LogReg  \n",
      "1               0.913709          0.913709      0.974774  LogReg  \n",
      "2               0.905358          0.905360      0.966887  LogReg  \n",
      "3               0.928323          0.928321      0.973413  LogReg  \n",
      "4               0.919916          0.919911      0.977326  LogReg  \n",
      "5               0.901183          0.901186      0.959952     KNN  \n",
      "6               0.901879          0.901904      0.959133     KNN  \n",
      "7               0.897008          0.896976      0.956774     KNN  \n",
      "8               0.895616          0.895611      0.952423     KNN  \n",
      "9               0.905989          0.905979      0.959363     KNN  \n",
      "10              0.887961          0.887973      0.962898     SVM  \n",
      "11              0.899791          0.899768      0.965747     SVM  \n",
      "12              0.902575          0.902567      0.963475     SVM  \n",
      "13              0.896312          0.896226      0.961219     SVM  \n",
      "14              0.900418          0.900364      0.966068     SVM  \n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      0.97      0.98      1206\n",
      "      benign       0.97      1.00      0.98      1189\n",
      "\n",
      "    accuracy                           0.98      2395\n",
      "   macro avg       0.98      0.98      0.98      2395\n",
      "weighted avg       0.98      0.98      0.98      2395\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.239554    0.021149       0.915101                 0.915147   \n",
      "1   0.202220    0.009345       0.913709                 0.913709   \n",
      "2   0.188308    0.009803       0.905358                 0.905534   \n",
      "3   0.329162    0.009122       0.928323                 0.928429   \n",
      "4   0.259995    0.009196       0.919916                 0.919914   \n",
      "5   0.091616    0.502946       0.901183                 0.901193   \n",
      "6   0.005744    0.377867       0.901879                 0.902076   \n",
      "7   0.005781    0.356251       0.897008                 0.897227   \n",
      "8   0.005549    0.364213       0.895616                 0.895776   \n",
      "9   0.005554    0.373682       0.905989                 0.905990   \n",
      "10  1.506358    1.261569       0.887961                 0.888612   \n",
      "11  1.462340    1.286884       0.899791                 0.899800   \n",
      "12  1.491945    1.272983       0.902575                 0.903063   \n",
      "13  1.483206    1.251711       0.896312                 0.897903   \n",
      "14  1.489936    1.306814       0.900418                 0.900625   \n",
      "15  0.025407    0.010559       0.988866                 0.989114   \n",
      "16  0.018460    0.009968       0.987474                 0.987769   \n",
      "17  0.020993    0.010139       0.985386                 0.985806   \n",
      "18  0.024392    0.010206       0.981907                 0.982542   \n",
      "19  0.019510    0.010093       0.986072                 0.986440   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.915101          0.915108      0.976453  LogReg  \n",
      "1               0.913709          0.913709      0.974774  LogReg  \n",
      "2               0.905358          0.905360      0.966887  LogReg  \n",
      "3               0.928323          0.928321      0.973413  LogReg  \n",
      "4               0.919916          0.919911      0.977326  LogReg  \n",
      "5               0.901183          0.901186      0.959952     KNN  \n",
      "6               0.901879          0.901904      0.959133     KNN  \n",
      "7               0.897008          0.896976      0.956774     KNN  \n",
      "8               0.895616          0.895611      0.952423     KNN  \n",
      "9               0.905989          0.905979      0.959363     KNN  \n",
      "10              0.887961          0.887973      0.962898     SVM  \n",
      "11              0.899791          0.899768      0.965747     SVM  \n",
      "12              0.902575          0.902567      0.963475     SVM  \n",
      "13              0.896312          0.896226      0.961219     SVM  \n",
      "14              0.900418          0.900364      0.966068     SVM  \n",
      "15              0.988866          0.988867      0.997962     GNB  \n",
      "16              0.987474          0.987466      0.996387     GNB  \n",
      "17              0.985386          0.985386      0.992435     GNB  \n",
      "18              0.981907          0.981902      0.993075     GNB  \n",
      "19              0.986072          0.986064      0.994986     GNB  \n",
      "60.72462756797904\n"
     ]
    }
   ],
   "source": [
    "## S7: IoT compromised (IoT + IoT)\n",
    " \n",
    "df_malicious = pd.concat([df1,df34])\n",
    " \n",
    "df_benign = pd.concat([df8,df9,df10,df11,df12,df21])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_all_combined_s0 = run_process(df_malicious,df_benign,df_results)\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nectar-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
