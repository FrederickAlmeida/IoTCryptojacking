{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c62b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rodou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tsfresh\n",
    "import os\n",
    "import json\n",
    "import scapy\n",
    "import numpy as np\n",
    "import warnings\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from scapy.all import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") #ignore warnings caused by \n",
    "\n",
    "\n",
    "#################################################################\n",
    "#                                                               #\n",
    "#               malicious csv files import                      #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "\n",
    "df1 = pd.read_csv('../Data/malicious/WebOS_binary.csv') #\n",
    "df2 = pd.read_csv('../Data/malicious/Server_Binary.csv') #\n",
    "df3 = pd.read_csv('../Data/malicious/Raspberry_Webmine_Robust.csv')\n",
    "df4 = pd.read_csv('../Data/malicious/Raspberry_Binary.csv') #\n",
    "df5 = pd.read_csv('../Data/malicious/Raspberry_Webmine_Aggressive.csv')\n",
    "df6 = pd.read_csv('../Data/malicious/Raspberry_WebminePool_Aggressive.csv')\n",
    "df7 = pd.read_csv('../Data/malicious/Server_WebminePool_Aggressive.csv') #\n",
    "df32 = pd.read_csv('../Data/malicious/Server_WebminePool_Robust.csv') #\n",
    "df33 = pd.read_csv('../Data/malicious/Raspberry_WebminePool_Stealthy.csv') #\n",
    "df34 = pd.read_csv('../Data/malicious/Raspberry_WebminePool_Robust.csv') #\n",
    "df35 = pd.read_csv('../Data/malicious/Desktop_WebminePool_Aggressive.csv') #\n",
    "\n",
    "\n",
    "#################################################################\n",
    "#                                                               #\n",
    "#               benign-1 csv files import                         #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "df8 = pd.read_csv('../Data/benign-1/interactive_01.csv') #\n",
    "df9 = pd.read_csv('../Data/benign-1/interactive_02.csv') #\n",
    "df10 = pd.read_csv('../Data/benign-1/interactive_03.csv') #\n",
    "df11 = pd.read_csv('../Data/benign-1/interactive_04.csv') #\n",
    "df12 = pd.read_csv('../Data/benign-1/interactive_05.csv') #\n",
    "df13 = pd.read_csv('../Data/benign-1/interactive_06.csv') #\n",
    "df14 = pd.read_csv('../Data/benign-1/web_1page_01.csv') #\n",
    "df15 = pd.read_csv('../Data/benign-1/web_1page_02.csv') #\n",
    "df16 = pd.read_csv('../Data/benign-1/web_1page_03.csv') #\n",
    "df17 = pd.read_csv('../Data/benign-1/web_1page_04.csv') #\n",
    "df18 = pd.read_csv('../Data/benign-1/web_1page_05.csv') #\n",
    "df19 = pd.read_csv('../Data/benign-1/bulk_xs_04.csv') #\n",
    "df20 = pd.read_csv('../Data/benign-1/bulk_xs_05.csv') #\n",
    "df21 = pd.read_csv('../Data/benign-1/video_180s480p_01.csv') #\n",
    "df22 = pd.read_csv('../Data/benign-1/video_180s480p_02.csv') #\n",
    "df23 = pd.read_csv('../Data/benign-1/video_x1_04.csv') #\n",
    "df24 = pd.read_csv('../Data/benign-1/web_multiple_04.csv') #\n",
    "df25 = pd.read_csv('../Data/benign-1/bulk_xs_01.csv') #\n",
    "df26 = pd.read_csv('../Data/benign-1/bulk_xs_09.csv') #\n",
    "df27 = pd.read_csv('../Data/benign-1/bulk_xs_06.csv') #\n",
    "df28 = pd.read_csv('../Data/benign-1/bulk_xs_03.csv') #\n",
    "df29 = pd.read_csv('../Data/benign-1/web_multiple_03.csv') #\n",
    "df30 = pd.read_csv('../Data/benign-1/web_multiple_05.csv') #\n",
    "df31 = pd.read_csv('../Data/benign-1/web_multiple_06.csv') #\n",
    "\n",
    "df_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 -->> 43173\n",
      "df2 -->> 1213354\n",
      "df3 -->> 3621\n",
      "df4 -->> 22111\n",
      "df5 -->> 14156\n",
      "df6 -->> 24476\n",
      "df7 -->> 3106\n",
      "df32 -->> 18460\n",
      "df33 -->> 10285\n",
      "df34 -->> 7708\n",
      "df35 -->> 234892\n",
      "/////////////////////////////////////////////////\n",
      "df8 -->> 4550\n",
      "df9 -->> 3869\n",
      "df10 -->> 5327\n",
      "df11 -->> 4727\n",
      "df12 -->> 4190\n",
      "df13 -->> 3481\n",
      "df14 -->> 38576\n",
      "df15 -->> 5961\n",
      "df16 -->> 1803\n",
      "df17 -->> 7029\n",
      "df18 -->> 1012\n",
      "df19 -->> 96545\n",
      "df20 -->> 108065\n",
      "df21 -->> 25138\n",
      "df22 -->> 91274\n",
      "df23 -->> 23597\n",
      "df24 -->> 59635\n",
      "df25 -->> 625216\n",
      "df26 -->> 266935\n",
      "df27 -->> 453471\n",
      "df28 -->> 654495\n",
      "df29 -->> 6764\n",
      "df30 -->> 25300\n",
      "df31 -->> 3689\n"
     ]
    }
   ],
   "source": [
    "print(\"df1 -->> {}\".format(len(df1)))\n",
    "print(\"df2 -->> {}\".format(len(df2)))\n",
    "print(\"df3 -->> {}\".format(len(df3)))\n",
    "print(\"df4 -->> {}\".format(len(df4)))\n",
    "print(\"df5 -->> {}\".format(len(df5)))\n",
    "print(\"df6 -->> {}\".format(len(df6)))\n",
    "print(\"df7 -->> {}\".format(len(df7)))\n",
    "print(\"df32 -->> {}\".format(len(df32)))\n",
    "print(\"df33 -->> {}\".format(len(df33)))\n",
    "print(\"df34 -->> {}\".format(len(df34)))\n",
    "print(\"df35 -->> {}\".format(len(df35)))\n",
    "print(\"/////////////////////////////////////////////////\")\n",
    "\n",
    "\n",
    "print(\"df8 -->> {}\".format(len(df8)))\n",
    "print(\"df9 -->> {}\".format(len(df9)))\n",
    "print(\"df10 -->> {}\".format(len(df10)))\n",
    "print(\"df11 -->> {}\".format(len(df11)))\n",
    "print(\"df12 -->> {}\".format(len(df12)))\n",
    "print(\"df13 -->> {}\".format(len(df13)))\n",
    "print(\"df14 -->> {}\".format(len(df14)))\n",
    "print(\"df15 -->> {}\".format(len(df15)))\n",
    "print(\"df16 -->> {}\".format(len(df16)))\n",
    "print(\"df17 -->> {}\".format(len(df17)))\n",
    "print(\"df18 -->> {}\".format(len(df18)))\n",
    "print(\"df19 -->> {}\".format(len(df19)))\n",
    "print(\"df20 -->> {}\".format(len(df20)))\n",
    "print(\"df21 -->> {}\".format(len(df21)))\n",
    "print(\"df22 -->> {}\".format(len(df22)))\n",
    "print(\"df23 -->> {}\".format(len(df23)))\n",
    "print(\"df24 -->> {}\".format(len(df24)))\n",
    "print(\"df25 -->> {}\".format(len(df25)))\n",
    "print(\"df26 -->> {}\".format(len(df26)))\n",
    "print(\"df27 -->> {}\".format(len(df27)))\n",
    "print(\"df28 -->> {}\".format(len(df28)))\n",
    "print(\"df29 -->> {}\".format(len(df29)))\n",
    "print(\"df30 -->> {}\".format(len(df30)))\n",
    "print(\"df31 -->> {}\".format(len(df31)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#                                                               #\n",
    "#                     Filtering                                 #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "# For WebOS = 18:56:80:17:d0:ef\n",
    "index_names = df1[((df1['HW_dst'] != '18:56:80:17:d0:ef') & (df1['Hw_src'] != '18:56:80:17:d0:ef'))].index\n",
    "df1.drop(index_names, inplace = True)\n",
    "\n",
    "# Big_Server_Monero_mining_data = a4:bb:6d:ac:e1:fd\n",
    "\n",
    "index_names = df2[((df2['HW_dst'] != 'a4:bb:6d:ac:e1:fd') & (df2['Hw_src'] != 'a4:bb:6d:ac:e1:fd'))].index\n",
    "df2.drop(index_names, inplace = True)\n",
    "\n",
    "# ege_data_rasberry = dc:a6:32:67:66:4b\t\n",
    "\n",
    "index_names = df3[((df3['HW_dst'] != 'dc:a6:32:67:66:4b') & (df3['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df3.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_binary_monero_mining = dc:a6:32:68:35:8a\n",
    "\n",
    "index_names = df4[((df4['HW_dst'] != 'dc:a6:32:68:35:8a') & (df4['Hw_src'] != 'dc:a6:32:68:35:8a'))].index\n",
    "df4.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_network_data_2 = dc:a6:32:67:66:4b\n",
    "\n",
    "index_names = df5[((df5['HW_dst'] != 'dc:a6:32:67:66:4b') & (df5['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df5.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry-Webmine = dc:a6:32:67:66:4b\n",
    "index_names = df6[((df6['HW_dst'] != 'dc:a6:32:67:66:4b') & (df6['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df6.drop(index_names, inplace = True)\n",
    "\n",
    "# Server_Webmine_Network_data = a4:bb:6d:ac:e1:fd\n",
    "\n",
    "index_names = df7[((df7['HW_dst'] != 'a4:bb:6d:ac:e1:fd') & (df7['Hw_src'] != 'a4:bb:6d:ac:e1:fd'))].index\n",
    "df7.drop(index_names, inplace = True)\n",
    "\n",
    "# Server_%50_Mining = a4:bb:6d:ac:e1:fd\n",
    "\n",
    "index_names = df32[((df32['HW_dst'] != 'a4:bb:6d:ac:e1:fd') & (df32['Hw_src'] != 'a4:bb:6d:ac:e1:fd'))].index\n",
    "df32.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_webmine_%10 = dc:a6:32:67:66:4b\n",
    "\n",
    "index_names = df33[((df33['HW_dst'] != 'dc:a6:32:67:66:4b') & (df33['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df33.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_webmine_%50 = dc:a6:32:68:35:8a\n",
    "\n",
    "index_names = df34[((df34['HW_dst'] != 'dc:a6:32:68:35:8a') & (df34['Hw_src'] != 'dc:a6:32:68:35:8a'))].index\n",
    "df34.drop(index_names, inplace = True)\n",
    "\n",
    "# Desktop_Webmine_%100 = dc:a6:32:68:35:8a\n",
    "\n",
    "index_names = df35[((df35['HW_dst'] != 'd8:3b:bf:8f:ba:ba') & (df35['Hw_src'] != 'd8:3b:bf:8f:ba:ba'))].index\n",
    "df35.drop(index_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#                                                               #\n",
    "#      Labeling Features for further calculations               #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "df1.insert(7, \"Is_malicious\", 1)\n",
    "df2.insert(7, \"Is_malicious\", 1)\n",
    "df3.insert(7, \"Is_malicious\", 1)\n",
    "df4.insert(7, \"Is_malicious\", 1)\n",
    "df5.insert(7, \"Is_malicious\", 1)\n",
    "df6.insert(7, \"Is_malicious\", 1)\n",
    "df7.insert(7, \"Is_malicious\", 1)\n",
    "\n",
    "# ========================================================\n",
    "\n",
    "df8.insert(7, \"Is_malicious\", 0)\n",
    "df9.insert(7, \"Is_malicious\", 0)\n",
    "df10.insert(7, \"Is_malicious\", 0)\n",
    "df11.insert(7, \"Is_malicious\", 0)\n",
    "df12.insert(7, \"Is_malicious\", 0)\n",
    "df13.insert(7, \"Is_malicious\", 0)\n",
    "df14.insert(7, \"Is_malicious\", 0)\n",
    "df15.insert(7, \"Is_malicious\", 0)\n",
    "df16.insert(7, \"Is_malicious\", 0)\n",
    "df17.insert(7, \"Is_malicious\", 0)\n",
    "df18.insert(7, \"Is_malicious\", 0)\n",
    "df19.insert(7, \"Is_malicious\", 0)\n",
    "df20.insert(7, \"Is_malicious\", 0)\n",
    "df21.insert(7, \"Is_malicious\", 0)\n",
    "df22.insert(7, \"Is_malicious\", 0)\n",
    "df23.insert(7, \"Is_malicious\", 0)\n",
    "df24.insert(7, \"Is_malicious\", 0)\n",
    "\n",
    "\n",
    "# ========================================================\n",
    "\n",
    "df25.insert(7, \"Is_malicious\", 0)\n",
    "df26.insert(7, \"Is_malicious\", 0)\n",
    "df27.insert(7, \"Is_malicious\", 0)\n",
    "df28.insert(7, \"Is_malicious\", 0)\n",
    "df29.insert(7, \"Is_malicious\", 0)\n",
    "df30.insert(7, \"Is_malicious\", 0)\n",
    "df31.insert(7, \"Is_malicious\", 0)\n",
    "\n",
    "df32.insert(7, \"Is_malicious\", 1)\n",
    "df33.insert(7, \"Is_malicious\", 1)\n",
    "df34.insert(7, \"Is_malicious\", 1)\n",
    "df35.insert(7, \"Is_malicious\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 -->> 41572\n",
      "df2 -->> 1198039\n",
      "df3 -->> 3519\n",
      "df4 -->> 11745\n",
      "df5 -->> 12871\n",
      "df6 -->> 19643\n",
      "df7 -->> 2539\n",
      "df8 -->> 4550\n",
      "df9 -->> 3869\n",
      "df10 -->> 5327\n",
      "df11 -->> 4727\n",
      "df12 -->> 4190\n",
      "df13 -->> 3481\n",
      "df14 -->> 38576\n",
      "df15 -->> 5961\n",
      "df16 -->> 1803\n",
      "df17 -->> 7029\n",
      "df18 -->> 1012\n",
      "df19 -->> 96545\n",
      "df20 -->> 108065\n",
      "df21 -->> 25138\n",
      "df22 -->> 91274\n",
      "df23 -->> 23597\n",
      "df24 -->> 59619\n",
      "df25 -->> 625194\n",
      "df26 -->> 266935\n",
      "df27 -->> 453466\n",
      "df28 -->> 654479\n",
      "df29 -->> 6764\n",
      "df30 -->> 25288\n",
      "df31 -->> 3689\n",
      "df32 -->> 16744\n",
      "df33 -->> 9880\n",
      "df34 -->> 6406\n",
      "df35 -->> 234272\n"
     ]
    }
   ],
   "source": [
    "print(\"df1 -->> {}\".format(len(df1.dropna())))\n",
    "print(\"df2 -->> {}\".format(len(df2.dropna())))\n",
    "print(\"df3 -->> {}\".format(len(df3.dropna())))\n",
    "print(\"df4 -->> {}\".format(len(df4.dropna())))\n",
    "print(\"df5 -->> {}\".format(len(df5.dropna())))\n",
    "print(\"df6 -->> {}\".format(len(df6.dropna())))\n",
    "print(\"df7 -->> {}\".format(len(df7.dropna())))\n",
    "print(\"df8 -->> {}\".format(len(df8.dropna())))\n",
    "print(\"df9 -->> {}\".format(len(df9.dropna())))\n",
    "print(\"df10 -->> {}\".format(len(df10.dropna())))\n",
    "print(\"df11 -->> {}\".format(len(df11.dropna())))\n",
    "print(\"df12 -->> {}\".format(len(df12.dropna())))\n",
    "print(\"df13 -->> {}\".format(len(df13.dropna())))\n",
    "print(\"df14 -->> {}\".format(len(df14.dropna())))\n",
    "print(\"df15 -->> {}\".format(len(df15.dropna())))\n",
    "print(\"df16 -->> {}\".format(len(df16.dropna())))\n",
    "print(\"df17 -->> {}\".format(len(df17.dropna())))\n",
    "print(\"df18 -->> {}\".format(len(df18.dropna())))\n",
    "print(\"df19 -->> {}\".format(len(df19.dropna())))\n",
    "print(\"df20 -->> {}\".format(len(df20.dropna())))\n",
    "print(\"df21 -->> {}\".format(len(df21.dropna())))\n",
    "print(\"df22 -->> {}\".format(len(df22.dropna())))\n",
    "print(\"df23 -->> {}\".format(len(df23.dropna())))\n",
    "print(\"df24 -->> {}\".format(len(df24.dropna())))\n",
    "print(\"df25 -->> {}\".format(len(df25.dropna())))\n",
    "print(\"df26 -->> {}\".format(len(df26.dropna())))\n",
    "print(\"df27 -->> {}\".format(len(df27.dropna())))\n",
    "print(\"df28 -->> {}\".format(len(df28.dropna())))\n",
    "print(\"df29 -->> {}\".format(len(df29.dropna())))\n",
    "print(\"df30 -->> {}\".format(len(df30.dropna())))\n",
    "print(\"df31 -->> {}\".format(len(df31.dropna())))\n",
    "print(\"df32 -->> {}\".format(len(df32.dropna())))\n",
    "print(\"df33 -->> {}\".format(len(df33.dropna())))\n",
    "print(\"df34 -->> {}\".format(len(df34.dropna())))\n",
    "print(\"df35 -->> {}\".format(len(df35.dropna())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_process(a,b,x):\n",
    "    \n",
    "    df_malicious = a.copy()\n",
    "    df_benign    = b.copy()\n",
    "    \n",
    "    from tsfresh import extract_features, select_features\n",
    "    from tsfresh.utilities.dataframe_functions import impute\n",
    "    from tsfresh import extract_features\n",
    "    from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "\n",
    "\n",
    "    df_malicious.reset_index(drop=True, inplace=True) #reset index\n",
    "    df_malicious['id']= np.floor(df_malicious.index.array/10)\n",
    "    df_benign.reset_index(drop=True, inplace=True) #reset index\n",
    "    df_benign['id']= np.floor(df_benign.index.array/10)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    tf1=tsfresh.extract_features(df_malicious,impute_function=impute, column_kind='Is_malicious',\n",
    "                                 column_id='id',column_sort=\"Time\",column_value = \"Length\")\n",
    "    tf1['class']= 1\n",
    "\n",
    "    \n",
    "    \n",
    "    tf2=tsfresh.extract_features(df_benign,impute_function=impute, column_kind='Is_malicious',\n",
    "                                 column_id='id',column_sort=\"Time\",column_value = \"Length\")\n",
    "    tf2['class']= 0\n",
    "\n",
    "\n",
    "    tf2.columns = tf1.columns\n",
    "\n",
    "    features=pd.concat([tf1,tf2])\n",
    "\n",
    "\n",
    "    features2 = features.copy()\n",
    "    features2.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    y = pd.Series(data = features2['class'], index=features2.index)\n",
    "    \n",
    "    from tsfresh.examples import load_robot_execution_failures\n",
    "    from tsfresh import extract_features, select_features\n",
    "    from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "\n",
    "    relevance_table = calculate_relevance_table(features2, y)\n",
    "    relevance_table = relevance_table[relevance_table.relevant]\n",
    "    relevance_table.sort_values(\"p_value\", inplace=True)\n",
    "\n",
    "    relevance_table\n",
    "    \n",
    "    best_features = relevance_table[relevance_table['p_value'] <= 0.05]\n",
    "\n",
    "    df_ML = pd.DataFrame()\n",
    "\n",
    "    for pkt in best_features:\n",
    "        df_ML[best_features.feature] = features[best_features.feature]\n",
    "\n",
    "    final = ML_Process(df_ML,x)\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_Process(df_ML,x):\n",
    "    df_results = x.copy() \n",
    "    print('let the ml starts')\n",
    "  \n",
    "    from sklearn import neighbors, metrics\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    #X = df_finalized[['Time', 'Length','Protocol']].values\n",
    "    X = df_ML.drop('class',axis=1).to_numpy()\n",
    "    #y = df_finalized[['Is_malicious']]\n",
    "    y = df_ML['class'].to_numpy()\n",
    "\n",
    "\n",
    "    #print(X,y)\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    Le = LabelEncoder()\n",
    "    for i in range(len(X[0])):\n",
    "        X[:, i] = Le.fit_transform(X[:, i])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=8675309)\n",
    "\n",
    "    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    #from xgboost import XGBClassifier\n",
    "    from sklearn import model_selection\n",
    "    from sklearn.utils import class_weight\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    y_train = y_train.ravel()\n",
    "    dfs = []\n",
    "    models = [\n",
    "        ('SVM-linear-scale-1', SVC(C = 1, kernel = 'linear',gamma ='scale')),\n",
    "        ('SVM-poly-scale-1', SVC(C = 1, kernel = 'poly',gamma ='scale')),\n",
    "        ('SVM-rbf-scale-1', SVC(C = 1, kernel = 'rbf',gamma ='scale')),\n",
    "        ('SVM-sigmoid-scale-1', SVC(C = 1, kernel = 'sigmoid',gamma ='scale')),\n",
    "        ('SVM-linear-auto-1', SVC(C = 1, kernel = 'linear',gamma ='auto')),\n",
    "        ('SVM-poly-auto-1', SVC(C = 1, kernel = 'poly',gamma ='auto')),\n",
    "        ('SVM-rbf-auto-1', SVC(C = 1, kernel = 'rbf',gamma ='auto')),\n",
    "        ('SVM-sigmoid-auto-1', SVC(C = 1, kernel = 'sigmoid',gamma ='auto')),\n",
    "        ('SVM-linear-scale-2', SVC(C = 2, kernel = 'linear',gamma ='scale')),\n",
    "        ('SVM-poly-scale-2', SVC(C = 2, kernel = 'poly',gamma ='scale')),\n",
    "        ('SVM-rbf-scale-2', SVC(C = 2, kernel = 'rbf',gamma ='scale')),\n",
    "        ('SVM-sigmoid-scale-2', SVC(C = 2, kernel = 'sigmoid',gamma ='scale')),\n",
    "        ('SVM-linear-auto-2', SVC(C = 2, kernel = 'linear',gamma ='auto')),\n",
    "        ('SVM-poly-auto-2', SVC(C = 2, kernel = 'poly',gamma ='auto')),\n",
    "        ('SVM-rbf-auto-2', SVC(C = 2, kernel = 'rbf',gamma ='auto')),\n",
    "        ('SVM-sigmoid-auto-2', SVC(C = 2, kernel = 'sigmoid',gamma ='auto'))\n",
    "            ]\n",
    "    results = []\n",
    "    names = []\n",
    "    scoring = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted', 'roc_auc']\n",
    "    target_names = ['malignant', 'benign']\n",
    "    for name, model in models:\n",
    "        kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state=90210)\n",
    "        cv_results = model_selection.cross_validate(model, X_train, y_train, cv=kfold, \n",
    "                                                    scoring=scoring)\n",
    "\n",
    "        clf = model.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(name)\n",
    "        print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        this_df = pd.DataFrame(cv_results)\n",
    "        this_df['model'] = name\n",
    "        dfs.append(this_df)\n",
    "        final = pd.concat(dfs, ignore_index=True)\n",
    "        print(final)\n",
    "\n",
    "    return(final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 9880\n",
      "benign: 9877\n",
      "0 NAN in malicious!\n",
      "0 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 9880\n",
      "benign: 9877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 142/142 [00:02<00:00, 57.16it/s]\n",
      "Feature Extraction: 100%|█████████████████████| 142/142 [00:03<00:00, 45.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let the ml starts\n",
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.95      0.94      0.94       246\n",
      "      benign       0.94      0.95      0.95       248\n",
      "\n",
      "    accuracy                           0.95       494\n",
      "   macro avg       0.95      0.95      0.95       494\n",
      "weighted avg       0.95      0.95      0.95       494\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  2.149490    0.025123       0.946128                 0.946370   \n",
      "1  2.106410    0.024873       0.929293                 0.929521   \n",
      "2  1.992329    0.022448       0.922297                 0.922481   \n",
      "3  2.070526    0.024539       0.918919                 0.920032   \n",
      "4  2.010084    0.028977       0.932432                 0.932872   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.946128          0.946076      0.981756  LogReg  \n",
      "1              0.929293          0.929312      0.976433  LogReg  \n",
      "2              0.922297          0.922295      0.967721  LogReg  \n",
      "3              0.918919          0.918800      0.977111  LogReg  \n",
      "4              0.932432          0.932482      0.983352  LogReg  \n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.89      0.93      0.91       246\n",
      "      benign       0.92      0.88      0.90       248\n",
      "\n",
      "    accuracy                           0.90       494\n",
      "   macro avg       0.91      0.90      0.90       494\n",
      "weighted avg       0.91      0.90      0.90       494\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  2.149490    0.025123       0.946128                 0.946370   \n",
      "1  2.106410    0.024873       0.929293                 0.929521   \n",
      "2  1.992329    0.022448       0.922297                 0.922481   \n",
      "3  2.070526    0.024539       0.918919                 0.920032   \n",
      "4  2.010084    0.028977       0.932432                 0.932872   \n",
      "5  0.002548    0.129716       0.898990                 0.899125   \n",
      "6  0.013734    0.110155       0.898990                 0.902239   \n",
      "7  0.013690    0.113376       0.898649                 0.902187   \n",
      "8  0.013814    0.108723       0.902027                 0.902063   \n",
      "9  0.013720    0.110766       0.925676                 0.927191   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.946128          0.946076      0.981756  LogReg  \n",
      "1              0.929293          0.929312      0.976433  LogReg  \n",
      "2              0.922297          0.922295      0.967721  LogReg  \n",
      "3              0.918919          0.918800      0.977111  LogReg  \n",
      "4              0.932432          0.932482      0.983352  LogReg  \n",
      "5              0.898990          0.898893      0.960601     KNN  \n",
      "6              0.898990          0.898586      0.953751     KNN  \n",
      "7              0.898649          0.898389      0.968886     KNN  \n",
      "8              0.902027          0.902035      0.960618     KNN  \n",
      "9              0.925676          0.925757      0.968951     KNN  \n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.92      0.91      0.91       246\n",
      "      benign       0.91      0.92      0.92       248\n",
      "\n",
      "    accuracy                           0.91       494\n",
      "   macro avg       0.92      0.91      0.91       494\n",
      "weighted avg       0.92      0.91      0.91       494\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   2.149490    0.025123       0.946128                 0.946370   \n",
      "1   2.106410    0.024873       0.929293                 0.929521   \n",
      "2   1.992329    0.022448       0.922297                 0.922481   \n",
      "3   2.070526    0.024539       0.918919                 0.920032   \n",
      "4   2.010084    0.028977       0.932432                 0.932872   \n",
      "5   0.002548    0.129716       0.898990                 0.899125   \n",
      "6   0.013734    0.110155       0.898990                 0.902239   \n",
      "7   0.013690    0.113376       0.898649                 0.902187   \n",
      "8   0.013814    0.108723       0.902027                 0.902063   \n",
      "9   0.013720    0.110766       0.925676                 0.927191   \n",
      "10  0.086445    0.064985       0.909091                 0.909074   \n",
      "11  0.076233    0.070466       0.902357                 0.902448   \n",
      "12  0.081925    0.075589       0.939189                 0.939189   \n",
      "13  0.079425    0.075281       0.881757                 0.881849   \n",
      "14  0.079255    0.069825       0.922297                 0.922957   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.946128          0.946076      0.981756  LogReg  \n",
      "1               0.929293          0.929312      0.976433  LogReg  \n",
      "2               0.922297          0.922295      0.967721  LogReg  \n",
      "3               0.918919          0.918800      0.977111  LogReg  \n",
      "4               0.932432          0.932482      0.983352  LogReg  \n",
      "5               0.898990          0.898893      0.960601     KNN  \n",
      "6               0.898990          0.898586      0.953751     KNN  \n",
      "7               0.898649          0.898389      0.968886     KNN  \n",
      "8               0.902027          0.902035      0.960618     KNN  \n",
      "9               0.925676          0.925757      0.968951     KNN  \n",
      "10              0.909091          0.909072      0.971383     SVM  \n",
      "11              0.902357          0.902310      0.974071     SVM  \n",
      "12              0.939189          0.939189      0.983518     SVM  \n",
      "13              0.881757          0.881712      0.963907     SVM  \n",
      "14              0.922297          0.922364      0.983948     SVM  \n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      0.99      1.00       246\n",
      "      benign       0.99      1.00      1.00       248\n",
      "\n",
      "    accuracy                           1.00       494\n",
      "   macro avg       1.00      1.00      1.00       494\n",
      "weighted avg       1.00      1.00      1.00       494\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   2.149490    0.025123       0.946128                 0.946370   \n",
      "1   2.106410    0.024873       0.929293                 0.929521   \n",
      "2   1.992329    0.022448       0.922297                 0.922481   \n",
      "3   2.070526    0.024539       0.918919                 0.920032   \n",
      "4   2.010084    0.028977       0.932432                 0.932872   \n",
      "5   0.002548    0.129716       0.898990                 0.899125   \n",
      "6   0.013734    0.110155       0.898990                 0.902239   \n",
      "7   0.013690    0.113376       0.898649                 0.902187   \n",
      "8   0.013814    0.108723       0.902027                 0.902063   \n",
      "9   0.013720    0.110766       0.925676                 0.927191   \n",
      "10  0.086445    0.064985       0.909091                 0.909074   \n",
      "11  0.076233    0.070466       0.902357                 0.902448   \n",
      "12  0.081925    0.075589       0.939189                 0.939189   \n",
      "13  0.079425    0.075281       0.881757                 0.881849   \n",
      "14  0.079255    0.069825       0.922297                 0.922957   \n",
      "15  0.004969    0.005522       1.000000                 1.000000   \n",
      "16  0.003756    0.005292       1.000000                 1.000000   \n",
      "17  0.003548    0.005319       1.000000                 1.000000   \n",
      "18  0.003652    0.005286       1.000000                 1.000000   \n",
      "19  0.003677    0.005359       1.000000                 1.000000   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.946128          0.946076      0.981756  LogReg  \n",
      "1               0.929293          0.929312      0.976433  LogReg  \n",
      "2               0.922297          0.922295      0.967721  LogReg  \n",
      "3               0.918919          0.918800      0.977111  LogReg  \n",
      "4               0.932432          0.932482      0.983352  LogReg  \n",
      "5               0.898990          0.898893      0.960601     KNN  \n",
      "6               0.898990          0.898586      0.953751     KNN  \n",
      "7               0.898649          0.898389      0.968886     KNN  \n",
      "8               0.902027          0.902035      0.960618     KNN  \n",
      "9               0.925676          0.925757      0.968951     KNN  \n",
      "10              0.909091          0.909072      0.971383     SVM  \n",
      "11              0.902357          0.902310      0.974071     SVM  \n",
      "12              0.939189          0.939189      0.983518     SVM  \n",
      "13              0.881757          0.881712      0.963907     SVM  \n",
      "14              0.922297          0.922364      0.983948     SVM  \n",
      "15              1.000000          1.000000      1.000000     GNB  \n",
      "16              1.000000          1.000000      1.000000     GNB  \n",
      "17              1.000000          1.000000      1.000000     GNB  \n",
      "18              1.000000          1.000000      1.000000     GNB  \n",
      "19              1.000000          1.000000      1.000000     GNB  \n",
      "29.746887399989646\n"
     ]
    }
   ],
   "source": [
    "# Scenario 2; Throttles\n",
    "    \n",
    "    # 1) THR: %10 (Stealthy)\n",
    "\n",
    "df_malicious = pd.concat([df33])\n",
    "df_benign = pd.concat([df8,df10])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_THR_10_s2 = run_process(df_malicious,df_benign,df_results)\n",
    "\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26868f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rodou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 9925\n",
      "benign: 10453\n",
      "0 NAN in malicious!\n",
      "0 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 9925\n",
      "benign: 10453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 142/142 [00:02<00:00, 70.03it/s]\n",
      "Feature Extraction: 100%|█████████████████████| 150/150 [00:02<00:00, 72.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let the ml starts\n",
      "SVM-linear-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      1.00      1.00       264\n",
      "      benign       1.00      1.00      1.00       246\n",
      "\n",
      "    accuracy                           1.00       510\n",
      "   macro avg       1.00      1.00      1.00       510\n",
      "weighted avg       1.00      1.00      1.00       510\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  0.159152    0.008241            1.0                      1.0   \n",
      "1  0.066759    0.007451            1.0                      1.0   \n",
      "2  0.166499    0.007725            1.0                      1.0   \n",
      "3  0.162189    0.006943            1.0                      1.0   \n",
      "4  0.108057    0.007698            1.0                      1.0   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0                   1.0               1.0           1.0  SVM-linear-scale-1  \n",
      "1                   1.0               1.0           1.0  SVM-linear-scale-1  \n",
      "2                   1.0               1.0           1.0  SVM-linear-scale-1  \n",
      "3                   1.0               1.0           1.0  SVM-linear-scale-1  \n",
      "4                   1.0               1.0           1.0  SVM-linear-scale-1  \n",
      "SVM-poly-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.86      0.81      0.83       264\n",
      "      benign       0.81      0.86      0.83       246\n",
      "\n",
      "    accuracy                           0.83       510\n",
      "   macro avg       0.83      0.83      0.83       510\n",
      "weighted avg       0.83      0.83      0.83       510\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  0.159152    0.008241       1.000000                 1.000000   \n",
      "1  0.066759    0.007451       1.000000                 1.000000   \n",
      "2  0.166499    0.007725       1.000000                 1.000000   \n",
      "3  0.162189    0.006943       1.000000                 1.000000   \n",
      "4  0.108057    0.007698       1.000000                 1.000000   \n",
      "5  0.093857    0.032366       0.803922                 0.804398   \n",
      "6  0.092993    0.033614       0.823529                 0.825977   \n",
      "7  0.093297    0.035702       0.830065                 0.838691   \n",
      "8  0.091128    0.032552       0.800654                 0.800726   \n",
      "9  0.094834    0.033950       0.822951                 0.832710   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0              1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "1              1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "2              1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "3              1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "4              1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "5              0.803922          0.804022      0.873806    SVM-poly-scale-1  \n",
      "6              0.823529          0.823484      0.911692    SVM-poly-scale-1  \n",
      "7              0.830065          0.830065      0.917554    SVM-poly-scale-1  \n",
      "8              0.800654          0.800681      0.868236    SVM-poly-scale-1  \n",
      "9              0.822951          0.821705      0.920795    SVM-poly-scale-1  \n",
      "SVM-rbf-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.80      0.90      0.85       264\n",
      "      benign       0.88      0.76      0.81       246\n",
      "\n",
      "    accuracy                           0.83       510\n",
      "   macro avg       0.84      0.83      0.83       510\n",
      "weighted avg       0.84      0.83      0.83       510\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.159152    0.008241       1.000000                 1.000000   \n",
      "1   0.066759    0.007451       1.000000                 1.000000   \n",
      "2   0.166499    0.007725       1.000000                 1.000000   \n",
      "3   0.162189    0.006943       1.000000                 1.000000   \n",
      "4   0.108057    0.007698       1.000000                 1.000000   \n",
      "5   0.093857    0.032366       0.803922                 0.804398   \n",
      "6   0.092993    0.033614       0.823529                 0.825977   \n",
      "7   0.093297    0.035702       0.830065                 0.838691   \n",
      "8   0.091128    0.032552       0.800654                 0.800726   \n",
      "9   0.094834    0.033950       0.822951                 0.832710   \n",
      "10  0.085961    0.089645       0.777778                 0.779646   \n",
      "11  0.089390    0.094593       0.826797                 0.832337   \n",
      "12  0.089846    0.088340       0.833333                 0.839362   \n",
      "13  0.088910    0.089758       0.803922                 0.814384   \n",
      "14  0.090306    0.088924       0.826230                 0.827895   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "1               1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "2               1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "3               1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "4               1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "5               0.803922          0.804022      0.873806    SVM-poly-scale-1  \n",
      "6               0.823529          0.823484      0.911692    SVM-poly-scale-1  \n",
      "7               0.830065          0.830065      0.917554    SVM-poly-scale-1  \n",
      "8               0.800654          0.800681      0.868236    SVM-poly-scale-1  \n",
      "9               0.822951          0.821705      0.920795    SVM-poly-scale-1  \n",
      "10              0.777778          0.776549      0.859413     SVM-rbf-scale-1  \n",
      "11              0.826797          0.825581      0.899889     SVM-rbf-scale-1  \n",
      "12              0.833333          0.831450      0.906905     SVM-rbf-scale-1  \n",
      "13              0.803922          0.803267      0.879366     SVM-rbf-scale-1  \n",
      "14              0.826230          0.825983      0.917140     SVM-rbf-scale-1  \n",
      "SVM-sigmoid-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.74      0.72      0.73       264\n",
      "      benign       0.70      0.72      0.71       246\n",
      "\n",
      "    accuracy                           0.72       510\n",
      "   macro avg       0.72      0.72      0.72       510\n",
      "weighted avg       0.72      0.72      0.72       510\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.159152    0.008241       1.000000                 1.000000   \n",
      "1   0.066759    0.007451       1.000000                 1.000000   \n",
      "2   0.166499    0.007725       1.000000                 1.000000   \n",
      "3   0.162189    0.006943       1.000000                 1.000000   \n",
      "4   0.108057    0.007698       1.000000                 1.000000   \n",
      "5   0.093857    0.032366       0.803922                 0.804398   \n",
      "6   0.092993    0.033614       0.823529                 0.825977   \n",
      "7   0.093297    0.035702       0.830065                 0.838691   \n",
      "8   0.091128    0.032552       0.800654                 0.800726   \n",
      "9   0.094834    0.033950       0.822951                 0.832710   \n",
      "10  0.085961    0.089645       0.777778                 0.779646   \n",
      "11  0.089390    0.094593       0.826797                 0.832337   \n",
      "12  0.089846    0.088340       0.833333                 0.839362   \n",
      "13  0.088910    0.089758       0.803922                 0.814384   \n",
      "14  0.090306    0.088924       0.826230                 0.827895   \n",
      "15  0.064985    0.030488       0.643791                 0.643675   \n",
      "16  0.064678    0.032200       0.686275                 0.686172   \n",
      "17  0.066070    0.031633       0.728758                 0.728339   \n",
      "18  0.144057    0.066356       0.330065                 0.331079   \n",
      "19  0.067822    0.032284       0.731148                 0.732203   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "1               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "2               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "3               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "4               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "5               0.803922          0.804022      0.873806     SVM-poly-scale-1  \n",
      "6               0.823529          0.823484      0.911692     SVM-poly-scale-1  \n",
      "7               0.830065          0.830065      0.917554     SVM-poly-scale-1  \n",
      "8               0.800654          0.800681      0.868236     SVM-poly-scale-1  \n",
      "9               0.822951          0.821705      0.920795     SVM-poly-scale-1  \n",
      "10              0.777778          0.776549      0.859413      SVM-rbf-scale-1  \n",
      "11              0.826797          0.825581      0.899889      SVM-rbf-scale-1  \n",
      "12              0.833333          0.831450      0.906905      SVM-rbf-scale-1  \n",
      "13              0.803922          0.803267      0.879366      SVM-rbf-scale-1  \n",
      "14              0.826230          0.825983      0.917140      SVM-rbf-scale-1  \n",
      "15              0.643791          0.643726      0.681988  SVM-sigmoid-scale-1  \n",
      "16              0.686275          0.686194      0.703344  SVM-sigmoid-scale-1  \n",
      "17              0.728758          0.728165      0.782162  SVM-sigmoid-scale-1  \n",
      "18              0.330065          0.329013      0.333776  SVM-sigmoid-scale-1  \n",
      "19              0.731148          0.730887      0.766469  SVM-sigmoid-scale-1  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-linear-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      1.00      1.00       264\n",
      "      benign       1.00      1.00      1.00       246\n",
      "\n",
      "    accuracy                           1.00       510\n",
      "   macro avg       1.00      1.00      1.00       510\n",
      "weighted avg       1.00      1.00      1.00       510\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.159152    0.008241       1.000000                 1.000000   \n",
      "1   0.066759    0.007451       1.000000                 1.000000   \n",
      "2   0.166499    0.007725       1.000000                 1.000000   \n",
      "3   0.162189    0.006943       1.000000                 1.000000   \n",
      "4   0.108057    0.007698       1.000000                 1.000000   \n",
      "5   0.093857    0.032366       0.803922                 0.804398   \n",
      "6   0.092993    0.033614       0.823529                 0.825977   \n",
      "7   0.093297    0.035702       0.830065                 0.838691   \n",
      "8   0.091128    0.032552       0.800654                 0.800726   \n",
      "9   0.094834    0.033950       0.822951                 0.832710   \n",
      "10  0.085961    0.089645       0.777778                 0.779646   \n",
      "11  0.089390    0.094593       0.826797                 0.832337   \n",
      "12  0.089846    0.088340       0.833333                 0.839362   \n",
      "13  0.088910    0.089758       0.803922                 0.814384   \n",
      "14  0.090306    0.088924       0.826230                 0.827895   \n",
      "15  0.064985    0.030488       0.643791                 0.643675   \n",
      "16  0.064678    0.032200       0.686275                 0.686172   \n",
      "17  0.066070    0.031633       0.728758                 0.728339   \n",
      "18  0.144057    0.066356       0.330065                 0.331079   \n",
      "19  0.067822    0.032284       0.731148                 0.732203   \n",
      "20  0.156396    0.007900       1.000000                 1.000000   \n",
      "21  0.067388    0.007515       1.000000                 1.000000   \n",
      "22  0.165808    0.007370       1.000000                 1.000000   \n",
      "23  0.161933    0.006891       1.000000                 1.000000   \n",
      "24  0.107602    0.007654       1.000000                 1.000000   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "1               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "2               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "3               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "4               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "5               0.803922          0.804022      0.873806     SVM-poly-scale-1  \n",
      "6               0.823529          0.823484      0.911692     SVM-poly-scale-1  \n",
      "7               0.830065          0.830065      0.917554     SVM-poly-scale-1  \n",
      "8               0.800654          0.800681      0.868236     SVM-poly-scale-1  \n",
      "9               0.822951          0.821705      0.920795     SVM-poly-scale-1  \n",
      "10              0.777778          0.776549      0.859413      SVM-rbf-scale-1  \n",
      "11              0.826797          0.825581      0.899889      SVM-rbf-scale-1  \n",
      "12              0.833333          0.831450      0.906905      SVM-rbf-scale-1  \n",
      "13              0.803922          0.803267      0.879366      SVM-rbf-scale-1  \n",
      "14              0.826230          0.825983      0.917140      SVM-rbf-scale-1  \n",
      "15              0.643791          0.643726      0.681988  SVM-sigmoid-scale-1  \n",
      "16              0.686275          0.686194      0.703344  SVM-sigmoid-scale-1  \n",
      "17              0.728758          0.728165      0.782162  SVM-sigmoid-scale-1  \n",
      "18              0.330065          0.329013      0.333776  SVM-sigmoid-scale-1  \n",
      "19              0.731148          0.730887      0.766469  SVM-sigmoid-scale-1  \n",
      "20              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "21              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "22              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "23              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "24              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "SVM-poly-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.89      0.89      0.89       264\n",
      "      benign       0.88      0.88      0.88       246\n",
      "\n",
      "    accuracy                           0.88       510\n",
      "   macro avg       0.88      0.88      0.88       510\n",
      "weighted avg       0.88      0.88      0.88       510\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.159152    0.008241       1.000000                 1.000000   \n",
      "1   0.066759    0.007451       1.000000                 1.000000   \n",
      "2   0.166499    0.007725       1.000000                 1.000000   \n",
      "3   0.162189    0.006943       1.000000                 1.000000   \n",
      "4   0.108057    0.007698       1.000000                 1.000000   \n",
      "5   0.093857    0.032366       0.803922                 0.804398   \n",
      "6   0.092993    0.033614       0.823529                 0.825977   \n",
      "7   0.093297    0.035702       0.830065                 0.838691   \n",
      "8   0.091128    0.032552       0.800654                 0.800726   \n",
      "9   0.094834    0.033950       0.822951                 0.832710   \n",
      "10  0.085961    0.089645       0.777778                 0.779646   \n",
      "11  0.089390    0.094593       0.826797                 0.832337   \n",
      "12  0.089846    0.088340       0.833333                 0.839362   \n",
      "13  0.088910    0.089758       0.803922                 0.814384   \n",
      "14  0.090306    0.088924       0.826230                 0.827895   \n",
      "15  0.064985    0.030488       0.643791                 0.643675   \n",
      "16  0.064678    0.032200       0.686275                 0.686172   \n",
      "17  0.066070    0.031633       0.728758                 0.728339   \n",
      "18  0.144057    0.066356       0.330065                 0.331079   \n",
      "19  0.067822    0.032284       0.731148                 0.732203   \n",
      "20  0.156396    0.007900       1.000000                 1.000000   \n",
      "21  0.067388    0.007515       1.000000                 1.000000   \n",
      "22  0.165808    0.007370       1.000000                 1.000000   \n",
      "23  0.161933    0.006891       1.000000                 1.000000   \n",
      "24  0.107602    0.007654       1.000000                 1.000000   \n",
      "25  0.122665    0.016166       0.882353                 0.883085   \n",
      "26  0.115771    0.016057       0.921569                 0.921924   \n",
      "27  0.137284    0.016568       0.928105                 0.928566   \n",
      "28  0.139052    0.015475       0.872549                 0.872527   \n",
      "29  0.110767    0.015370       0.885246                 0.889044   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "1               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "2               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "3               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "4               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "5               0.803922          0.804022      0.873806     SVM-poly-scale-1  \n",
      "6               0.823529          0.823484      0.911692     SVM-poly-scale-1  \n",
      "7               0.830065          0.830065      0.917554     SVM-poly-scale-1  \n",
      "8               0.800654          0.800681      0.868236     SVM-poly-scale-1  \n",
      "9               0.822951          0.821705      0.920795     SVM-poly-scale-1  \n",
      "10              0.777778          0.776549      0.859413      SVM-rbf-scale-1  \n",
      "11              0.826797          0.825581      0.899889      SVM-rbf-scale-1  \n",
      "12              0.833333          0.831450      0.906905      SVM-rbf-scale-1  \n",
      "13              0.803922          0.803267      0.879366      SVM-rbf-scale-1  \n",
      "14              0.826230          0.825983      0.917140      SVM-rbf-scale-1  \n",
      "15              0.643791          0.643726      0.681988  SVM-sigmoid-scale-1  \n",
      "16              0.686275          0.686194      0.703344  SVM-sigmoid-scale-1  \n",
      "17              0.728758          0.728165      0.782162  SVM-sigmoid-scale-1  \n",
      "18              0.330065          0.329013      0.333776  SVM-sigmoid-scale-1  \n",
      "19              0.731148          0.730887      0.766469  SVM-sigmoid-scale-1  \n",
      "20              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "21              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "22              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "23              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "24              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "25              0.882353          0.882110      0.930735      SVM-poly-auto-1  \n",
      "26              0.921569          0.921589      0.970450      SVM-poly-auto-1  \n",
      "27              0.928105          0.927974      0.967923      SVM-poly-auto-1  \n",
      "28              0.872549          0.872529      0.905437      SVM-poly-auto-1  \n",
      "29              0.885246          0.884986      0.937393      SVM-poly-auto-1  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-rbf-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.61      1.00      0.75       264\n",
      "      benign       1.00      0.30      0.46       246\n",
      "\n",
      "    accuracy                           0.66       510\n",
      "   macro avg       0.80      0.65      0.61       510\n",
      "weighted avg       0.80      0.66      0.61       510\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.159152    0.008241       1.000000                 1.000000   \n",
      "1   0.066759    0.007451       1.000000                 1.000000   \n",
      "2   0.166499    0.007725       1.000000                 1.000000   \n",
      "3   0.162189    0.006943       1.000000                 1.000000   \n",
      "4   0.108057    0.007698       1.000000                 1.000000   \n",
      "5   0.093857    0.032366       0.803922                 0.804398   \n",
      "6   0.092993    0.033614       0.823529                 0.825977   \n",
      "7   0.093297    0.035702       0.830065                 0.838691   \n",
      "8   0.091128    0.032552       0.800654                 0.800726   \n",
      "9   0.094834    0.033950       0.822951                 0.832710   \n",
      "10  0.085961    0.089645       0.777778                 0.779646   \n",
      "11  0.089390    0.094593       0.826797                 0.832337   \n",
      "12  0.089846    0.088340       0.833333                 0.839362   \n",
      "13  0.088910    0.089758       0.803922                 0.814384   \n",
      "14  0.090306    0.088924       0.826230                 0.827895   \n",
      "15  0.064985    0.030488       0.643791                 0.643675   \n",
      "16  0.064678    0.032200       0.686275                 0.686172   \n",
      "17  0.066070    0.031633       0.728758                 0.728339   \n",
      "18  0.144057    0.066356       0.330065                 0.331079   \n",
      "19  0.067822    0.032284       0.731148                 0.732203   \n",
      "20  0.156396    0.007900       1.000000                 1.000000   \n",
      "21  0.067388    0.007515       1.000000                 1.000000   \n",
      "22  0.165808    0.007370       1.000000                 1.000000   \n",
      "23  0.161933    0.006891       1.000000                 1.000000   \n",
      "24  0.107602    0.007654       1.000000                 1.000000   \n",
      "25  0.122665    0.016166       0.882353                 0.883085   \n",
      "26  0.115771    0.016057       0.921569                 0.921924   \n",
      "27  0.137284    0.016568       0.928105                 0.928566   \n",
      "28  0.139052    0.015475       0.872549                 0.872527   \n",
      "29  0.110767    0.015370       0.885246                 0.889044   \n",
      "30  0.138970    0.145343       0.568627                 0.742467   \n",
      "31  0.132746    0.140131       0.637255                 0.786938   \n",
      "32  0.131117    0.146591       0.627451                 0.793352   \n",
      "33  0.136956    0.144377       0.575163                 0.744714   \n",
      "34  0.135907    0.145289       0.613115                 0.781574   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "1               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "2               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "3               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "4               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "5               0.803922          0.804022      0.873806     SVM-poly-scale-1  \n",
      "6               0.823529          0.823484      0.911692     SVM-poly-scale-1  \n",
      "7               0.830065          0.830065      0.917554     SVM-poly-scale-1  \n",
      "8               0.800654          0.800681      0.868236     SVM-poly-scale-1  \n",
      "9               0.822951          0.821705      0.920795     SVM-poly-scale-1  \n",
      "10              0.777778          0.776549      0.859413      SVM-rbf-scale-1  \n",
      "11              0.826797          0.825581      0.899889      SVM-rbf-scale-1  \n",
      "12              0.833333          0.831450      0.906905      SVM-rbf-scale-1  \n",
      "13              0.803922          0.803267      0.879366      SVM-rbf-scale-1  \n",
      "14              0.826230          0.825983      0.917140      SVM-rbf-scale-1  \n",
      "15              0.643791          0.643726      0.681988  SVM-sigmoid-scale-1  \n",
      "16              0.686275          0.686194      0.703344  SVM-sigmoid-scale-1  \n",
      "17              0.728758          0.728165      0.782162  SVM-sigmoid-scale-1  \n",
      "18              0.330065          0.329013      0.333776  SVM-sigmoid-scale-1  \n",
      "19              0.731148          0.730887      0.766469  SVM-sigmoid-scale-1  \n",
      "20              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "21              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "22              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "23              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "24              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "25              0.882353          0.882110      0.930735      SVM-poly-auto-1  \n",
      "26              0.921569          0.921589      0.970450      SVM-poly-auto-1  \n",
      "27              0.928105          0.927974      0.967923      SVM-poly-auto-1  \n",
      "28              0.872549          0.872529      0.905437      SVM-poly-auto-1  \n",
      "29              0.885246          0.884986      0.937393      SVM-poly-auto-1  \n",
      "30              0.568627          0.492366      0.698179       SVM-rbf-auto-1  \n",
      "31              0.637255          0.575580      0.719723       SVM-rbf-auto-1  \n",
      "32              0.627451          0.581576      0.740746       SVM-rbf-auto-1  \n",
      "33              0.575163          0.501231      0.696747       SVM-rbf-auto-1  \n",
      "34              0.613115          0.544229      0.705689       SVM-rbf-auto-1  \n",
      "SVM-sigmoid-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.52      1.00      0.68       264\n",
      "      benign       0.00      0.00      0.00       246\n",
      "\n",
      "    accuracy                           0.52       510\n",
      "   macro avg       0.26      0.50      0.34       510\n",
      "weighted avg       0.27      0.52      0.35       510\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.159152    0.008241       1.000000                 1.000000   \n",
      "1   0.066759    0.007451       1.000000                 1.000000   \n",
      "2   0.166499    0.007725       1.000000                 1.000000   \n",
      "3   0.162189    0.006943       1.000000                 1.000000   \n",
      "4   0.108057    0.007698       1.000000                 1.000000   \n",
      "5   0.093857    0.032366       0.803922                 0.804398   \n",
      "6   0.092993    0.033614       0.823529                 0.825977   \n",
      "7   0.093297    0.035702       0.830065                 0.838691   \n",
      "8   0.091128    0.032552       0.800654                 0.800726   \n",
      "9   0.094834    0.033950       0.822951                 0.832710   \n",
      "10  0.085961    0.089645       0.777778                 0.779646   \n",
      "11  0.089390    0.094593       0.826797                 0.832337   \n",
      "12  0.089846    0.088340       0.833333                 0.839362   \n",
      "13  0.088910    0.089758       0.803922                 0.814384   \n",
      "14  0.090306    0.088924       0.826230                 0.827895   \n",
      "15  0.064985    0.030488       0.643791                 0.643675   \n",
      "16  0.064678    0.032200       0.686275                 0.686172   \n",
      "17  0.066070    0.031633       0.728758                 0.728339   \n",
      "18  0.144057    0.066356       0.330065                 0.331079   \n",
      "19  0.067822    0.032284       0.731148                 0.732203   \n",
      "20  0.156396    0.007900       1.000000                 1.000000   \n",
      "21  0.067388    0.007515       1.000000                 1.000000   \n",
      "22  0.165808    0.007370       1.000000                 1.000000   \n",
      "23  0.161933    0.006891       1.000000                 1.000000   \n",
      "24  0.107602    0.007654       1.000000                 1.000000   \n",
      "25  0.122665    0.016166       0.882353                 0.883085   \n",
      "26  0.115771    0.016057       0.921569                 0.921924   \n",
      "27  0.137284    0.016568       0.928105                 0.928566   \n",
      "28  0.139052    0.015475       0.872549                 0.872527   \n",
      "29  0.110767    0.015370       0.885246                 0.889044   \n",
      "30  0.138970    0.145343       0.568627                 0.742467   \n",
      "31  0.132746    0.140131       0.637255                 0.786938   \n",
      "32  0.131117    0.146591       0.627451                 0.793352   \n",
      "33  0.136956    0.144377       0.575163                 0.744714   \n",
      "34  0.135907    0.145289       0.613115                 0.781574   \n",
      "35  0.133119    0.057754       0.526144                 0.276827   \n",
      "36  0.132212    0.056665       0.516340                 0.266607   \n",
      "37  0.134041    0.057149       0.535948                 0.287240   \n",
      "38  0.130327    0.055601       0.477124                 0.227647   \n",
      "39  0.131748    0.056124       0.501639                 0.251642   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "1               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "2               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "3               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "4               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "5               0.803922          0.804022      0.873806     SVM-poly-scale-1  \n",
      "6               0.823529          0.823484      0.911692     SVM-poly-scale-1  \n",
      "7               0.830065          0.830065      0.917554     SVM-poly-scale-1  \n",
      "8               0.800654          0.800681      0.868236     SVM-poly-scale-1  \n",
      "9               0.822951          0.821705      0.920795     SVM-poly-scale-1  \n",
      "10              0.777778          0.776549      0.859413      SVM-rbf-scale-1  \n",
      "11              0.826797          0.825581      0.899889      SVM-rbf-scale-1  \n",
      "12              0.833333          0.831450      0.906905      SVM-rbf-scale-1  \n",
      "13              0.803922          0.803267      0.879366      SVM-rbf-scale-1  \n",
      "14              0.826230          0.825983      0.917140      SVM-rbf-scale-1  \n",
      "15              0.643791          0.643726      0.681988  SVM-sigmoid-scale-1  \n",
      "16              0.686275          0.686194      0.703344  SVM-sigmoid-scale-1  \n",
      "17              0.728758          0.728165      0.782162  SVM-sigmoid-scale-1  \n",
      "18              0.330065          0.329013      0.333776  SVM-sigmoid-scale-1  \n",
      "19              0.731148          0.730887      0.766469  SVM-sigmoid-scale-1  \n",
      "20              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "21              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "22              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "23              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "24              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "25              0.882353          0.882110      0.930735      SVM-poly-auto-1  \n",
      "26              0.921569          0.921589      0.970450      SVM-poly-auto-1  \n",
      "27              0.928105          0.927974      0.967923      SVM-poly-auto-1  \n",
      "28              0.872549          0.872529      0.905437      SVM-poly-auto-1  \n",
      "29              0.885246          0.884986      0.937393      SVM-poly-auto-1  \n",
      "30              0.568627          0.492366      0.698179       SVM-rbf-auto-1  \n",
      "31              0.637255          0.575580      0.719723       SVM-rbf-auto-1  \n",
      "32              0.627451          0.581576      0.740746       SVM-rbf-auto-1  \n",
      "33              0.575163          0.501231      0.696747       SVM-rbf-auto-1  \n",
      "34              0.613115          0.544229      0.705689       SVM-rbf-auto-1  \n",
      "35              0.526144          0.362780      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.516340          0.351645      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.535948          0.374023      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.477124          0.308231      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.501639          0.335156      0.500000   SVM-sigmoid-auto-1  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-linear-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      1.00      1.00       264\n",
      "      benign       1.00      1.00      1.00       246\n",
      "\n",
      "    accuracy                           1.00       510\n",
      "   macro avg       1.00      1.00      1.00       510\n",
      "weighted avg       1.00      1.00      1.00       510\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.159152    0.008241       1.000000                 1.000000   \n",
      "1   0.066759    0.007451       1.000000                 1.000000   \n",
      "2   0.166499    0.007725       1.000000                 1.000000   \n",
      "3   0.162189    0.006943       1.000000                 1.000000   \n",
      "4   0.108057    0.007698       1.000000                 1.000000   \n",
      "5   0.093857    0.032366       0.803922                 0.804398   \n",
      "6   0.092993    0.033614       0.823529                 0.825977   \n",
      "7   0.093297    0.035702       0.830065                 0.838691   \n",
      "8   0.091128    0.032552       0.800654                 0.800726   \n",
      "9   0.094834    0.033950       0.822951                 0.832710   \n",
      "10  0.085961    0.089645       0.777778                 0.779646   \n",
      "11  0.089390    0.094593       0.826797                 0.832337   \n",
      "12  0.089846    0.088340       0.833333                 0.839362   \n",
      "13  0.088910    0.089758       0.803922                 0.814384   \n",
      "14  0.090306    0.088924       0.826230                 0.827895   \n",
      "15  0.064985    0.030488       0.643791                 0.643675   \n",
      "16  0.064678    0.032200       0.686275                 0.686172   \n",
      "17  0.066070    0.031633       0.728758                 0.728339   \n",
      "18  0.144057    0.066356       0.330065                 0.331079   \n",
      "19  0.067822    0.032284       0.731148                 0.732203   \n",
      "20  0.156396    0.007900       1.000000                 1.000000   \n",
      "21  0.067388    0.007515       1.000000                 1.000000   \n",
      "22  0.165808    0.007370       1.000000                 1.000000   \n",
      "23  0.161933    0.006891       1.000000                 1.000000   \n",
      "24  0.107602    0.007654       1.000000                 1.000000   \n",
      "25  0.122665    0.016166       0.882353                 0.883085   \n",
      "26  0.115771    0.016057       0.921569                 0.921924   \n",
      "27  0.137284    0.016568       0.928105                 0.928566   \n",
      "28  0.139052    0.015475       0.872549                 0.872527   \n",
      "29  0.110767    0.015370       0.885246                 0.889044   \n",
      "30  0.138970    0.145343       0.568627                 0.742467   \n",
      "31  0.132746    0.140131       0.637255                 0.786938   \n",
      "32  0.131117    0.146591       0.627451                 0.793352   \n",
      "33  0.136956    0.144377       0.575163                 0.744714   \n",
      "34  0.135907    0.145289       0.613115                 0.781574   \n",
      "35  0.133119    0.057754       0.526144                 0.276827   \n",
      "36  0.132212    0.056665       0.516340                 0.266607   \n",
      "37  0.134041    0.057149       0.535948                 0.287240   \n",
      "38  0.130327    0.055601       0.477124                 0.227647   \n",
      "39  0.131748    0.056124       0.501639                 0.251642   \n",
      "40  0.158930    0.008091       1.000000                 1.000000   \n",
      "41  0.067559    0.007482       1.000000                 1.000000   \n",
      "42  0.166358    0.007492       1.000000                 1.000000   \n",
      "43  0.161433    0.006910       1.000000                 1.000000   \n",
      "44  0.107317    0.007662       1.000000                 1.000000   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "1               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "2               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "3               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "4               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "5               0.803922          0.804022      0.873806     SVM-poly-scale-1  \n",
      "6               0.823529          0.823484      0.911692     SVM-poly-scale-1  \n",
      "7               0.830065          0.830065      0.917554     SVM-poly-scale-1  \n",
      "8               0.800654          0.800681      0.868236     SVM-poly-scale-1  \n",
      "9               0.822951          0.821705      0.920795     SVM-poly-scale-1  \n",
      "10              0.777778          0.776549      0.859413      SVM-rbf-scale-1  \n",
      "11              0.826797          0.825581      0.899889      SVM-rbf-scale-1  \n",
      "12              0.833333          0.831450      0.906905      SVM-rbf-scale-1  \n",
      "13              0.803922          0.803267      0.879366      SVM-rbf-scale-1  \n",
      "14              0.826230          0.825983      0.917140      SVM-rbf-scale-1  \n",
      "15              0.643791          0.643726      0.681988  SVM-sigmoid-scale-1  \n",
      "16              0.686275          0.686194      0.703344  SVM-sigmoid-scale-1  \n",
      "17              0.728758          0.728165      0.782162  SVM-sigmoid-scale-1  \n",
      "18              0.330065          0.329013      0.333776  SVM-sigmoid-scale-1  \n",
      "19              0.731148          0.730887      0.766469  SVM-sigmoid-scale-1  \n",
      "20              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "21              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "22              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "23              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "24              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "25              0.882353          0.882110      0.930735      SVM-poly-auto-1  \n",
      "26              0.921569          0.921589      0.970450      SVM-poly-auto-1  \n",
      "27              0.928105          0.927974      0.967923      SVM-poly-auto-1  \n",
      "28              0.872549          0.872529      0.905437      SVM-poly-auto-1  \n",
      "29              0.885246          0.884986      0.937393      SVM-poly-auto-1  \n",
      "30              0.568627          0.492366      0.698179       SVM-rbf-auto-1  \n",
      "31              0.637255          0.575580      0.719723       SVM-rbf-auto-1  \n",
      "32              0.627451          0.581576      0.740746       SVM-rbf-auto-1  \n",
      "33              0.575163          0.501231      0.696747       SVM-rbf-auto-1  \n",
      "34              0.613115          0.544229      0.705689       SVM-rbf-auto-1  \n",
      "35              0.526144          0.362780      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.516340          0.351645      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.535948          0.374023      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.477124          0.308231      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.501639          0.335156      0.500000   SVM-sigmoid-auto-1  \n",
      "40              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "41              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "42              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "43              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "44              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "SVM-poly-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.86      0.83      0.85       264\n",
      "      benign       0.83      0.85      0.84       246\n",
      "\n",
      "    accuracy                           0.84       510\n",
      "   macro avg       0.84      0.84      0.84       510\n",
      "weighted avg       0.84      0.84      0.84       510\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.159152    0.008241       1.000000                 1.000000   \n",
      "1   0.066759    0.007451       1.000000                 1.000000   \n",
      "2   0.166499    0.007725       1.000000                 1.000000   \n",
      "3   0.162189    0.006943       1.000000                 1.000000   \n",
      "4   0.108057    0.007698       1.000000                 1.000000   \n",
      "5   0.093857    0.032366       0.803922                 0.804398   \n",
      "6   0.092993    0.033614       0.823529                 0.825977   \n",
      "7   0.093297    0.035702       0.830065                 0.838691   \n",
      "8   0.091128    0.032552       0.800654                 0.800726   \n",
      "9   0.094834    0.033950       0.822951                 0.832710   \n",
      "10  0.085961    0.089645       0.777778                 0.779646   \n",
      "11  0.089390    0.094593       0.826797                 0.832337   \n",
      "12  0.089846    0.088340       0.833333                 0.839362   \n",
      "13  0.088910    0.089758       0.803922                 0.814384   \n",
      "14  0.090306    0.088924       0.826230                 0.827895   \n",
      "15  0.064985    0.030488       0.643791                 0.643675   \n",
      "16  0.064678    0.032200       0.686275                 0.686172   \n",
      "17  0.066070    0.031633       0.728758                 0.728339   \n",
      "18  0.144057    0.066356       0.330065                 0.331079   \n",
      "19  0.067822    0.032284       0.731148                 0.732203   \n",
      "20  0.156396    0.007900       1.000000                 1.000000   \n",
      "21  0.067388    0.007515       1.000000                 1.000000   \n",
      "22  0.165808    0.007370       1.000000                 1.000000   \n",
      "23  0.161933    0.006891       1.000000                 1.000000   \n",
      "24  0.107602    0.007654       1.000000                 1.000000   \n",
      "25  0.122665    0.016166       0.882353                 0.883085   \n",
      "26  0.115771    0.016057       0.921569                 0.921924   \n",
      "27  0.137284    0.016568       0.928105                 0.928566   \n",
      "28  0.139052    0.015475       0.872549                 0.872527   \n",
      "29  0.110767    0.015370       0.885246                 0.889044   \n",
      "30  0.138970    0.145343       0.568627                 0.742467   \n",
      "31  0.132746    0.140131       0.637255                 0.786938   \n",
      "32  0.131117    0.146591       0.627451                 0.793352   \n",
      "33  0.136956    0.144377       0.575163                 0.744714   \n",
      "34  0.135907    0.145289       0.613115                 0.781574   \n",
      "35  0.133119    0.057754       0.526144                 0.276827   \n",
      "36  0.132212    0.056665       0.516340                 0.266607   \n",
      "37  0.134041    0.057149       0.535948                 0.287240   \n",
      "38  0.130327    0.055601       0.477124                 0.227647   \n",
      "39  0.131748    0.056124       0.501639                 0.251642   \n",
      "40  0.158930    0.008091       1.000000                 1.000000   \n",
      "41  0.067559    0.007482       1.000000                 1.000000   \n",
      "42  0.166358    0.007492       1.000000                 1.000000   \n",
      "43  0.161433    0.006910       1.000000                 1.000000   \n",
      "44  0.107317    0.007662       1.000000                 1.000000   \n",
      "45  0.094209    0.028626       0.823529                 0.823992   \n",
      "46  0.094393    0.030249       0.866013                 0.866068   \n",
      "47  0.094275    0.030231       0.869281                 0.870219   \n",
      "48  0.092161    0.028752       0.823529                 0.824836   \n",
      "49  0.094198    0.030057       0.826230                 0.830396   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "1               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "2               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "3               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "4               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "5               0.803922          0.804022      0.873806     SVM-poly-scale-1  \n",
      "6               0.823529          0.823484      0.911692     SVM-poly-scale-1  \n",
      "7               0.830065          0.830065      0.917554     SVM-poly-scale-1  \n",
      "8               0.800654          0.800681      0.868236     SVM-poly-scale-1  \n",
      "9               0.822951          0.821705      0.920795     SVM-poly-scale-1  \n",
      "10              0.777778          0.776549      0.859413      SVM-rbf-scale-1  \n",
      "11              0.826797          0.825581      0.899889      SVM-rbf-scale-1  \n",
      "12              0.833333          0.831450      0.906905      SVM-rbf-scale-1  \n",
      "13              0.803922          0.803267      0.879366      SVM-rbf-scale-1  \n",
      "14              0.826230          0.825983      0.917140      SVM-rbf-scale-1  \n",
      "15              0.643791          0.643726      0.681988  SVM-sigmoid-scale-1  \n",
      "16              0.686275          0.686194      0.703344  SVM-sigmoid-scale-1  \n",
      "17              0.728758          0.728165      0.782162  SVM-sigmoid-scale-1  \n",
      "18              0.330065          0.329013      0.333776  SVM-sigmoid-scale-1  \n",
      "19              0.731148          0.730887      0.766469  SVM-sigmoid-scale-1  \n",
      "20              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "21              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "22              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "23              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "24              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "25              0.882353          0.882110      0.930735      SVM-poly-auto-1  \n",
      "26              0.921569          0.921589      0.970450      SVM-poly-auto-1  \n",
      "27              0.928105          0.927974      0.967923      SVM-poly-auto-1  \n",
      "28              0.872549          0.872529      0.905437      SVM-poly-auto-1  \n",
      "29              0.885246          0.884986      0.937393      SVM-poly-auto-1  \n",
      "30              0.568627          0.492366      0.698179       SVM-rbf-auto-1  \n",
      "31              0.637255          0.575580      0.719723       SVM-rbf-auto-1  \n",
      "32              0.627451          0.581576      0.740746       SVM-rbf-auto-1  \n",
      "33              0.575163          0.501231      0.696747       SVM-rbf-auto-1  \n",
      "34              0.613115          0.544229      0.705689       SVM-rbf-auto-1  \n",
      "35              0.526144          0.362780      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.516340          0.351645      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.535948          0.374023      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.477124          0.308231      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.501639          0.335156      0.500000   SVM-sigmoid-auto-1  \n",
      "40              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "41              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "42              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "43              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "44              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "45              0.823529          0.823620      0.882030     SVM-poly-scale-2  \n",
      "46              0.866013          0.865957      0.920587     SVM-poly-scale-2  \n",
      "47              0.869281          0.869415      0.924854     SVM-poly-scale-2  \n",
      "48              0.823529          0.823620      0.870933     SVM-poly-scale-2  \n",
      "49              0.826230          0.825720      0.924450     SVM-poly-scale-2  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-rbf-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.86      0.91      0.88       264\n",
      "      benign       0.89      0.84      0.87       246\n",
      "\n",
      "    accuracy                           0.87       510\n",
      "   macro avg       0.88      0.87      0.87       510\n",
      "weighted avg       0.88      0.87      0.87       510\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.159152    0.008241       1.000000                 1.000000   \n",
      "1   0.066759    0.007451       1.000000                 1.000000   \n",
      "2   0.166499    0.007725       1.000000                 1.000000   \n",
      "3   0.162189    0.006943       1.000000                 1.000000   \n",
      "4   0.108057    0.007698       1.000000                 1.000000   \n",
      "5   0.093857    0.032366       0.803922                 0.804398   \n",
      "6   0.092993    0.033614       0.823529                 0.825977   \n",
      "7   0.093297    0.035702       0.830065                 0.838691   \n",
      "8   0.091128    0.032552       0.800654                 0.800726   \n",
      "9   0.094834    0.033950       0.822951                 0.832710   \n",
      "10  0.085961    0.089645       0.777778                 0.779646   \n",
      "11  0.089390    0.094593       0.826797                 0.832337   \n",
      "12  0.089846    0.088340       0.833333                 0.839362   \n",
      "13  0.088910    0.089758       0.803922                 0.814384   \n",
      "14  0.090306    0.088924       0.826230                 0.827895   \n",
      "15  0.064985    0.030488       0.643791                 0.643675   \n",
      "16  0.064678    0.032200       0.686275                 0.686172   \n",
      "17  0.066070    0.031633       0.728758                 0.728339   \n",
      "18  0.144057    0.066356       0.330065                 0.331079   \n",
      "19  0.067822    0.032284       0.731148                 0.732203   \n",
      "20  0.156396    0.007900       1.000000                 1.000000   \n",
      "21  0.067388    0.007515       1.000000                 1.000000   \n",
      "22  0.165808    0.007370       1.000000                 1.000000   \n",
      "23  0.161933    0.006891       1.000000                 1.000000   \n",
      "24  0.107602    0.007654       1.000000                 1.000000   \n",
      "25  0.122665    0.016166       0.882353                 0.883085   \n",
      "26  0.115771    0.016057       0.921569                 0.921924   \n",
      "27  0.137284    0.016568       0.928105                 0.928566   \n",
      "28  0.139052    0.015475       0.872549                 0.872527   \n",
      "29  0.110767    0.015370       0.885246                 0.889044   \n",
      "30  0.138970    0.145343       0.568627                 0.742467   \n",
      "31  0.132746    0.140131       0.637255                 0.786938   \n",
      "32  0.131117    0.146591       0.627451                 0.793352   \n",
      "33  0.136956    0.144377       0.575163                 0.744714   \n",
      "34  0.135907    0.145289       0.613115                 0.781574   \n",
      "35  0.133119    0.057754       0.526144                 0.276827   \n",
      "36  0.132212    0.056665       0.516340                 0.266607   \n",
      "37  0.134041    0.057149       0.535948                 0.287240   \n",
      "38  0.130327    0.055601       0.477124                 0.227647   \n",
      "39  0.131748    0.056124       0.501639                 0.251642   \n",
      "40  0.158930    0.008091       1.000000                 1.000000   \n",
      "41  0.067559    0.007482       1.000000                 1.000000   \n",
      "42  0.166358    0.007492       1.000000                 1.000000   \n",
      "43  0.161433    0.006910       1.000000                 1.000000   \n",
      "44  0.107317    0.007662       1.000000                 1.000000   \n",
      "45  0.094209    0.028626       0.823529                 0.823992   \n",
      "46  0.094393    0.030249       0.866013                 0.866068   \n",
      "47  0.094275    0.030231       0.869281                 0.870219   \n",
      "48  0.092161    0.028752       0.823529                 0.824836   \n",
      "49  0.094198    0.030057       0.826230                 0.830396   \n",
      "50  0.083215    0.077581       0.820261                 0.821257   \n",
      "51  0.086975    0.085261       0.846405                 0.855171   \n",
      "52  0.089320    0.085370       0.882353                 0.882965   \n",
      "53  0.085426    0.083856       0.826797                 0.834103   \n",
      "54  0.086171    0.085961       0.862295                 0.862363   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "1               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "2               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "3               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "4               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "5               0.803922          0.804022      0.873806     SVM-poly-scale-1  \n",
      "6               0.823529          0.823484      0.911692     SVM-poly-scale-1  \n",
      "7               0.830065          0.830065      0.917554     SVM-poly-scale-1  \n",
      "8               0.800654          0.800681      0.868236     SVM-poly-scale-1  \n",
      "9               0.822951          0.821705      0.920795     SVM-poly-scale-1  \n",
      "10              0.777778          0.776549      0.859413      SVM-rbf-scale-1  \n",
      "11              0.826797          0.825581      0.899889      SVM-rbf-scale-1  \n",
      "12              0.833333          0.831450      0.906905      SVM-rbf-scale-1  \n",
      "13              0.803922          0.803267      0.879366      SVM-rbf-scale-1  \n",
      "14              0.826230          0.825983      0.917140      SVM-rbf-scale-1  \n",
      "15              0.643791          0.643726      0.681988  SVM-sigmoid-scale-1  \n",
      "16              0.686275          0.686194      0.703344  SVM-sigmoid-scale-1  \n",
      "17              0.728758          0.728165      0.782162  SVM-sigmoid-scale-1  \n",
      "18              0.330065          0.329013      0.333776  SVM-sigmoid-scale-1  \n",
      "19              0.731148          0.730887      0.766469  SVM-sigmoid-scale-1  \n",
      "20              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "21              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "22              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "23              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "24              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "25              0.882353          0.882110      0.930735      SVM-poly-auto-1  \n",
      "26              0.921569          0.921589      0.970450      SVM-poly-auto-1  \n",
      "27              0.928105          0.927974      0.967923      SVM-poly-auto-1  \n",
      "28              0.872549          0.872529      0.905437      SVM-poly-auto-1  \n",
      "29              0.885246          0.884986      0.937393      SVM-poly-auto-1  \n",
      "30              0.568627          0.492366      0.698179       SVM-rbf-auto-1  \n",
      "31              0.637255          0.575580      0.719723       SVM-rbf-auto-1  \n",
      "32              0.627451          0.581576      0.740746       SVM-rbf-auto-1  \n",
      "33              0.575163          0.501231      0.696747       SVM-rbf-auto-1  \n",
      "34              0.613115          0.544229      0.705689       SVM-rbf-auto-1  \n",
      "35              0.526144          0.362780      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.516340          0.351645      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.535948          0.374023      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.477124          0.308231      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.501639          0.335156      0.500000   SVM-sigmoid-auto-1  \n",
      "40              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "41              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "42              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "43              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "44              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "45              0.823529          0.823620      0.882030     SVM-poly-scale-2  \n",
      "46              0.866013          0.865957      0.920587     SVM-poly-scale-2  \n",
      "47              0.869281          0.869415      0.924854     SVM-poly-scale-2  \n",
      "48              0.823529          0.823620      0.870933     SVM-poly-scale-2  \n",
      "49              0.826230          0.825720      0.924450     SVM-poly-scale-2  \n",
      "50              0.820261          0.819687      0.879203      SVM-rbf-scale-2  \n",
      "51              0.846405          0.844951      0.922297      SVM-rbf-scale-2  \n",
      "52              0.882353          0.882048      0.924468      SVM-rbf-scale-2  \n",
      "53              0.826797          0.826525      0.888271      SVM-rbf-scale-2  \n",
      "54              0.862295          0.862292      0.928148      SVM-rbf-scale-2  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-sigmoid-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.75      0.71      0.73       264\n",
      "      benign       0.71      0.74      0.72       246\n",
      "\n",
      "    accuracy                           0.73       510\n",
      "   macro avg       0.73      0.73      0.73       510\n",
      "weighted avg       0.73      0.73      0.73       510\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.159152    0.008241       1.000000                 1.000000   \n",
      "1   0.066759    0.007451       1.000000                 1.000000   \n",
      "2   0.166499    0.007725       1.000000                 1.000000   \n",
      "3   0.162189    0.006943       1.000000                 1.000000   \n",
      "4   0.108057    0.007698       1.000000                 1.000000   \n",
      "5   0.093857    0.032366       0.803922                 0.804398   \n",
      "6   0.092993    0.033614       0.823529                 0.825977   \n",
      "7   0.093297    0.035702       0.830065                 0.838691   \n",
      "8   0.091128    0.032552       0.800654                 0.800726   \n",
      "9   0.094834    0.033950       0.822951                 0.832710   \n",
      "10  0.085961    0.089645       0.777778                 0.779646   \n",
      "11  0.089390    0.094593       0.826797                 0.832337   \n",
      "12  0.089846    0.088340       0.833333                 0.839362   \n",
      "13  0.088910    0.089758       0.803922                 0.814384   \n",
      "14  0.090306    0.088924       0.826230                 0.827895   \n",
      "15  0.064985    0.030488       0.643791                 0.643675   \n",
      "16  0.064678    0.032200       0.686275                 0.686172   \n",
      "17  0.066070    0.031633       0.728758                 0.728339   \n",
      "18  0.144057    0.066356       0.330065                 0.331079   \n",
      "19  0.067822    0.032284       0.731148                 0.732203   \n",
      "20  0.156396    0.007900       1.000000                 1.000000   \n",
      "21  0.067388    0.007515       1.000000                 1.000000   \n",
      "22  0.165808    0.007370       1.000000                 1.000000   \n",
      "23  0.161933    0.006891       1.000000                 1.000000   \n",
      "24  0.107602    0.007654       1.000000                 1.000000   \n",
      "25  0.122665    0.016166       0.882353                 0.883085   \n",
      "26  0.115771    0.016057       0.921569                 0.921924   \n",
      "27  0.137284    0.016568       0.928105                 0.928566   \n",
      "28  0.139052    0.015475       0.872549                 0.872527   \n",
      "29  0.110767    0.015370       0.885246                 0.889044   \n",
      "30  0.138970    0.145343       0.568627                 0.742467   \n",
      "31  0.132746    0.140131       0.637255                 0.786938   \n",
      "32  0.131117    0.146591       0.627451                 0.793352   \n",
      "33  0.136956    0.144377       0.575163                 0.744714   \n",
      "34  0.135907    0.145289       0.613115                 0.781574   \n",
      "35  0.133119    0.057754       0.526144                 0.276827   \n",
      "36  0.132212    0.056665       0.516340                 0.266607   \n",
      "37  0.134041    0.057149       0.535948                 0.287240   \n",
      "38  0.130327    0.055601       0.477124                 0.227647   \n",
      "39  0.131748    0.056124       0.501639                 0.251642   \n",
      "40  0.158930    0.008091       1.000000                 1.000000   \n",
      "41  0.067559    0.007482       1.000000                 1.000000   \n",
      "42  0.166358    0.007492       1.000000                 1.000000   \n",
      "43  0.161433    0.006910       1.000000                 1.000000   \n",
      "44  0.107317    0.007662       1.000000                 1.000000   \n",
      "45  0.094209    0.028626       0.823529                 0.823992   \n",
      "46  0.094393    0.030249       0.866013                 0.866068   \n",
      "47  0.094275    0.030231       0.869281                 0.870219   \n",
      "48  0.092161    0.028752       0.823529                 0.824836   \n",
      "49  0.094198    0.030057       0.826230                 0.830396   \n",
      "50  0.083215    0.077581       0.820261                 0.821257   \n",
      "51  0.086975    0.085261       0.846405                 0.855171   \n",
      "52  0.089320    0.085370       0.882353                 0.882965   \n",
      "53  0.085426    0.083856       0.826797                 0.834103   \n",
      "54  0.086171    0.085961       0.862295                 0.862363   \n",
      "55  0.062519    0.029204       0.643791                 0.643675   \n",
      "56  0.062473    0.030022       0.686275                 0.686275   \n",
      "57  0.064480    0.030670       0.732026                 0.731647   \n",
      "58  0.139167    0.063171       0.333333                 0.334282   \n",
      "59  0.065073    0.030984       0.731148                 0.732203   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "1               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "2               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "3               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "4               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "5               0.803922          0.804022      0.873806     SVM-poly-scale-1  \n",
      "6               0.823529          0.823484      0.911692     SVM-poly-scale-1  \n",
      "7               0.830065          0.830065      0.917554     SVM-poly-scale-1  \n",
      "8               0.800654          0.800681      0.868236     SVM-poly-scale-1  \n",
      "9               0.822951          0.821705      0.920795     SVM-poly-scale-1  \n",
      "10              0.777778          0.776549      0.859413      SVM-rbf-scale-1  \n",
      "11              0.826797          0.825581      0.899889      SVM-rbf-scale-1  \n",
      "12              0.833333          0.831450      0.906905      SVM-rbf-scale-1  \n",
      "13              0.803922          0.803267      0.879366      SVM-rbf-scale-1  \n",
      "14              0.826230          0.825983      0.917140      SVM-rbf-scale-1  \n",
      "15              0.643791          0.643726      0.681988  SVM-sigmoid-scale-1  \n",
      "16              0.686275          0.686194      0.703344  SVM-sigmoid-scale-1  \n",
      "17              0.728758          0.728165      0.782162  SVM-sigmoid-scale-1  \n",
      "18              0.330065          0.329013      0.333776  SVM-sigmoid-scale-1  \n",
      "19              0.731148          0.730887      0.766469  SVM-sigmoid-scale-1  \n",
      "20              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "21              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "22              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "23              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "24              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "25              0.882353          0.882110      0.930735      SVM-poly-auto-1  \n",
      "26              0.921569          0.921589      0.970450      SVM-poly-auto-1  \n",
      "27              0.928105          0.927974      0.967923      SVM-poly-auto-1  \n",
      "28              0.872549          0.872529      0.905437      SVM-poly-auto-1  \n",
      "29              0.885246          0.884986      0.937393      SVM-poly-auto-1  \n",
      "30              0.568627          0.492366      0.698179       SVM-rbf-auto-1  \n",
      "31              0.637255          0.575580      0.719723       SVM-rbf-auto-1  \n",
      "32              0.627451          0.581576      0.740746       SVM-rbf-auto-1  \n",
      "33              0.575163          0.501231      0.696747       SVM-rbf-auto-1  \n",
      "34              0.613115          0.544229      0.705689       SVM-rbf-auto-1  \n",
      "35              0.526144          0.362780      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.516340          0.351645      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.535948          0.374023      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.477124          0.308231      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.501639          0.335156      0.500000   SVM-sigmoid-auto-1  \n",
      "40              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "41              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "42              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "43              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "44              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "45              0.823529          0.823620      0.882030     SVM-poly-scale-2  \n",
      "46              0.866013          0.865957      0.920587     SVM-poly-scale-2  \n",
      "47              0.869281          0.869415      0.924854     SVM-poly-scale-2  \n",
      "48              0.823529          0.823620      0.870933     SVM-poly-scale-2  \n",
      "49              0.826230          0.825720      0.924450     SVM-poly-scale-2  \n",
      "50              0.820261          0.819687      0.879203      SVM-rbf-scale-2  \n",
      "51              0.846405          0.844951      0.922297      SVM-rbf-scale-2  \n",
      "52              0.882353          0.882048      0.924468      SVM-rbf-scale-2  \n",
      "53              0.826797          0.826525      0.888271      SVM-rbf-scale-2  \n",
      "54              0.862295          0.862292      0.928148      SVM-rbf-scale-2  \n",
      "55              0.643791          0.643726      0.682116  SVM-sigmoid-scale-2  \n",
      "56              0.686275          0.686275      0.703259  SVM-sigmoid-scale-2  \n",
      "57              0.732026          0.731333      0.782635  SVM-sigmoid-scale-2  \n",
      "58              0.333333          0.332079      0.334675  SVM-sigmoid-scale-2  \n",
      "59              0.731148          0.730887      0.766512  SVM-sigmoid-scale-2  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-linear-auto-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      1.00      1.00       264\n",
      "      benign       1.00      1.00      1.00       246\n",
      "\n",
      "    accuracy                           1.00       510\n",
      "   macro avg       1.00      1.00      1.00       510\n",
      "weighted avg       1.00      1.00      1.00       510\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.159152    0.008241            1.0                      1.0   \n",
      "1   0.066759    0.007451            1.0                      1.0   \n",
      "2   0.166499    0.007725            1.0                      1.0   \n",
      "3   0.162189    0.006943            1.0                      1.0   \n",
      "4   0.108057    0.007698            1.0                      1.0   \n",
      "..       ...         ...            ...                      ...   \n",
      "60  0.156528    0.007882            1.0                      1.0   \n",
      "61  0.066907    0.007387            1.0                      1.0   \n",
      "62  0.164653    0.007347            1.0                      1.0   \n",
      "63  0.160970    0.006921            1.0                      1.0   \n",
      "64  0.106825    0.007662            1.0                      1.0   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0                    1.0               1.0           1.0  SVM-linear-scale-1  \n",
      "1                    1.0               1.0           1.0  SVM-linear-scale-1  \n",
      "2                    1.0               1.0           1.0  SVM-linear-scale-1  \n",
      "3                    1.0               1.0           1.0  SVM-linear-scale-1  \n",
      "4                    1.0               1.0           1.0  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "60                   1.0               1.0           1.0   SVM-linear-auto-2  \n",
      "61                   1.0               1.0           1.0   SVM-linear-auto-2  \n",
      "62                   1.0               1.0           1.0   SVM-linear-auto-2  \n",
      "63                   1.0               1.0           1.0   SVM-linear-auto-2  \n",
      "64                   1.0               1.0           1.0   SVM-linear-auto-2  \n",
      "\n",
      "[65 rows x 8 columns]\n",
      "SVM-poly-auto-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.89      0.89      0.89       264\n",
      "      benign       0.88      0.88      0.88       246\n",
      "\n",
      "    accuracy                           0.88       510\n",
      "   macro avg       0.88      0.88      0.88       510\n",
      "weighted avg       0.88      0.88      0.88       510\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.159152    0.008241       1.000000                 1.000000   \n",
      "1   0.066759    0.007451       1.000000                 1.000000   \n",
      "2   0.166499    0.007725       1.000000                 1.000000   \n",
      "3   0.162189    0.006943       1.000000                 1.000000   \n",
      "4   0.108057    0.007698       1.000000                 1.000000   \n",
      "..       ...         ...            ...                      ...   \n",
      "65  0.122201    0.016132       0.882353                 0.883085   \n",
      "66  0.115726    0.016022       0.921569                 0.921924   \n",
      "67  0.136905    0.016429       0.928105                 0.928566   \n",
      "68  0.138379    0.015502       0.872549                 0.872527   \n",
      "69  0.109803    0.015316       0.885246                 0.889044   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "1               1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "2               1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "3               1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "4               1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "65              0.882353          0.882110      0.930735     SVM-poly-auto-2  \n",
      "66              0.921569          0.921589      0.970450     SVM-poly-auto-2  \n",
      "67              0.928105          0.927974      0.967923     SVM-poly-auto-2  \n",
      "68              0.872549          0.872529      0.905437     SVM-poly-auto-2  \n",
      "69              0.885246          0.884986      0.937393     SVM-poly-auto-2  \n",
      "\n",
      "[70 rows x 8 columns]\n",
      "SVM-rbf-auto-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.61      1.00      0.75       264\n",
      "      benign       1.00      0.30      0.46       246\n",
      "\n",
      "    accuracy                           0.66       510\n",
      "   macro avg       0.80      0.65      0.61       510\n",
      "weighted avg       0.80      0.66      0.61       510\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.159152    0.008241       1.000000                 1.000000   \n",
      "1   0.066759    0.007451       1.000000                 1.000000   \n",
      "2   0.166499    0.007725       1.000000                 1.000000   \n",
      "3   0.162189    0.006943       1.000000                 1.000000   \n",
      "4   0.108057    0.007698       1.000000                 1.000000   \n",
      "..       ...         ...            ...                      ...   \n",
      "70  0.132862    0.134238       0.568627                 0.742467   \n",
      "71  0.128907    0.139466       0.637255                 0.786938   \n",
      "72  0.132379    0.132263       0.627451                 0.793352   \n",
      "73  0.134615    0.131866       0.575163                 0.744714   \n",
      "74  0.132904    0.130773       0.613115                 0.781574   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "1               1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "2               1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "3               1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "4               1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "70              0.568627          0.492366      0.698179      SVM-rbf-auto-2  \n",
      "71              0.637255          0.575580      0.719723      SVM-rbf-auto-2  \n",
      "72              0.627451          0.581576      0.740746      SVM-rbf-auto-2  \n",
      "73              0.575163          0.501231      0.696747      SVM-rbf-auto-2  \n",
      "74              0.613115          0.544229      0.705689      SVM-rbf-auto-2  \n",
      "\n",
      "[75 rows x 8 columns]\n",
      "SVM-sigmoid-auto-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.52      1.00      0.68       264\n",
      "      benign       0.00      0.00      0.00       246\n",
      "\n",
      "    accuracy                           0.52       510\n",
      "   macro avg       0.26      0.50      0.34       510\n",
      "weighted avg       0.27      0.52      0.35       510\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.159152    0.008241       1.000000                 1.000000   \n",
      "1   0.066759    0.007451       1.000000                 1.000000   \n",
      "2   0.166499    0.007725       1.000000                 1.000000   \n",
      "3   0.162189    0.006943       1.000000                 1.000000   \n",
      "4   0.108057    0.007698       1.000000                 1.000000   \n",
      "..       ...         ...            ...                      ...   \n",
      "75  0.134493    0.057452       0.526144                 0.276827   \n",
      "76  0.131970    0.057287       0.516340                 0.266607   \n",
      "77  0.134505    0.057460       0.535948                 0.287240   \n",
      "78  0.133134    0.056192       0.477124                 0.227647   \n",
      "79  0.132552    0.056562       0.501639                 0.251642   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               1.000000          1.000000           1.0  SVM-linear-scale-1  \n",
      "1               1.000000          1.000000           1.0  SVM-linear-scale-1  \n",
      "2               1.000000          1.000000           1.0  SVM-linear-scale-1  \n",
      "3               1.000000          1.000000           1.0  SVM-linear-scale-1  \n",
      "4               1.000000          1.000000           1.0  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "75              0.526144          0.362780           0.5  SVM-sigmoid-auto-2  \n",
      "76              0.516340          0.351645           0.5  SVM-sigmoid-auto-2  \n",
      "77              0.535948          0.374023           0.5  SVM-sigmoid-auto-2  \n",
      "78              0.477124          0.308231           0.5  SVM-sigmoid-auto-2  \n",
      "79              0.501639          0.335156           0.5  SVM-sigmoid-auto-2  \n",
      "\n",
      "[80 rows x 8 columns]\n",
      "24.918010805999074\n"
     ]
    }
   ],
   "source": [
    "# 2) THR: %50 (Robust)\n",
    "\n",
    "df_malicious = pd.concat([df3,df34])\n",
    "df_benign = pd.concat([df29,df31])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_THR_50_s2 = run_process(df_malicious,df_benign,df_results)\n",
    "\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313328ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rodou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 1520681\n",
      "benign: 1519195\n",
      "0 NAN in malicious!\n",
      "33 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 1520681\n",
      "benign: 1519162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 160/160 [04:23<00:00,  1.64s/it]\n",
      "Feature Extraction: 100%|█████████████████████| 160/160 [04:07<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let the ml starts\n",
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.98      0.98     37923\n",
      "      benign       0.98      0.98      0.98     38074\n",
      "\n",
      "    accuracy                           0.98     75997\n",
      "   macro avg       0.98      0.98      0.98     75997\n",
      "weighted avg       0.98      0.98      0.98     75997\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  6.241755    0.235247       0.981008                 0.981078   \n",
      "1  6.566289    0.168072       0.979714                 0.979780   \n",
      "2  7.357708    0.129282       0.979363                 0.979428   \n",
      "3  5.899415    0.139058       0.979692                 0.979797   \n",
      "4  5.758039    0.129053       0.979560                 0.979615   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.981008          0.981007      0.992900  LogReg  \n",
      "1              0.979714          0.979713      0.992195  LogReg  \n",
      "2              0.979363          0.979363      0.992892  LogReg  \n",
      "3              0.979692          0.979691      0.992489  LogReg  \n",
      "4              0.979560          0.979559      0.992577  LogReg  \n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.98      0.98     37923\n",
      "      benign       0.98      0.98      0.98     38074\n",
      "\n",
      "    accuracy                           0.98     75997\n",
      "   macro avg       0.98      0.98      0.98     75997\n",
      "weighted avg       0.98      0.98      0.98     75997\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  6.241755    0.235247       0.981008                 0.981078   \n",
      "1  6.566289    0.168072       0.979714                 0.979780   \n",
      "2  7.357708    0.129282       0.979363                 0.979428   \n",
      "3  5.899415    0.139058       0.979692                 0.979797   \n",
      "4  5.758039    0.129053       0.979560                 0.979615   \n",
      "5  0.253100  367.878758       0.979999                 0.980009   \n",
      "6  0.270692  363.608822       0.979889                 0.979900   \n",
      "7  0.254529  363.882532       0.979122                 0.979126   \n",
      "8  0.270708  369.489278       0.978946                 0.978954   \n",
      "9  0.428487  391.086489       0.979100                 0.979105   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.981008          0.981007      0.992900  LogReg  \n",
      "1              0.979714          0.979713      0.992195  LogReg  \n",
      "2              0.979363          0.979363      0.992892  LogReg  \n",
      "3              0.979692          0.979691      0.992489  LogReg  \n",
      "4              0.979560          0.979559      0.992577  LogReg  \n",
      "5              0.979999          0.979999      0.992979     KNN  \n",
      "6              0.979889          0.979889      0.993013     KNN  \n",
      "7              0.979122          0.979122      0.992672     KNN  \n",
      "8              0.978946          0.978946      0.993082     KNN  \n",
      "9              0.979100          0.979099      0.993063     KNN  \n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.99      0.98      0.98     37923\n",
      "      benign       0.98      0.99      0.98     38074\n",
      "\n",
      "    accuracy                           0.98     75997\n",
      "   macro avg       0.98      0.98      0.98     75997\n",
      "weighted avg       0.98      0.98      0.98     75997\n",
      "\n",
      "       fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0      6.241755    0.235247       0.981008                 0.981078   \n",
      "1      6.566289    0.168072       0.979714                 0.979780   \n",
      "2      7.357708    0.129282       0.979363                 0.979428   \n",
      "3      5.899415    0.139058       0.979692                 0.979797   \n",
      "4      5.758039    0.129053       0.979560                 0.979615   \n",
      "5      0.253100  367.878758       0.979999                 0.980009   \n",
      "6      0.270692  363.608822       0.979889                 0.979900   \n",
      "7      0.254529  363.882532       0.979122                 0.979126   \n",
      "8      0.270708  369.489278       0.978946                 0.978954   \n",
      "9      0.428487  391.086489       0.979100                 0.979105   \n",
      "10  1719.707144  270.929915       0.984495                 0.984642   \n",
      "11  1609.793466  265.811531       0.984341                 0.984512   \n",
      "12  2408.418243  272.574108       0.983837                 0.983987   \n",
      "13  2302.584075  261.156202       0.983179                 0.983363   \n",
      "14  2195.438468  260.862245       0.983924                 0.984071   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.981008          0.981007      0.992900  LogReg  \n",
      "1               0.979714          0.979713      0.992195  LogReg  \n",
      "2               0.979363          0.979363      0.992892  LogReg  \n",
      "3               0.979692          0.979691      0.992489  LogReg  \n",
      "4               0.979560          0.979559      0.992577  LogReg  \n",
      "5               0.979999          0.979999      0.992979     KNN  \n",
      "6               0.979889          0.979889      0.993013     KNN  \n",
      "7               0.979122          0.979122      0.992672     KNN  \n",
      "8               0.978946          0.978946      0.993082     KNN  \n",
      "9               0.979100          0.979099      0.993063     KNN  \n",
      "10              0.984495          0.984494      0.996208     SVM  \n",
      "11              0.984341          0.984340      0.995856     SVM  \n",
      "12              0.983837          0.983837      0.995612     SVM  \n",
      "13              0.983179          0.983177      0.996074     SVM  \n",
      "14              0.983924          0.983923      0.995069     SVM  \n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      0.96      0.98     37923\n",
      "      benign       0.97      1.00      0.98     38074\n",
      "\n",
      "    accuracy                           0.98     75997\n",
      "   macro avg       0.98      0.98      0.98     75997\n",
      "weighted avg       0.98      0.98      0.98     75997\n",
      "\n",
      "       fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0      6.241755    0.235247       0.981008                 0.981078   \n",
      "1      6.566289    0.168072       0.979714                 0.979780   \n",
      "2      7.357708    0.129282       0.979363                 0.979428   \n",
      "3      5.899415    0.139058       0.979692                 0.979797   \n",
      "4      5.758039    0.129053       0.979560                 0.979615   \n",
      "5      0.253100  367.878758       0.979999                 0.980009   \n",
      "6      0.270692  363.608822       0.979889                 0.979900   \n",
      "7      0.254529  363.882532       0.979122                 0.979126   \n",
      "8      0.270708  369.489278       0.978946                 0.978954   \n",
      "9      0.428487  391.086489       0.979100                 0.979105   \n",
      "10  1719.707144  270.929915       0.984495                 0.984642   \n",
      "11  1609.793466  265.811531       0.984341                 0.984512   \n",
      "12  2408.418243  272.574108       0.983837                 0.983987   \n",
      "13  2302.584075  261.156202       0.983179                 0.983363   \n",
      "14  2195.438468  260.862245       0.983924                 0.984071   \n",
      "15     1.011097    0.467396       0.981622                 0.982154   \n",
      "16     1.015896    0.463127       0.980394                 0.980956   \n",
      "17     1.018739    0.469019       0.980065                 0.980557   \n",
      "18     1.012077    0.464469       0.979582                 0.980147   \n",
      "19     1.011041    0.489543       0.979736                 0.980238   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.981008          0.981007      0.992900  LogReg  \n",
      "1               0.979714          0.979713      0.992195  LogReg  \n",
      "2               0.979363          0.979363      0.992892  LogReg  \n",
      "3               0.979692          0.979691      0.992489  LogReg  \n",
      "4               0.979560          0.979559      0.992577  LogReg  \n",
      "5               0.979999          0.979999      0.992979     KNN  \n",
      "6               0.979889          0.979889      0.993013     KNN  \n",
      "7               0.979122          0.979122      0.992672     KNN  \n",
      "8               0.978946          0.978946      0.993082     KNN  \n",
      "9               0.979100          0.979099      0.993063     KNN  \n",
      "10              0.984495          0.984494      0.996208     SVM  \n",
      "11              0.984341          0.984340      0.995856     SVM  \n",
      "12              0.983837          0.983837      0.995612     SVM  \n",
      "13              0.983179          0.983177      0.996074     SVM  \n",
      "14              0.983924          0.983923      0.995069     SVM  \n",
      "15              0.981622          0.981617      0.982440     GNB  \n",
      "16              0.980394          0.980388      0.981718     GNB  \n",
      "17              0.980065          0.980062      0.982058     GNB  \n",
      "18              0.979582          0.979576      0.981123     GNB  \n",
      "19              0.979736          0.979730      0.981806     GNB  \n",
      "18343.352437399008\n"
     ]
    }
   ],
   "source": [
    " # 3) THR: %100 (Aggressive)\n",
    "    \n",
    "df_malicious = pd.concat([df1,df2,df4,df5,df6,df7,df35])[:30000]\n",
    "df_benign    = pd.concat([df11,df12,df13,df14,df16,df17,df21,df23,df26,df27,df28,df29,df30,df31])[:30000]\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_THR_100_s2 = run_process(df_malicious,df_benign,df_results)\n",
    "\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1dbaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rodou')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nectar-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
