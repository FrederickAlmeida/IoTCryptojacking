{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "545bcbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tsfresh\n",
    "import os\n",
    "import json\n",
    "import scapy\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from scapy.all import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") #ignore warnings caused by \n",
    "\n",
    "\n",
    "#################################################################\n",
    "#                                                               #\n",
    "#               malicious csv files import                      #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "df1 = pd.read_csv('~/malicious/WebOS_binary.csv') #\n",
    "df2 = pd.read_csv('~/malicious/Server_Binary.csv') #\n",
    "df3 = pd.read_csv('~/malicious/Raspberry_Webmine_Robust.csv')\n",
    "df4 = pd.read_csv('~/malicious/Raspberry_Binary.csv') #\n",
    "df5 = pd.read_csv('~/malicious/Raspberry_Webmine_Aggressive.csv')\n",
    "df6 = pd.read_csv('~/malicious/Raspberry_WebminePool_Aggressive.csv')\n",
    "df7 = pd.read_csv('~/malicious/Server_WebminePool_Aggressive.csv') #\n",
    "\n",
    "df32 = pd.read_csv('~/malicious/Server_WebminePool_Robust.csv') #\n",
    "df33 = pd.read_csv('~/malicious/Raspberry_WebminePool_Stealthy.csv') #\n",
    "df34 = pd.read_csv('~/malicious/Raspberry_WebminePool_Robust.csv') #\n",
    "df35 = pd.read_csv('~/malicious/Desktop_WebminePool_Aggressive.csv') #\n",
    "\n",
    "\n",
    "#################################################################\n",
    "#                                                               #\n",
    "#               benign csv files import                         #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "############### LAPTOP #############\n",
    "\n",
    "df8 = pd.read_csv('~/benign2/Laptop/Laptop_download_benign.csv')\n",
    "df9 = pd.read_csv('~/benign2/Laptop/Laptop_idle_benign.csv')\n",
    "df10 = pd.read_csv('~/benign2/Laptop/Laptop_interactive_benign.csv')\n",
    "df11 = pd.read_csv('~/benign2/Laptop/Laptop_video_benign.csv')\n",
    "df12 = pd.read_csv('~/benign2/Laptop/Laptop_webbrowsing_benign.csv')\n",
    "\n",
    "############### Raspberry ##########\n",
    "\n",
    "df13 = pd.read_csv('~/benign2/Rasberry/Raspberry_download_benign.csv')\n",
    "df14 = pd.read_csv('~/benign2/Rasberry/Raspberry_idle_benign.csv')\n",
    "df15 = pd.read_csv('~/benign2/Rasberry/Raspberry_interactive_benign.csv')\n",
    "df16 = pd.read_csv('~/benign2/Rasberry/Raspberry_video_benign.csv')\n",
    "df17 = pd.read_csv('~/benign2/Rasberry/Raspberry_webbrowsing_benign.csv')\n",
    "\n",
    "############### Server ############\n",
    "\n",
    "\n",
    "df18 = pd.read_csv('~/benign2/Server/Server_download_benign.csv')\n",
    "df19 = pd.read_csv('~/benign2/Server/Server_idle_benign.csv')\n",
    "df20 = pd.read_csv('~/benign2/Server/Server_interactive_benign.csv')\n",
    "df21 = pd.read_csv('~/benign2/Server/Server_video_benign.csv')\n",
    "df22 = pd.read_csv('~/benign2/Server/Server_webbrowsing_benign.csv')\n",
    "\n",
    "############### WebOS ############\n",
    "\n",
    "df23 = pd.read_csv('~/benign2/WebOS/Webos_video(live&normal)_benign.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8ca31fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 -->> 43173\n",
      "df2 -->> 1213354\n",
      "df3 -->> 3621\n",
      "df4 -->> 22111\n",
      "df5 -->> 14156\n",
      "df6 -->> 24476\n",
      "df7 -->> 3106\n",
      "df32 -->> 18460\n",
      "df33 -->> 10285\n",
      "df34 -->> 7708\n",
      "df35 -->> 234892\n",
      "/////////////////////////////////////////////////\n",
      " LAPTOP \n",
      "df8 -->> 442866\n",
      "df9 -->> 113602\n",
      "df10 -->> 81681\n",
      "df11 -->> 29010\n",
      "df12 -->> 99235\n",
      " Raspberry \n",
      "df13 -->> 276808\n",
      "df14 -->> 73\n",
      "df15 -->> 104241\n",
      "df16 -->> 57205\n",
      "df17 -->> 123298\n",
      " Server \n",
      "df18 -->> 564831\n",
      "df19 -->> 13459\n",
      "df20 -->> 123728\n",
      "df21 -->> 109497\n",
      "df22 -->> 43713\n",
      " WebOS \n",
      "df23 -->> 177704\n",
      "malicious: 1595342\n",
      "benign: 2360951\n"
     ]
    }
   ],
   "source": [
    "print(\"df1 -->> {}\".format(len(df1)))\n",
    "print(\"df2 -->> {}\".format(len(df2)))\n",
    "print(\"df3 -->> {}\".format(len(df3)))\n",
    "print(\"df4 -->> {}\".format(len(df4)))\n",
    "print(\"df5 -->> {}\".format(len(df5)))\n",
    "print(\"df6 -->> {}\".format(len(df6)))\n",
    "print(\"df7 -->> {}\".format(len(df7)))\n",
    "print(\"df32 -->> {}\".format(len(df32)))\n",
    "print(\"df33 -->> {}\".format(len(df33)))\n",
    "print(\"df34 -->> {}\".format(len(df34)))\n",
    "print(\"df35 -->> {}\".format(len(df35)))\n",
    "print(\"/////////////////////////////////////////////////\")\n",
    "\n",
    "print(\" LAPTOP \")\n",
    "\n",
    "\n",
    "print(\"df8 -->> {}\".format(len(df8)))\n",
    "print(\"df9 -->> {}\".format(len(df9)))\n",
    "print(\"df10 -->> {}\".format(len(df10)))\n",
    "print(\"df11 -->> {}\".format(len(df11)))\n",
    "print(\"df12 -->> {}\".format(len(df12)))\n",
    "\n",
    "print(\" Raspberry \")\n",
    "\n",
    "\n",
    "print(\"df13 -->> {}\".format(len(df13)))\n",
    "print(\"df14 -->> {}\".format(len(df14)))\n",
    "print(\"df15 -->> {}\".format(len(df15)))\n",
    "print(\"df16 -->> {}\".format(len(df16)))\n",
    "print(\"df17 -->> {}\".format(len(df17)))\n",
    "\n",
    "print(\" Server \")\n",
    "\n",
    "print(\"df18 -->> {}\".format(len(df18)))\n",
    "print(\"df19 -->> {}\".format(len(df19)))\n",
    "print(\"df20 -->> {}\".format(len(df20)))\n",
    "print(\"df21 -->> {}\".format(len(df21)))\n",
    "print(\"df22 -->> {}\".format(len(df22)))\n",
    "\n",
    "print(\" WebOS \")\n",
    "\n",
    "print(\"df23 -->> {}\".format(len(df23)))\n",
    "\n",
    "\n",
    "df_malicious = pd.concat([df1,df2,df3,df4,df5,df6,df7,df32,df33,df34,df35])\n",
    " \n",
    "df_benign = pd.concat([df8,df9,df10,df11,df12,df13,df14,df15,df16,df17,df18,df19,df20,df21,df22,df23])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d28c3660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prune the datasets for labeling process for malicious data\n",
    "\n",
    "\n",
    "# For WebOS = 18:56:80:17:d0:ef\n",
    "index_names = df1[((df1['HW_dst'] != '18:56:80:17:d0:ef') & (df1['Hw_src'] != '18:56:80:17:d0:ef'))].index\n",
    "df1.drop(index_names, inplace = True)\n",
    "\n",
    "# Big_Server_Monero_mining_data = a4:bb:6d:ac:e1:fd\n",
    "\n",
    "index_names = df2[((df2['HW_dst'] != 'a4:bb:6d:ac:e1:fd') & (df2['Hw_src'] != 'a4:bb:6d:ac:e1:fd'))].index\n",
    "df2.drop(index_names, inplace = True)\n",
    "\n",
    "# ege_data_rasberry = dc:a6:32:67:66:4b\t\n",
    "\n",
    "index_names = df3[((df3['HW_dst'] != 'dc:a6:32:67:66:4b') & (df3['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df3.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_binary_monero_mining = dc:a6:32:68:35:8a\n",
    "\n",
    "index_names = df4[((df4['HW_dst'] != 'dc:a6:32:68:35:8a') & (df4['Hw_src'] != 'dc:a6:32:68:35:8a'))].index\n",
    "df4.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_network_data_2 = dc:a6:32:67:66:4b\n",
    "\n",
    "index_names = df5[((df5['HW_dst'] != 'dc:a6:32:67:66:4b') & (df5['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df5.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry-Webmine = dc:a6:32:67:66:4b\n",
    "index_names = df6[((df6['HW_dst'] != 'dc:a6:32:67:66:4b') & (df6['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df6.drop(index_names, inplace = True)\n",
    "\n",
    "# Server_Webmine_Network_data = a4:bb:6d:ac:e1:fd\n",
    "\n",
    "index_names = df7[((df7['HW_dst'] != 'a4:bb:6d:ac:e1:fd') & (df7['Hw_src'] != 'a4:bb:6d:ac:e1:fd'))].index\n",
    "df7.drop(index_names, inplace = True)\n",
    "\n",
    "# Server_%50_Mining = a4:bb:6d:ac:e1:fd\n",
    "\n",
    "index_names = df32[((df32['HW_dst'] != 'a4:bb:6d:ac:e1:fd') & (df32['Hw_src'] != 'a4:bb:6d:ac:e1:fd'))].index\n",
    "df32.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_webmine_%10 = dc:a6:32:67:66:4b\n",
    "\n",
    "index_names = df33[((df33['HW_dst'] != 'dc:a6:32:67:66:4b') & (df33['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df33.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_webmine_%50 = dc:a6:32:68:35:8a\n",
    "\n",
    "index_names = df34[((df34['HW_dst'] != 'dc:a6:32:68:35:8a') & (df34['Hw_src'] != 'dc:a6:32:68:35:8a'))].index\n",
    "df34.drop(index_names, inplace = True)\n",
    "\n",
    "# Desktop_Webmine_%100 = dc:a6:32:68:35:8a\n",
    "\n",
    "index_names = df35[((df35['HW_dst'] != 'd8:3b:bf:8f:ba:ba') & (df35['Hw_src'] != 'd8:3b:bf:8f:ba:ba'))].index\n",
    "df35.drop(index_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0d0070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#                                                               #\n",
    "#      Labeling Features for further calculations               #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "df1.insert(7, \"Is_malicious\", 1)\n",
    "df2.insert(7, \"Is_malicious\", 1)\n",
    "df3.insert(7, \"Is_malicious\", 1)\n",
    "df4.insert(7, \"Is_malicious\", 1)\n",
    "df5.insert(7, \"Is_malicious\", 1)\n",
    "df6.insert(7, \"Is_malicious\", 1)\n",
    "df7.insert(7, \"Is_malicious\", 1)\n",
    "\n",
    "# ========================================================\n",
    "\n",
    "df8.insert(7, \"Is_malicious\", 0)\n",
    "df9.insert(7, \"Is_malicious\", 0)\n",
    "df10.insert(7, \"Is_malicious\", 0)\n",
    "df11.insert(7, \"Is_malicious\", 0)\n",
    "df12.insert(7, \"Is_malicious\", 0)\n",
    "df13.insert(7, \"Is_malicious\", 0)\n",
    "df14.insert(7, \"Is_malicious\", 0)\n",
    "df15.insert(7, \"Is_malicious\", 0)\n",
    "df16.insert(7, \"Is_malicious\", 0)\n",
    "df17.insert(7, \"Is_malicious\", 0)\n",
    "df18.insert(7, \"Is_malicious\", 0)\n",
    "df19.insert(7, \"Is_malicious\", 0)\n",
    "df20.insert(7, \"Is_malicious\", 0)\n",
    "df21.insert(7, \"Is_malicious\", 0)\n",
    "df22.insert(7, \"Is_malicious\", 0)\n",
    "df23.insert(7, \"Is_malicious\", 0)\n",
    "\n",
    "# ========================================================\n",
    "\n",
    "\n",
    "df32.insert(7, \"Is_malicious\", 1)\n",
    "df33.insert(7, \"Is_malicious\", 1)\n",
    "df34.insert(7, \"Is_malicious\", 1)\n",
    "df35.insert(7, \"Is_malicious\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13020e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_process(a,b,x):\n",
    "    \n",
    "    df_malicious = a.copy()\n",
    "    df_benign    = b.copy()\n",
    "    \n",
    "    from tsfresh import extract_features, select_features\n",
    "    from tsfresh.utilities.dataframe_functions import impute\n",
    "    from tsfresh import extract_features\n",
    "    from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "\n",
    "\n",
    "    df_malicious.reset_index(drop=True, inplace=True) #reset index\n",
    "    df_malicious['id']= np.floor(df_malicious.index.array/10)\n",
    "    df_benign.reset_index(drop=True, inplace=True) #reset index\n",
    "    df_benign['id']= np.floor(df_benign.index.array/10)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    tf1=tsfresh.extract_features(df_malicious,impute_function=impute, column_kind='Is_malicious',\n",
    "                                 column_id='id',column_sort=\"Time\",column_value = \"Length\")\n",
    "    tf1['class']= 1\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    tf2=tsfresh.extract_features(df_benign,impute_function=impute, column_kind='Is_malicious',\n",
    "                                 column_id='id',column_sort=\"Time\",column_value = \"Length\")\n",
    "    tf2['class']= 0\n",
    "    \n",
    "\n",
    "\n",
    "    tf2.columns = tf1.columns\n",
    "\n",
    "    features=pd.concat([tf1,tf2])\n",
    "    #features.reset_index(drop=True, inplace=True) #reset index\n",
    "    \n",
    "#   best_features = pd.read_csv('/home/ege/Desktop/Mining_data/mining/new_captures/features_final.csv')\n",
    "\n",
    "    features2 = features.copy()\n",
    "    features2.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    y = pd.Series(data = features2['class'], index=features2.index)\n",
    "    \n",
    "    from tsfresh.examples import load_robot_execution_failures\n",
    "    from tsfresh import extract_features, select_features\n",
    "    from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "\n",
    "    relevance_table = calculate_relevance_table(features2, y)\n",
    "    relevance_table = relevance_table[relevance_table.relevant]\n",
    "    relevance_table.sort_values(\"p_value\", inplace=True)\n",
    "\n",
    "    relevance_table\n",
    "    \n",
    "    best_features = relevance_table[relevance_table['p_value'] <= 0.05]\n",
    "\n",
    "    df_ML = pd.DataFrame()\n",
    "\n",
    "    for pkt in best_features:\n",
    "        df_ML[best_features.feature] = features[best_features.feature]\n",
    "\n",
    "    final = ML_Process(df_ML,x)\n",
    "    \n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1db46d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_Process(df_ML,x):\n",
    "    df_results = x.copy() \n",
    "    print('let the ml starts')\n",
    "  \n",
    "    from sklearn import neighbors, metrics\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    #X = df_finalized[['Time', 'Length','Protocol']].values\n",
    "    X = df_ML.drop('class',axis=1).to_numpy()\n",
    "    #y = df_finalized[['Is_malicious']]\n",
    "    y = df_ML['class'].to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "    #print(X,y)\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    Le = LabelEncoder()\n",
    "    for i in range(len(X[0])):\n",
    "        X[:, i] = Le.fit_transform(X[:, i])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=8675309)\n",
    " \n",
    "    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    #from xgboost import XGBClassifier\n",
    "    from sklearn import model_selection\n",
    "    from sklearn.utils import class_weight\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    y_train = y_train.ravel()\n",
    "    dfs = []\n",
    "    models = [\n",
    "          ('LogReg', LogisticRegression()), \n",
    "          #('RF', RandomForestClassifier()),\n",
    "          ('KNN', KNeighborsClassifier()),\n",
    "          ('SVM', SVC()), \n",
    "          ('GNB', GaussianNB())\n",
    "          #('XGB', XGBClassifier())\n",
    "            ]\n",
    "    results = []\n",
    "    names = []\n",
    "    scoring = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted', 'roc_auc']\n",
    "    target_names = ['malignant', 'benign']\n",
    "    for name, model in models:\n",
    "        kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state=90210)\n",
    "        cv_results = model_selection.cross_validate(model, X_train, y_train, cv=kfold, \n",
    "                                                    scoring=scoring)\n",
    "  \n",
    "        clf = model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(name)\n",
    "        print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        this_df = pd.DataFrame(cv_results)\n",
    "        this_df['model'] = name\n",
    "        dfs.append(this_df)\n",
    "        df_resulta = df_results.append(dfs)\n",
    "        final = pd.concat(dfs, ignore_index=True)\n",
    "        print(final)\n",
    "\n",
    "\n",
    "    return(final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0a48abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aee553c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 9880\n",
      "benign: 2360951\n",
      "0 NAN in malicious!\n",
      "0 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 9880\n",
      "benign: 2360951\n",
      "1- Are we here?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 142/142 [00:02<00:00, 67.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2- Are we here?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 160/160 [06:45<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3- Are we here?\n",
      "4- Are we here?\n",
      "let the ml starts\n",
      "6- Are we here?\n",
      "7- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      1.00      1.00     59021\n",
      "      benign       0.87      0.54      0.67       250\n",
      "\n",
      "    accuracy                           1.00     59271\n",
      "   macro avg       0.93      0.77      0.83     59271\n",
      "weighted avg       1.00      1.00      1.00     59271\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  4.252312    0.071560       0.997582                 0.997336   \n",
      "1  3.363858    0.069667       0.997441                 0.997195   \n",
      "2  4.176279    0.069942       0.997750                 0.997568   \n",
      "3  4.123696    0.069804       0.997385                 0.997058   \n",
      "4  4.966840    0.087749       0.997750                 0.997502   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.997582          0.997381      0.986014  LogReg  \n",
      "1              0.997441          0.997150      0.995396  LogReg  \n",
      "2              0.997750          0.997509      0.994172  LogReg  \n",
      "3              0.997385          0.997035      0.990893  LogReg  \n",
      "4              0.997750          0.997562      0.993057  LogReg  \n",
      "10- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      1.00      1.00     59021\n",
      "      benign       0.71      0.29      0.41       250\n",
      "\n",
      "    accuracy                           1.00     59271\n",
      "   macro avg       0.85      0.64      0.70     59271\n",
      "weighted avg       1.00      1.00      1.00     59271\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  4.252312    0.071560       0.997582                 0.997336   \n",
      "1  3.363858    0.069667       0.997441                 0.997195   \n",
      "2  4.176279    0.069942       0.997750                 0.997568   \n",
      "3  4.123696    0.069804       0.997385                 0.997058   \n",
      "4  4.966840    0.087749       0.997750                 0.997502   \n",
      "5  0.174907  177.336972       0.996204                 0.995160   \n",
      "6  0.231846  145.038169       0.995951                 0.995043   \n",
      "7  0.372939  146.089270       0.995866                 0.994675   \n",
      "8  0.158376  153.117785       0.995838                 0.994385   \n",
      "9  0.165577  151.220577       0.996766                 0.995872   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.997582          0.997381      0.986014  LogReg  \n",
      "1              0.997441          0.997150      0.995396  LogReg  \n",
      "2              0.997750          0.997509      0.994172  LogReg  \n",
      "3              0.997385          0.997035      0.990893  LogReg  \n",
      "4              0.997750          0.997562      0.993057  LogReg  \n",
      "5              0.996204          0.995183      0.836982     KNN  \n",
      "6              0.995951          0.994786      0.835161     KNN  \n",
      "7              0.995866          0.994687      0.838460     KNN  \n",
      "8              0.995838          0.994801      0.833573     KNN  \n",
      "9              0.996766          0.995905      0.836560     KNN  \n",
      "10- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      1.00      1.00     59021\n",
      "      benign       0.00      0.00      0.00       250\n",
      "\n",
      "    accuracy                           1.00     59271\n",
      "   macro avg       0.50      0.50      0.50     59271\n",
      "weighted avg       0.99      1.00      0.99     59271\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0    4.252312    0.071560       0.997582                 0.997336   \n",
      "1    3.363858    0.069667       0.997441                 0.997195   \n",
      "2    4.176279    0.069942       0.997750                 0.997568   \n",
      "3    4.123696    0.069804       0.997385                 0.997058   \n",
      "4    4.966840    0.087749       0.997750                 0.997502   \n",
      "5    0.174907  177.336972       0.996204                 0.995160   \n",
      "6    0.231846  145.038169       0.995951                 0.995043   \n",
      "7    0.372939  146.089270       0.995866                 0.994675   \n",
      "8    0.158376  153.117785       0.995838                 0.994385   \n",
      "9    0.165577  151.220577       0.996766                 0.995872   \n",
      "10  56.150000   22.349212       0.995866                 0.991750   \n",
      "11  47.515241   21.929520       0.995388                 0.990798   \n",
      "12  47.456683   22.102044       0.995557                 0.991134   \n",
      "13  66.551781   26.887814       0.995951                 0.991918   \n",
      "14  59.978723   27.674355       0.996485                 0.992982   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.997582          0.997381      0.986014  LogReg  \n",
      "1               0.997441          0.997150      0.995396  LogReg  \n",
      "2               0.997750          0.997509      0.994172  LogReg  \n",
      "3               0.997385          0.997035      0.990893  LogReg  \n",
      "4               0.997750          0.997562      0.993057  LogReg  \n",
      "5               0.996204          0.995183      0.836982     KNN  \n",
      "6               0.995951          0.994786      0.835161     KNN  \n",
      "7               0.995866          0.994687      0.838460     KNN  \n",
      "8               0.995838          0.994801      0.833573     KNN  \n",
      "9               0.996766          0.995905      0.836560     KNN  \n",
      "10              0.995866          0.993804      0.978139     SVM  \n",
      "11              0.995388          0.993088      0.981449     SVM  \n",
      "12              0.995557          0.993341      0.988833     SVM  \n",
      "13              0.995951          0.993930      0.970459     SVM  \n",
      "14              0.996485          0.994731      0.981106     SVM  \n",
      "10- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      1.00      1.00     59021\n",
      "      benign       1.00      1.00      1.00       250\n",
      "\n",
      "    accuracy                           1.00     59271\n",
      "   macro avg       1.00      1.00      1.00     59271\n",
      "weighted avg       1.00      1.00      1.00     59271\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0    4.252312    0.071560       0.997582                 0.997336   \n",
      "1    3.363858    0.069667       0.997441                 0.997195   \n",
      "2    4.176279    0.069942       0.997750                 0.997568   \n",
      "3    4.123696    0.069804       0.997385                 0.997058   \n",
      "4    4.966840    0.087749       0.997750                 0.997502   \n",
      "5    0.174907  177.336972       0.996204                 0.995160   \n",
      "6    0.231846  145.038169       0.995951                 0.995043   \n",
      "7    0.372939  146.089270       0.995866                 0.994675   \n",
      "8    0.158376  153.117785       0.995838                 0.994385   \n",
      "9    0.165577  151.220577       0.996766                 0.995872   \n",
      "10  56.150000   22.349212       0.995866                 0.991750   \n",
      "11  47.515241   21.929520       0.995388                 0.990798   \n",
      "12  47.456683   22.102044       0.995557                 0.991134   \n",
      "13  66.551781   26.887814       0.995951                 0.991918   \n",
      "14  59.978723   27.674355       0.996485                 0.992982   \n",
      "15   1.236787    0.183727       0.999888                 0.999888   \n",
      "16   0.450588    0.181854       0.999972                 0.999972   \n",
      "17   0.447922    0.181691       0.999972                 0.999972   \n",
      "18   0.447722    0.669969       1.000000                 1.000000   \n",
      "19   0.629294    0.183238       0.999944                 0.999944   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.997582          0.997381      0.986014  LogReg  \n",
      "1               0.997441          0.997150      0.995396  LogReg  \n",
      "2               0.997750          0.997509      0.994172  LogReg  \n",
      "3               0.997385          0.997035      0.990893  LogReg  \n",
      "4               0.997750          0.997562      0.993057  LogReg  \n",
      "5               0.996204          0.995183      0.836982     KNN  \n",
      "6               0.995951          0.994786      0.835161     KNN  \n",
      "7               0.995866          0.994687      0.838460     KNN  \n",
      "8               0.995838          0.994801      0.833573     KNN  \n",
      "9               0.996766          0.995905      0.836560     KNN  \n",
      "10              0.995866          0.993804      0.978139     SVM  \n",
      "11              0.995388          0.993088      0.981449     SVM  \n",
      "12              0.995557          0.993341      0.988833     SVM  \n",
      "13              0.995951          0.993930      0.970459     SVM  \n",
      "14              0.996485          0.994731      0.981106     SVM  \n",
      "15              0.999888          0.999887      0.993197     GNB  \n",
      "16              0.999972          0.999972      1.000000     GNB  \n",
      "17              0.999972          0.999972      0.996835     GNB  \n",
      "18              1.000000          1.000000      1.000000     GNB  \n",
      "19              0.999944          0.999944      0.996000     GNB  \n",
      "10- Are we here?\n",
      "5- Are we here?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2382.6017561280023\n"
     ]
    }
   ],
   "source": [
    "# Scenario 2; Throttles\n",
    "    \n",
    "    # 1) THR: %10\n",
    "\n",
    "df_malicious = pd.concat([df33])\n",
    "df_benign = pd.concat([df8,df9,df10,df11,df12,df13,df14,df15,df16,df17,df18,df19,df20,df21,df22,df23])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_THR_10_s2 = run_process(df_malicious,df_benign,df_results)\n",
    "results_THR_10_s2.to_csv('~/results_THR_10_s2.csv')\n",
    "\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96b3e9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 26669\n",
      "benign: 2360951\n",
      "0 NAN in malicious!\n",
      "0 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 26669\n",
      "benign: 2360951\n",
      "1- Are we here?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 157/157 [00:05<00:00, 27.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2- Are we here?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 160/160 [07:32<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3- Are we here?\n",
      "4- Are we here?\n",
      "let the ml starts\n",
      "6- Are we here?\n",
      "7- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.99      1.00      1.00     59047\n",
      "      benign       0.73      0.25      0.37       644\n",
      "\n",
      "    accuracy                           0.99     59691\n",
      "   macro avg       0.86      0.62      0.68     59691\n",
      "weighted avg       0.99      0.99      0.99     59691\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  4.697168    0.082318       0.990060                 0.987925   \n",
      "1  4.273820    0.074046       0.990395                 0.988671   \n",
      "2  4.086390    0.073501       0.990311                 0.987782   \n",
      "3  5.260649    0.083827       0.990367                 0.988642   \n",
      "4  6.642900    0.278174       0.990423                 0.988355   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.990060          0.987371      0.960381  LogReg  \n",
      "1              0.990395          0.987759      0.952853  LogReg  \n",
      "2              0.990311          0.987727      0.956704  LogReg  \n",
      "3              0.990367          0.987895      0.973217  LogReg  \n",
      "4              0.990423          0.988190      0.958537  LogReg  \n",
      "10- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.99      1.00      1.00     59047\n",
      "      benign       0.72      0.45      0.55       644\n",
      "\n",
      "    accuracy                           0.99     59691\n",
      "   macro avg       0.85      0.72      0.77     59691\n",
      "weighted avg       0.99      0.99      0.99     59691\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  4.697168    0.082318       0.990060                 0.987925   \n",
      "1  4.273820    0.074046       0.990395                 0.988671   \n",
      "2  4.086390    0.073501       0.990311                 0.987782   \n",
      "3  5.260649    0.083827       0.990367                 0.988642   \n",
      "4  6.642900    0.278174       0.990423                 0.988355   \n",
      "5  0.240462  200.462288       0.991456                 0.990098   \n",
      "6  0.200873  222.812450       0.991624                 0.990381   \n",
      "7  0.439476  218.079724       0.992126                 0.991052   \n",
      "8  0.227989  181.268291       0.991595                 0.990347   \n",
      "9  0.213917  209.701744       0.991763                 0.990636   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.990060          0.987371      0.960381  LogReg  \n",
      "1              0.990395          0.987759      0.952853  LogReg  \n",
      "2              0.990311          0.987727      0.956704  LogReg  \n",
      "3              0.990367          0.987895      0.973217  LogReg  \n",
      "4              0.990423          0.988190      0.958537  LogReg  \n",
      "5              0.991456          0.990166      0.862375     KNN  \n",
      "6              0.991624          0.990570      0.847375     KNN  \n",
      "7              0.992126          0.991326      0.880893     KNN  \n",
      "8              0.991595          0.990429      0.887222     KNN  \n",
      "9              0.991763          0.990910      0.888152     KNN  \n",
      "10- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.99      1.00      0.99     59047\n",
      "      benign       0.00      0.00      0.00       644\n",
      "\n",
      "    accuracy                           0.99     59691\n",
      "   macro avg       0.49      0.50      0.50     59691\n",
      "weighted avg       0.98      0.99      0.98     59691\n",
      "\n",
      "      fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0     4.697168    0.082318       0.990060                 0.987925   \n",
      "1     4.273820    0.074046       0.990395                 0.988671   \n",
      "2     4.086390    0.073501       0.990311                 0.987782   \n",
      "3     5.260649    0.083827       0.990367                 0.988642   \n",
      "4     6.642900    0.278174       0.990423                 0.988355   \n",
      "5     0.240462  200.462288       0.991456                 0.990098   \n",
      "6     0.200873  222.812450       0.991624                 0.990381   \n",
      "7     0.439476  218.079724       0.992126                 0.991052   \n",
      "8     0.227989  181.268291       0.991595                 0.990347   \n",
      "9     0.213917  209.701744       0.991763                 0.990636   \n",
      "10  746.100234   60.463438       0.988524                 0.977180   \n",
      "11  514.241214   62.423985       0.988552                 0.977236   \n",
      "12  643.209208   65.237922       0.989334                 0.978781   \n",
      "13  392.503456   60.395298       0.988329                 0.976793   \n",
      "14  411.126225   56.613517       0.988775                 0.977677   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.990060          0.987371      0.960381  LogReg  \n",
      "1               0.990395          0.987759      0.952853  LogReg  \n",
      "2               0.990311          0.987727      0.956704  LogReg  \n",
      "3               0.990367          0.987895      0.973217  LogReg  \n",
      "4               0.990423          0.988190      0.958537  LogReg  \n",
      "5               0.991456          0.990166      0.862375     KNN  \n",
      "6               0.991624          0.990570      0.847375     KNN  \n",
      "7               0.992126          0.991326      0.880893     KNN  \n",
      "8               0.991595          0.990429      0.887222     KNN  \n",
      "9               0.991763          0.990910      0.888152     KNN  \n",
      "10              0.988524          0.982820      0.890013     SVM  \n",
      "11              0.988552          0.982861      0.882175     SVM  \n",
      "12              0.989334          0.984029      0.914143     SVM  \n",
      "13              0.988329          0.982527      0.930969     SVM  \n",
      "14              0.988775          0.983195      0.909396     SVM  \n",
      "10- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      0.93      0.96     59047\n",
      "      benign       0.11      0.80      0.19       644\n",
      "\n",
      "    accuracy                           0.93     59691\n",
      "   macro avg       0.55      0.86      0.58     59691\n",
      "weighted avg       0.99      0.93      0.95     59691\n",
      "\n",
      "      fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0     4.697168    0.082318       0.990060                 0.987925   \n",
      "1     4.273820    0.074046       0.990395                 0.988671   \n",
      "2     4.086390    0.073501       0.990311                 0.987782   \n",
      "3     5.260649    0.083827       0.990367                 0.988642   \n",
      "4     6.642900    0.278174       0.990423                 0.988355   \n",
      "5     0.240462  200.462288       0.991456                 0.990098   \n",
      "6     0.200873  222.812450       0.991624                 0.990381   \n",
      "7     0.439476  218.079724       0.992126                 0.991052   \n",
      "8     0.227989  181.268291       0.991595                 0.990347   \n",
      "9     0.213917  209.701744       0.991763                 0.990636   \n",
      "10  746.100234   60.463438       0.988524                 0.977180   \n",
      "11  514.241214   62.423985       0.988552                 0.977236   \n",
      "12  643.209208   65.237922       0.989334                 0.978781   \n",
      "13  392.503456   60.395298       0.988329                 0.976793   \n",
      "14  411.126225   56.613517       0.988775                 0.977677   \n",
      "15    0.719694    0.196977       0.920648                 0.987534   \n",
      "16    0.470626    0.194520       0.997683                 0.997662   \n",
      "17    0.470339    0.192082       0.921874                 0.988184   \n",
      "18    0.470804    0.192752       0.920115                 0.987010   \n",
      "19    0.470086    0.191257       0.931033                 0.987554   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.990060          0.987371      0.960381  LogReg  \n",
      "1               0.990395          0.987759      0.952853  LogReg  \n",
      "2               0.990311          0.987727      0.956704  LogReg  \n",
      "3               0.990367          0.987895      0.973217  LogReg  \n",
      "4               0.990423          0.988190      0.958537  LogReg  \n",
      "5               0.991456          0.990166      0.862375     KNN  \n",
      "6               0.991624          0.990570      0.847375     KNN  \n",
      "7               0.992126          0.991326      0.880893     KNN  \n",
      "8               0.991595          0.990429      0.887222     KNN  \n",
      "9               0.991763          0.990910      0.888152     KNN  \n",
      "10              0.988524          0.982820      0.890013     SVM  \n",
      "11              0.988552          0.982861      0.882175     SVM  \n",
      "12              0.989334          0.984029      0.914143     SVM  \n",
      "13              0.988329          0.982527      0.930969     SVM  \n",
      "14              0.988775          0.983195      0.909396     SVM  \n",
      "15              0.920648          0.949479      0.944309     GNB  \n",
      "16              0.997683          0.997567      0.989127     GNB  \n",
      "17              0.921874          0.950678      0.945832     GNB  \n",
      "18              0.920115          0.949012      0.942327     GNB  \n",
      "19              0.931033          0.955427      0.948759     GNB  \n",
      "10- Are we here?\n",
      "5- Are we here?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6066.748016807993\n"
     ]
    }
   ],
   "source": [
    "# 2) THR: %50\n",
    "\n",
    "df_malicious = pd.concat([df3,df32,df34])\n",
    "df_benign = pd.concat([df8,df9,df10,df11,df12,df13,df14,df15,df16,df17,df18,df19,df20,df21,df22,df23])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_THR_50_s2 = run_process(df_malicious,df_benign,df_results)\n",
    "results_THR_50_s2.to_csv('~/results_THR_50_s2.csv')\n",
    "\n",
    "\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0027d096",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 1520681\n",
      "benign: 2360951\n",
      "0 NAN in malicious!\n",
      "0 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 1520681\n",
      "benign: 2360951\n",
      "1- Are we here?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 160/160 [03:53<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2- Are we here?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 160/160 [06:20<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3- Are we here?\n",
      "4- Are we here?\n",
      "let the ml starts\n",
      "6- Are we here?\n",
      "7- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.93      0.94      0.93     59137\n",
      "      benign       0.90      0.89      0.90     37905\n",
      "\n",
      "    accuracy                           0.92     97042\n",
      "   macro avg       0.92      0.91      0.91     97042\n",
      "weighted avg       0.92      0.92      0.92     97042\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  7.146636    0.149930       0.920240                 0.920090   \n",
      "1  6.809423    0.154554       0.921357                 0.921196   \n",
      "2  7.046479    0.160028       0.919914                 0.919746   \n",
      "3  7.133878    0.197075       0.921407                 0.921277   \n",
      "4  7.365741    0.206145       0.919174                 0.919082   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.920240          0.920132      0.972171  LogReg  \n",
      "1              0.921357          0.921232      0.973207  LogReg  \n",
      "2              0.919914          0.919787      0.972173  LogReg  \n",
      "3              0.921407          0.921320      0.973167  LogReg  \n",
      "4              0.919174          0.919120      0.972727  LogReg  \n",
      "10- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.95      0.97      0.96     59137\n",
      "      benign       0.95      0.93      0.94     37905\n",
      "\n",
      "    accuracy                           0.95     97042\n",
      "   macro avg       0.95      0.95      0.95     97042\n",
      "weighted avg       0.95      0.95      0.95     97042\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  7.146636    0.149930       0.920240                 0.920090   \n",
      "1  6.809423    0.154554       0.921357                 0.921196   \n",
      "2  7.046479    0.160028       0.919914                 0.919746   \n",
      "3  7.133878    0.197075       0.921407                 0.921277   \n",
      "4  7.365741    0.206145       0.919174                 0.919082   \n",
      "5  0.297410  618.089775       0.949953                 0.949908   \n",
      "6  0.303722  612.761214       0.949781                 0.949719   \n",
      "7  0.372646  592.114176       0.949334                 0.949273   \n",
      "8  0.281538  563.718314       0.950038                 0.950005   \n",
      "9  0.286016  590.206040       0.950605                 0.950573   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.920240          0.920132      0.972171  LogReg  \n",
      "1              0.921357          0.921232      0.973207  LogReg  \n",
      "2              0.919914          0.919787      0.972173  LogReg  \n",
      "3              0.921407          0.921320      0.973167  LogReg  \n",
      "4              0.919174          0.919120      0.972727  LogReg  \n",
      "5              0.949953          0.949842      0.979035     KNN  \n",
      "6              0.949781          0.949688      0.979729     KNN  \n",
      "7              0.949334          0.949231      0.978552     KNN  \n",
      "8              0.950038          0.949914      0.979077     KNN  \n",
      "9              0.950605          0.950487      0.980456     KNN  \n",
      "10- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.95      0.96      0.95     59137\n",
      "      benign       0.94      0.91      0.93     37905\n",
      "\n",
      "    accuracy                           0.94     97042\n",
      "   macro avg       0.94      0.94      0.94     97042\n",
      "weighted avg       0.94      0.94      0.94     97042\n",
      "\n",
      "       fit_time   score_time  test_accuracy  test_precision_weighted  \\\n",
      "0      7.146636     0.149930       0.920240                 0.920090   \n",
      "1      6.809423     0.154554       0.921357                 0.921196   \n",
      "2      7.046479     0.160028       0.919914                 0.919746   \n",
      "3      7.133878     0.197075       0.921407                 0.921277   \n",
      "4      7.365741     0.206145       0.919174                 0.919082   \n",
      "5      0.297410   618.089775       0.949953                 0.949908   \n",
      "6      0.303722   612.761214       0.949781                 0.949719   \n",
      "7      0.372646   592.114176       0.949334                 0.949273   \n",
      "8      0.281538   563.718314       0.950038                 0.950005   \n",
      "9      0.286016   590.206040       0.950605                 0.950573   \n",
      "10  3667.342825  1481.231382       0.940644                 0.940567   \n",
      "11  3927.578880  1355.369773       0.941967                 0.941889   \n",
      "12  3543.437739  1420.576940       0.942224                 0.942162   \n",
      "13  3844.199178  1484.534951       0.941759                 0.941687   \n",
      "14  3586.989471  1429.988488       0.941966                 0.941893   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.920240          0.920132      0.972171  LogReg  \n",
      "1               0.921357          0.921232      0.973207  LogReg  \n",
      "2               0.919914          0.919787      0.972173  LogReg  \n",
      "3               0.921407          0.921320      0.973167  LogReg  \n",
      "4               0.919174          0.919120      0.972727  LogReg  \n",
      "5               0.949953          0.949842      0.979035     KNN  \n",
      "6               0.949781          0.949688      0.979729     KNN  \n",
      "7               0.949334          0.949231      0.978552     KNN  \n",
      "8               0.950038          0.949914      0.979077     KNN  \n",
      "9               0.950605          0.950487      0.980456     KNN  \n",
      "10              0.940644          0.940497      0.979850     SVM  \n",
      "11              0.941967          0.941829      0.979695     SVM  \n",
      "12              0.942224          0.942065      0.980780     SVM  \n",
      "13              0.941759          0.941611      0.980646     SVM  \n",
      "14              0.941966          0.941825      0.980251     SVM  \n",
      "10- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.91      0.93      0.92     59137\n",
      "      benign       0.88      0.85      0.87     37905\n",
      "\n",
      "    accuracy                           0.90     97042\n",
      "   macro avg       0.89      0.89      0.89     97042\n",
      "weighted avg       0.90      0.90      0.90     97042\n",
      "\n",
      "       fit_time   score_time  test_accuracy  test_precision_weighted  \\\n",
      "0      7.146636     0.149930       0.920240                 0.920090   \n",
      "1      6.809423     0.154554       0.921357                 0.921196   \n",
      "2      7.046479     0.160028       0.919914                 0.919746   \n",
      "3      7.133878     0.197075       0.921407                 0.921277   \n",
      "4      7.365741     0.206145       0.919174                 0.919082   \n",
      "5      0.297410   618.089775       0.949953                 0.949908   \n",
      "6      0.303722   612.761214       0.949781                 0.949719   \n",
      "7      0.372646   592.114176       0.949334                 0.949273   \n",
      "8      0.281538   563.718314       0.950038                 0.950005   \n",
      "9      0.286016   590.206040       0.950605                 0.950573   \n",
      "10  3667.342825  1481.231382       0.940644                 0.940567   \n",
      "11  3927.578880  1355.369773       0.941967                 0.941889   \n",
      "12  3543.437739  1420.576940       0.942224                 0.942162   \n",
      "13  3844.199178  1484.534951       0.941759                 0.941687   \n",
      "14  3586.989471  1429.988488       0.941966                 0.941893   \n",
      "15     1.241840     0.517526       0.897913                 0.897608   \n",
      "16     1.199836     0.517969       0.896625                 0.896295   \n",
      "17     1.199196     0.517779       0.897484                 0.897149   \n",
      "18     1.196812     0.516903       0.896933                 0.896608   \n",
      "19     1.197938     0.518734       0.896778                 0.896512   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.920240          0.920132      0.972171  LogReg  \n",
      "1               0.921357          0.921232      0.973207  LogReg  \n",
      "2               0.919914          0.919787      0.972173  LogReg  \n",
      "3               0.921407          0.921320      0.973167  LogReg  \n",
      "4               0.919174          0.919120      0.972727  LogReg  \n",
      "5               0.949953          0.949842      0.979035     KNN  \n",
      "6               0.949781          0.949688      0.979729     KNN  \n",
      "7               0.949334          0.949231      0.978552     KNN  \n",
      "8               0.950038          0.949914      0.979077     KNN  \n",
      "9               0.950605          0.950487      0.980456     KNN  \n",
      "10              0.940644          0.940497      0.979850     SVM  \n",
      "11              0.941967          0.941829      0.979695     SVM  \n",
      "12              0.942224          0.942065      0.980780     SVM  \n",
      "13              0.941759          0.941611      0.980646     SVM  \n",
      "14              0.941966          0.941825      0.980251     SVM  \n",
      "15              0.897913          0.897647      0.914326     GNB  \n",
      "16              0.896625          0.896305      0.914994     GNB  \n",
      "17              0.897484          0.897148      0.918033     GNB  \n",
      "18              0.896933          0.896640      0.914426     GNB  \n",
      "19              0.896778          0.896584      0.910927     GNB  \n",
      "10- Are we here?\n",
      "5- Are we here?\n",
      "37348.54506377301\n"
     ]
    }
   ],
   "source": [
    " # 3) THR: %100\n",
    "    \n",
    "df_malicious = pd.concat([df1,df2,df4,df5,df6,df7,df35])\n",
    "df_benign = pd.concat([df8,df9,df10,df11,df12,df13,df14,df15,df16,df17,df18,df19,df20,df21,df22,df23])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_THR_100_s2 = run_process(df_malicious,df_benign,df_results)\n",
    "results_THR_100_s2.to_csv('~/results_THR_100_s2.csv')\n",
    "\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92c20412",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_S2 = pd.concat([results_THR_100_s2,results_THR_50_s2,results_THR_10_s2])\n",
    "df_S2.to_csv('/home/csl/Desktop/ege/Major_Rev_results/inbalanced/df_S2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7067074c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 305874\n",
      "benign: 2360951\n",
      "0 NAN in malicious!\n",
      "0 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 305874\n",
      "benign: 2360951\n",
      "1- Are we here?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 160/160 [00:44<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2- Are we here?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 160/160 [06:15<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3- Are we here?\n",
      "4- Are we here?\n",
      "let the ml starts\n",
      "6- Are we here?\n",
      "7- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.94      0.97      0.96     59006\n",
      "      benign       0.70      0.52      0.60      7665\n",
      "\n",
      "    accuracy                           0.92     66671\n",
      "   macro avg       0.82      0.75      0.78     66671\n",
      "weighted avg       0.91      0.92      0.91     66671\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  7.302426    0.101362       0.920256                 0.912004   \n",
      "1  4.517509    0.165511       0.922156                 0.914830   \n",
      "2  5.500190    0.100484       0.919581                 0.912030   \n",
      "3  7.565541    0.117465       0.924004                 0.917690   \n",
      "4  7.542882    0.117522       0.925479                 0.919659   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.920256          0.912643      0.934026  LogReg  \n",
      "1              0.922156          0.915657      0.934290  LogReg  \n",
      "2              0.919581          0.913427      0.928121  LogReg  \n",
      "3              0.924004          0.919058      0.935141  LogReg  \n",
      "4              0.925479          0.921078      0.933491  LogReg  \n",
      "10- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.96      0.98      0.97     59006\n",
      "      benign       0.85      0.72      0.78      7665\n",
      "\n",
      "    accuracy                           0.95     66671\n",
      "   macro avg       0.91      0.85      0.88     66671\n",
      "weighted avg       0.95      0.95      0.95     66671\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  7.302426    0.101362       0.920256                 0.912004   \n",
      "1  4.517509    0.165511       0.922156                 0.914830   \n",
      "2  5.500190    0.100484       0.919581                 0.912030   \n",
      "3  7.565541    0.117465       0.924004                 0.917690   \n",
      "4  7.542882    0.117522       0.925479                 0.919659   \n",
      "5  0.225092  278.214430       0.951979                 0.949741   \n",
      "6  0.307347  276.381060       0.950054                 0.947790   \n",
      "7  0.471454  270.621322       0.950354                 0.948086   \n",
      "8  0.246812  259.362746       0.950552                 0.948219   \n",
      "9  0.466007  263.837606       0.950102                 0.947837   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.920256          0.912643      0.934026  LogReg  \n",
      "1              0.922156          0.915657      0.934290  LogReg  \n",
      "2              0.919581          0.913427      0.928121  LogReg  \n",
      "3              0.924004          0.919058      0.935141  LogReg  \n",
      "4              0.925479          0.921078      0.933491  LogReg  \n",
      "5              0.951979          0.949986      0.941674     KNN  \n",
      "6              0.950054          0.948231      0.938139     KNN  \n",
      "7              0.950354          0.948461      0.940024     KNN  \n",
      "8              0.950552          0.948483      0.938594     KNN  \n",
      "9              0.950102          0.948292      0.939901     KNN  \n",
      "10- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.96      0.99      0.97     59006\n",
      "      benign       0.88      0.66      0.76      7665\n",
      "\n",
      "    accuracy                           0.95     66671\n",
      "   macro avg       0.92      0.83      0.87     66671\n",
      "weighted avg       0.95      0.95      0.95     66671\n",
      "\n",
      "       fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0      7.302426    0.101362       0.920256                 0.912004   \n",
      "1      4.517509    0.165511       0.922156                 0.914830   \n",
      "2      5.500190    0.100484       0.919581                 0.912030   \n",
      "3      7.565541    0.117465       0.924004                 0.917690   \n",
      "4      7.542882    0.117522       0.925479                 0.919659   \n",
      "5      0.225092  278.214430       0.951979                 0.949741   \n",
      "6      0.307347  276.381060       0.950054                 0.947790   \n",
      "7      0.471454  270.621322       0.950354                 0.948086   \n",
      "8      0.246812  259.362746       0.950552                 0.948219   \n",
      "9      0.466007  263.837606       0.950102                 0.947837   \n",
      "10  1334.749323  640.888330       0.948554                 0.946100   \n",
      "11  1442.945778  640.570855       0.947179                 0.944476   \n",
      "12  1479.196543  654.183985       0.946729                 0.944053   \n",
      "13  1255.230536  654.991725       0.948353                 0.945909   \n",
      "14  1257.337161  648.015013       0.947778                 0.945093   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.920256          0.912643      0.934026  LogReg  \n",
      "1               0.922156          0.915657      0.934290  LogReg  \n",
      "2               0.919581          0.913427      0.928121  LogReg  \n",
      "3               0.924004          0.919058      0.935141  LogReg  \n",
      "4               0.925479          0.921078      0.933491  LogReg  \n",
      "5               0.951979          0.949986      0.941674     KNN  \n",
      "6               0.950054          0.948231      0.938139     KNN  \n",
      "7               0.950354          0.948461      0.940024     KNN  \n",
      "8               0.950552          0.948483      0.938594     KNN  \n",
      "9               0.950102          0.948292      0.939901     KNN  \n",
      "10              0.948554          0.944903      0.948997     SVM  \n",
      "11              0.947179          0.943751      0.946158     SVM  \n",
      "12              0.946729          0.943097      0.942841     SVM  \n",
      "13              0.948353          0.944817      0.943698     SVM  \n",
      "14              0.947778          0.944507      0.943475     SVM  \n",
      "10- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      1.00      1.00     59006\n",
      "      benign       1.00      0.98      0.99      7665\n",
      "\n",
      "    accuracy                           1.00     66671\n",
      "   macro avg       1.00      0.99      0.99     66671\n",
      "weighted avg       1.00      1.00      1.00     66671\n",
      "\n",
      "       fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0      7.302426    0.101362       0.920256                 0.912004   \n",
      "1      4.517509    0.165511       0.922156                 0.914830   \n",
      "2      5.500190    0.100484       0.919581                 0.912030   \n",
      "3      7.565541    0.117465       0.924004                 0.917690   \n",
      "4      7.542882    0.117522       0.925479                 0.919659   \n",
      "5      0.225092  278.214430       0.951979                 0.949741   \n",
      "6      0.307347  276.381060       0.950054                 0.947790   \n",
      "7      0.471454  270.621322       0.950354                 0.948086   \n",
      "8      0.246812  259.362746       0.950552                 0.948219   \n",
      "9      0.466007  263.837606       0.950102                 0.947837   \n",
      "10  1334.749323  640.888330       0.948554                 0.946100   \n",
      "11  1442.945778  640.570855       0.947179                 0.944476   \n",
      "12  1479.196543  654.183985       0.946729                 0.944053   \n",
      "13  1255.230536  654.991725       0.948353                 0.945909   \n",
      "14  1257.337161  648.015013       0.947778                 0.945093   \n",
      "15     0.789787    0.257989       0.997275                 0.997284   \n",
      "16     0.714845    0.232840       0.997925                 0.997927   \n",
      "17     0.713305    0.231702       0.998000                 0.998004   \n",
      "18     0.713057    0.231813       0.997850                 0.997855   \n",
      "19     0.715599    0.233758       0.997600                 0.997606   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.920256          0.912643      0.934026  LogReg  \n",
      "1               0.922156          0.915657      0.934290  LogReg  \n",
      "2               0.919581          0.913427      0.928121  LogReg  \n",
      "3               0.924004          0.919058      0.935141  LogReg  \n",
      "4               0.925479          0.921078      0.933491  LogReg  \n",
      "5               0.951979          0.949986      0.941674     KNN  \n",
      "6               0.950054          0.948231      0.938139     KNN  \n",
      "7               0.950354          0.948461      0.940024     KNN  \n",
      "8               0.950552          0.948483      0.938594     KNN  \n",
      "9               0.950102          0.948292      0.939901     KNN  \n",
      "10              0.948554          0.944903      0.948997     SVM  \n",
      "11              0.947179          0.943751      0.946158     SVM  \n",
      "12              0.946729          0.943097      0.942841     SVM  \n",
      "13              0.948353          0.944817      0.943698     SVM  \n",
      "14              0.947778          0.944507      0.943475     SVM  \n",
      "15              0.997275          0.997261      0.995491     GNB  \n",
      "16              0.997925          0.997918      0.997138     GNB  \n",
      "17              0.998000          0.997993      0.997417     GNB  \n",
      "18              0.997850          0.997841      0.997575     GNB  \n",
      "19              0.997600          0.997589      0.995439     GNB  \n",
      "10- Are we here?\n",
      "5- Are we here?\n",
      "15967.059617698003\n"
     ]
    }
   ],
   "source": [
    "## S3; In-browser VS Binary ##\n",
    "\n",
    "  #1) In-Browser\n",
    "df_malicious = pd.concat([df3,df5,df6,df7,df32,df33,df34,df35])\n",
    "df_benign = pd.concat([df8,df9,df10,df11,df12,df13,df14,df15,df16,df17,df18,df19,df20,df21,df22,df23])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_In_s3 = run_process(df_malicious,df_benign,df_results)\n",
    "results_In_s3.to_csv('~/results_In_s3.csv')\n",
    "\n",
    "\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db597928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 1251356\n",
      "benign: 2360951\n",
      "0 NAN in malicious!\n",
      "0 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 1251356\n",
      "benign: 2360951\n",
      "1- Are we here?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 160/160 [03:05<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2- Are we here?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 160/160 [06:11<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3- Are we here?\n",
      "4- Are we here?\n",
      "let the ml starts\n",
      "6- Are we here?\n",
      "7- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.97      0.97     58875\n",
      "      benign       0.94      0.96      0.95     31433\n",
      "\n",
      "    accuracy                           0.97     90308\n",
      "   macro avg       0.96      0.97      0.96     90308\n",
      "weighted avg       0.97      0.97      0.97     90308\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  6.529183    0.141626       0.966061                 0.966464   \n",
      "1  6.490053    0.147844       0.965747                 0.966143   \n",
      "2  6.491731    0.149736       0.967205                 0.967487   \n",
      "3  6.371884    0.151092       0.966005                 0.966444   \n",
      "4  6.882980    0.236319       0.965709                 0.966062   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.966061          0.966165      0.992302  LogReg  \n",
      "1              0.965747          0.965852      0.991956  LogReg  \n",
      "2              0.967205          0.967286      0.992520  LogReg  \n",
      "3              0.966005          0.966120      0.992884  LogReg  \n",
      "4              0.965709          0.965808      0.991601  LogReg  \n",
      "10- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.98      0.98     58875\n",
      "      benign       0.96      0.97      0.97     31433\n",
      "\n",
      "    accuracy                           0.98     90308\n",
      "   macro avg       0.97      0.98      0.97     90308\n",
      "weighted avg       0.98      0.98      0.98     90308\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  6.529183    0.141626       0.966061                 0.966464   \n",
      "1  6.490053    0.147844       0.965747                 0.966143   \n",
      "2  6.491731    0.149736       0.967205                 0.967487   \n",
      "3  6.371884    0.151092       0.966005                 0.966444   \n",
      "4  6.882980    0.236319       0.965709                 0.966062   \n",
      "5  0.279194  498.130990       0.976451                 0.976528   \n",
      "6  0.273043  495.983097       0.976100                 0.976141   \n",
      "7  0.275763  515.886531       0.977115                 0.977153   \n",
      "8  0.296116  496.476736       0.976414                 0.976517   \n",
      "9  0.275000  508.370720       0.975380                 0.975424   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.966061          0.966165      0.992302  LogReg  \n",
      "1              0.965747          0.965852      0.991956  LogReg  \n",
      "2              0.967205          0.967286      0.992520  LogReg  \n",
      "3              0.966005          0.966120      0.992884  LogReg  \n",
      "4              0.965709          0.965808      0.991601  LogReg  \n",
      "5              0.976451          0.976477      0.991618     KNN  \n",
      "6              0.976100          0.976117      0.991038     KNN  \n",
      "7              0.977115          0.977130      0.990861     KNN  \n",
      "8              0.976414          0.976447      0.991700     KNN  \n",
      "9              0.975380          0.975398      0.990224     KNN  \n",
      "10- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.98      0.98     58875\n",
      "      benign       0.96      0.97      0.96     31433\n",
      "\n",
      "    accuracy                           0.97     90308\n",
      "   macro avg       0.97      0.97      0.97     90308\n",
      "weighted avg       0.97      0.97      0.97     90308\n",
      "\n",
      "       fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0      6.529183    0.141626       0.966061                 0.966464   \n",
      "1      6.490053    0.147844       0.965747                 0.966143   \n",
      "2      6.491731    0.149736       0.967205                 0.967487   \n",
      "3      6.371884    0.151092       0.966005                 0.966444   \n",
      "4      6.882980    0.236319       0.965709                 0.966062   \n",
      "5      0.279194  498.130990       0.976451                 0.976528   \n",
      "6      0.273043  495.983097       0.976100                 0.976141   \n",
      "7      0.275763  515.886531       0.977115                 0.977153   \n",
      "8      0.296116  496.476736       0.976414                 0.976517   \n",
      "9      0.275000  508.370720       0.975380                 0.975424   \n",
      "10  1380.872459  572.743395       0.971320                 0.971456   \n",
      "11  1433.763674  601.725967       0.971228                 0.971321   \n",
      "12  1397.161671  591.987622       0.972446                 0.972552   \n",
      "13  1439.850106  568.841441       0.971210                 0.971370   \n",
      "14  1413.278408  567.040143       0.970508                 0.970657   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.966061          0.966165      0.992302  LogReg  \n",
      "1               0.965747          0.965852      0.991956  LogReg  \n",
      "2               0.967205          0.967286      0.992520  LogReg  \n",
      "3               0.966005          0.966120      0.992884  LogReg  \n",
      "4               0.965709          0.965808      0.991601  LogReg  \n",
      "5               0.976451          0.976477      0.991618     KNN  \n",
      "6               0.976100          0.976117      0.991038     KNN  \n",
      "7               0.977115          0.977130      0.990861     KNN  \n",
      "8               0.976414          0.976447      0.991700     KNN  \n",
      "9               0.975380          0.975398      0.990224     KNN  \n",
      "10              0.971320          0.971365      0.992355     SVM  \n",
      "11              0.971228          0.971262      0.992075     SVM  \n",
      "12              0.972446          0.972483      0.992561     SVM  \n",
      "13              0.971210          0.971261      0.992650     SVM  \n",
      "14              0.970508          0.970557      0.991844     SVM  \n",
      "10- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.99      0.94      0.96     58875\n",
      "      benign       0.90      0.98      0.94     31433\n",
      "\n",
      "    accuracy                           0.95     90308\n",
      "   macro avg       0.94      0.96      0.95     90308\n",
      "weighted avg       0.96      0.95      0.95     90308\n",
      "\n",
      "       fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0      6.529183    0.141626       0.966061                 0.966464   \n",
      "1      6.490053    0.147844       0.965747                 0.966143   \n",
      "2      6.491731    0.149736       0.967205                 0.967487   \n",
      "3      6.371884    0.151092       0.966005                 0.966444   \n",
      "4      6.882980    0.236319       0.965709                 0.966062   \n",
      "5      0.279194  498.130990       0.976451                 0.976528   \n",
      "6      0.273043  495.983097       0.976100                 0.976141   \n",
      "7      0.275763  515.886531       0.977115                 0.977153   \n",
      "8      0.296116  496.476736       0.976414                 0.976517   \n",
      "9      0.275000  508.370720       0.975380                 0.975424   \n",
      "10  1380.872459  572.743395       0.971320                 0.971456   \n",
      "11  1433.763674  601.725967       0.971228                 0.971321   \n",
      "12  1397.161671  591.987622       0.972446                 0.972552   \n",
      "13  1439.850106  568.841441       0.971210                 0.971370   \n",
      "14  1413.278408  567.040143       0.970508                 0.970657   \n",
      "15     1.159954    0.362143       0.953271                 0.956641   \n",
      "16     1.160706    0.429400       0.952976                 0.956337   \n",
      "17     1.150197    0.351479       0.954286                 0.957393   \n",
      "18     1.134848    0.347407       0.951850                 0.955692   \n",
      "19     1.133603    0.342258       0.954562                 0.957722   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.966061          0.966165      0.992302  LogReg  \n",
      "1               0.965747          0.965852      0.991956  LogReg  \n",
      "2               0.967205          0.967286      0.992520  LogReg  \n",
      "3               0.966005          0.966120      0.992884  LogReg  \n",
      "4               0.965709          0.965808      0.991601  LogReg  \n",
      "5               0.976451          0.976477      0.991618     KNN  \n",
      "6               0.976100          0.976117      0.991038     KNN  \n",
      "7               0.977115          0.977130      0.990861     KNN  \n",
      "8               0.976414          0.976447      0.991700     KNN  \n",
      "9               0.975380          0.975398      0.990224     KNN  \n",
      "10              0.971320          0.971365      0.992355     SVM  \n",
      "11              0.971228          0.971262      0.992075     SVM  \n",
      "12              0.972446          0.972483      0.992561     SVM  \n",
      "13              0.971210          0.971261      0.992650     SVM  \n",
      "14              0.970508          0.970557      0.991844     SVM  \n",
      "15              0.953271          0.953739      0.965276     GNB  \n",
      "16              0.952976          0.953455      0.964833     GNB  \n",
      "17              0.954286          0.954734      0.965539     GNB  \n",
      "18              0.951850          0.952388      0.964319     GNB  \n",
      "19              0.954562          0.955020      0.965574     GNB  \n",
      "10- Are we here?\n",
      "5- Are we here?\n",
      "17183.10876534402\n"
     ]
    }
   ],
   "source": [
    "#2) Binary\n",
    "df_malicious = pd.concat([df1,df2,df4])\n",
    "df_benign = pd.concat([df8,df9,df10,df11,df12,df13,df14,df15,df16,df17,df18,df19,df20,df21,df22,df23])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_Host_s3 = run_process(df_malicious,df_benign,df_results)\n",
    "results_Host_s3.to_csv('~/results_Host_s3.csv')\n",
    "\n",
    "\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31e39654",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_S3 = pd.concat([results_Host_s3,results_In_s3])\n",
    "df_S3.to_csv('~/df_S3.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
