{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "545bcbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tsfresh\n",
    "import os\n",
    "import json\n",
    "import scapy\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from scapy.all import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") #ignore warnings caused by \n",
    "\n",
    "\n",
    "#################################################################\n",
    "#                                                               #\n",
    "#               malicious csv files import                      #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "df1 = pd.read_csv('~/malicious/WebOS_binary.csv') #\n",
    "df2 = pd.read_csv('~/malicious/Server_Binary.csv') #\n",
    "df3 = pd.read_csv('~/malicious/Raspberry_Webmine_Robust.csv')\n",
    "df4 = pd.read_csv('~/malicious/Raspberry_Binary.csv') #\n",
    "df5 = pd.read_csv('~/malicious/Raspberry_Webmine_Aggressive.csv')\n",
    "df6 = pd.read_csv('~/malicious/Raspberry_WebminePool_Aggressive.csv')\n",
    "df7 = pd.read_csv('~/malicious/Server_WebminePool_Aggressive.csv') #\n",
    "\n",
    "df32 = pd.read_csv('~/malicious/Server_WebminePool_Robust.csv') #\n",
    "df33 = pd.read_csv('~/malicious/Raspberry_WebminePool_Stealthy.csv') #\n",
    "df34 = pd.read_csv('~/malicious/Raspberry_WebminePool_Robust.csv') #\n",
    "df35 = pd.read_csv('~/malicious/Desktop_WebminePool_Aggressive.csv') #\n",
    "\n",
    "\n",
    "#################################################################\n",
    "#                                                               #\n",
    "#               benign csv files import                         #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "############### LAPTOP #############\n",
    "\n",
    "df8 = pd.read_csv('~/benign2/Laptop/Laptop_download_benign.csv')\n",
    "df9 = pd.read_csv('~/benign2/Laptop/Laptop_idle_benign.csv')\n",
    "df10 = pd.read_csv('~/benign2/Laptop/Laptop_interactive_benign.csv')\n",
    "df11 = pd.read_csv('~/benign2/Laptop/Laptop_video_benign.csv')\n",
    "df12 = pd.read_csv('~/benign2/Laptop/Laptop_webbrowsing_benign.csv')\n",
    "\n",
    "############### Raspberry ##########\n",
    "\n",
    "df13 = pd.read_csv('~/benign2/Rasberry/Raspberry_download_benign.csv')\n",
    "df14 = pd.read_csv('~/benign2/Rasberry/Raspberry_idle_benign.csv')\n",
    "df15 = pd.read_csv('~/benign2/Rasberry/Raspberry_interactive_benign.csv')\n",
    "df16 = pd.read_csv('~/benign2/Rasberry/Raspberry_video_benign.csv')\n",
    "df17 = pd.read_csv('~/benign2/Rasberry/Raspberry_webbrowsing_benign.csv')\n",
    "\n",
    "############### Server ############\n",
    "\n",
    "\n",
    "df18 = pd.read_csv('~/benign2/Server/Server_download_benign.csv')\n",
    "df19 = pd.read_csv('~/benign2/Server/Server_idle_benign.csv')\n",
    "df20 = pd.read_csv('~/benign2/Server/Server_interactive_benign.csv')\n",
    "df21 = pd.read_csv('~/benign2/Server/Server_video_benign.csv')\n",
    "df22 = pd.read_csv('~/benign2/Server/Server_webbrowsing_benign.csv')\n",
    "\n",
    "############### WebOS ############\n",
    "\n",
    "df23 = pd.read_csv('~/benign2/WebOS/Webos_video(live&normal)_benign.csv')\n",
    "\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8ca31fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 -->> 43173\n",
      "df2 -->> 1213354\n",
      "df3 -->> 3621\n",
      "df4 -->> 22111\n",
      "df5 -->> 14156\n",
      "df6 -->> 24476\n",
      "df7 -->> 3106\n",
      "df32 -->> 18460\n",
      "df33 -->> 10285\n",
      "df34 -->> 7708\n",
      "df35 -->> 234892\n",
      "/////////////////////////////////////////////////\n",
      " LAPTOP \n",
      "df8 -->> 442866\n",
      "df9 -->> 113602\n",
      "df10 -->> 81681\n",
      "df11 -->> 29010\n",
      "df12 -->> 99235\n",
      " Raspberry \n",
      "df13 -->> 276808\n",
      "df14 -->> 73\n",
      "df15 -->> 104241\n",
      "df16 -->> 57205\n",
      "df17 -->> 123298\n",
      " Server \n",
      "df18 -->> 564831\n",
      "df19 -->> 13459\n",
      "df20 -->> 123728\n",
      "df21 -->> 109497\n",
      "df22 -->> 43713\n",
      " WebOS \n",
      "df23 -->> 177704\n",
      "malicious: 1595342\n",
      "benign: 2360951\n"
     ]
    }
   ],
   "source": [
    "print(\"df1 -->> {}\".format(len(df1)))\n",
    "print(\"df2 -->> {}\".format(len(df2)))\n",
    "print(\"df3 -->> {}\".format(len(df3)))\n",
    "print(\"df4 -->> {}\".format(len(df4)))\n",
    "print(\"df5 -->> {}\".format(len(df5)))\n",
    "print(\"df6 -->> {}\".format(len(df6)))\n",
    "print(\"df7 -->> {}\".format(len(df7)))\n",
    "print(\"df32 -->> {}\".format(len(df32)))\n",
    "print(\"df33 -->> {}\".format(len(df33)))\n",
    "print(\"df34 -->> {}\".format(len(df34)))\n",
    "print(\"df35 -->> {}\".format(len(df35)))\n",
    "print(\"/////////////////////////////////////////////////\")\n",
    "\n",
    "print(\" LAPTOP \")\n",
    "\n",
    "\n",
    "print(\"df8 -->> {}\".format(len(df8)))\n",
    "print(\"df9 -->> {}\".format(len(df9)))\n",
    "print(\"df10 -->> {}\".format(len(df10)))\n",
    "print(\"df11 -->> {}\".format(len(df11)))\n",
    "print(\"df12 -->> {}\".format(len(df12)))\n",
    "\n",
    "print(\" Raspberry \")\n",
    "\n",
    "\n",
    "print(\"df13 -->> {}\".format(len(df13)))\n",
    "print(\"df14 -->> {}\".format(len(df14)))\n",
    "print(\"df15 -->> {}\".format(len(df15)))\n",
    "print(\"df16 -->> {}\".format(len(df16)))\n",
    "print(\"df17 -->> {}\".format(len(df17)))\n",
    "\n",
    "print(\" Server \")\n",
    "\n",
    "print(\"df18 -->> {}\".format(len(df18)))\n",
    "print(\"df19 -->> {}\".format(len(df19)))\n",
    "print(\"df20 -->> {}\".format(len(df20)))\n",
    "print(\"df21 -->> {}\".format(len(df21)))\n",
    "print(\"df22 -->> {}\".format(len(df22)))\n",
    "\n",
    "print(\" WebOS \")\n",
    "\n",
    "print(\"df23 -->> {}\".format(len(df23)))\n",
    "\n",
    "\n",
    "df_malicious = pd.concat([df1,df2,df3,df4,df5,df6,df7,df32,df33,df34,df35])\n",
    " \n",
    "df_benign = pd.concat([df8,df9,df10,df11,df12,df13,df14,df15,df16,df17,df18,df19,df20,df21,df22,df23])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d28c3660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prune the datasets for labeling process for malicious data\n",
    "\n",
    "\n",
    "# For WebOS = 18:56:80:17:d0:ef\n",
    "index_names = df1[((df1['HW_dst'] != '18:56:80:17:d0:ef') & (df1['Hw_src'] != '18:56:80:17:d0:ef'))].index\n",
    "df1.drop(index_names, inplace = True)\n",
    "\n",
    "# Big_Server_Monero_mining_data = a4:bb:6d:ac:e1:fd\n",
    "\n",
    "index_names = df2[((df2['HW_dst'] != 'a4:bb:6d:ac:e1:fd') & (df2['Hw_src'] != 'a4:bb:6d:ac:e1:fd'))].index\n",
    "df2.drop(index_names, inplace = True)\n",
    "\n",
    "# ege_data_rasberry = dc:a6:32:67:66:4b\t\n",
    "\n",
    "index_names = df3[((df3['HW_dst'] != 'dc:a6:32:67:66:4b') & (df3['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df3.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_binary_monero_mining = dc:a6:32:68:35:8a\n",
    "\n",
    "index_names = df4[((df4['HW_dst'] != 'dc:a6:32:68:35:8a') & (df4['Hw_src'] != 'dc:a6:32:68:35:8a'))].index\n",
    "df4.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_network_data_2 = dc:a6:32:67:66:4b\n",
    "\n",
    "index_names = df5[((df5['HW_dst'] != 'dc:a6:32:67:66:4b') & (df5['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df5.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry-Webmine = dc:a6:32:67:66:4b\n",
    "index_names = df6[((df6['HW_dst'] != 'dc:a6:32:67:66:4b') & (df6['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df6.drop(index_names, inplace = True)\n",
    "\n",
    "# Server_Webmine_Network_data = a4:bb:6d:ac:e1:fd\n",
    "\n",
    "index_names = df7[((df7['HW_dst'] != 'a4:bb:6d:ac:e1:fd') & (df7['Hw_src'] != 'a4:bb:6d:ac:e1:fd'))].index\n",
    "df7.drop(index_names, inplace = True)\n",
    "\n",
    "# Server_%50_Mining = a4:bb:6d:ac:e1:fd\n",
    "\n",
    "index_names = df32[((df32['HW_dst'] != 'a4:bb:6d:ac:e1:fd') & (df32['Hw_src'] != 'a4:bb:6d:ac:e1:fd'))].index\n",
    "df32.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_webmine_%10 = dc:a6:32:67:66:4b\n",
    "\n",
    "index_names = df33[((df33['HW_dst'] != 'dc:a6:32:67:66:4b') & (df33['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df33.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_webmine_%50 = dc:a6:32:68:35:8a\n",
    "\n",
    "index_names = df34[((df34['HW_dst'] != 'dc:a6:32:68:35:8a') & (df34['Hw_src'] != 'dc:a6:32:68:35:8a'))].index\n",
    "df34.drop(index_names, inplace = True)\n",
    "\n",
    "# Desktop_Webmine_%100 = dc:a6:32:68:35:8a\n",
    "\n",
    "index_names = df35[((df35['HW_dst'] != 'd8:3b:bf:8f:ba:ba') & (df35['Hw_src'] != 'd8:3b:bf:8f:ba:ba'))].index\n",
    "df35.drop(index_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0d0070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#                                                               #\n",
    "#      Labeling Features for further calculations               #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "df1.insert(7, \"Is_malicious\", 1)\n",
    "df2.insert(7, \"Is_malicious\", 1)\n",
    "df3.insert(7, \"Is_malicious\", 1)\n",
    "df4.insert(7, \"Is_malicious\", 1)\n",
    "df5.insert(7, \"Is_malicious\", 1)\n",
    "df6.insert(7, \"Is_malicious\", 1)\n",
    "df7.insert(7, \"Is_malicious\", 1)\n",
    "\n",
    "# ========================================================\n",
    "\n",
    "df8.insert(7, \"Is_malicious\", 0)\n",
    "df9.insert(7, \"Is_malicious\", 0)\n",
    "df10.insert(7, \"Is_malicious\", 0)\n",
    "df11.insert(7, \"Is_malicious\", 0)\n",
    "df12.insert(7, \"Is_malicious\", 0)\n",
    "df13.insert(7, \"Is_malicious\", 0)\n",
    "df14.insert(7, \"Is_malicious\", 0)\n",
    "df15.insert(7, \"Is_malicious\", 0)\n",
    "df16.insert(7, \"Is_malicious\", 0)\n",
    "df17.insert(7, \"Is_malicious\", 0)\n",
    "df18.insert(7, \"Is_malicious\", 0)\n",
    "df19.insert(7, \"Is_malicious\", 0)\n",
    "df20.insert(7, \"Is_malicious\", 0)\n",
    "df21.insert(7, \"Is_malicious\", 0)\n",
    "df22.insert(7, \"Is_malicious\", 0)\n",
    "df23.insert(7, \"Is_malicious\", 0)\n",
    "\n",
    "# ========================================================\n",
    "\n",
    "\n",
    "df32.insert(7, \"Is_malicious\", 1)\n",
    "df33.insert(7, \"Is_malicious\", 1)\n",
    "df34.insert(7, \"Is_malicious\", 1)\n",
    "df35.insert(7, \"Is_malicious\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13020e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_process(a,b,x):\n",
    "    \n",
    "    df_malicious = a.copy()\n",
    "    df_benign    = b.copy()\n",
    "    \n",
    "    from tsfresh import extract_features, select_features\n",
    "    from tsfresh.utilities.dataframe_functions import impute\n",
    "    from tsfresh import extract_features\n",
    "    from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "\n",
    "\n",
    "    df_malicious.reset_index(drop=True, inplace=True) #reset index\n",
    "    df_malicious['id']= np.floor(df_malicious.index.array/10)\n",
    "    df_benign.reset_index(drop=True, inplace=True) #reset index\n",
    "    df_benign['id']= np.floor(df_benign.index.array/10)\n",
    "    \n",
    "\n",
    "    \n",
    "    print('1- Are we here?')\n",
    "    tf1=tsfresh.extract_features(df_malicious,impute_function=impute, column_kind='Is_malicious',\n",
    "                                 column_id='id',column_sort=\"Time\",column_value = \"Length\")\n",
    "    tf1['class']= 1\n",
    "\n",
    "    print('2- Are we here?')\n",
    "    \n",
    "    \n",
    "    tf2=tsfresh.extract_features(df_benign,impute_function=impute, column_kind='Is_malicious',\n",
    "                                 column_id='id',column_sort=\"Time\",column_value = \"Length\")\n",
    "    tf2['class']= 0\n",
    "    \n",
    "    print('3- Are we here?')\n",
    "\n",
    "    tf2.columns = tf1.columns\n",
    "\n",
    "    features=pd.concat([tf1,tf2])\n",
    "    #features.reset_index(drop=True, inplace=True) #reset index\n",
    "    \n",
    "#   best_features = pd.read_csv('/home/ege/Desktop/Mining_data/mining/new_captures/features_final.csv')\n",
    "\n",
    "    features2 = features.copy()\n",
    "    features2.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    y = pd.Series(data = features2['class'], index=features2.index)\n",
    "    \n",
    "    from tsfresh.examples import load_robot_execution_failures\n",
    "    from tsfresh import extract_features, select_features\n",
    "    from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "\n",
    "    relevance_table = calculate_relevance_table(features2, y)\n",
    "    relevance_table = relevance_table[relevance_table.relevant]\n",
    "    relevance_table.sort_values(\"p_value\", inplace=True)\n",
    "\n",
    "    relevance_table\n",
    "    \n",
    "    best_features = relevance_table[relevance_table['p_value'] <= 0.05]\n",
    "\n",
    "    df_ML = pd.DataFrame()\n",
    "\n",
    "    for pkt in best_features:\n",
    "        df_ML[best_features.feature] = features[best_features.feature]\n",
    "    print('4- Are we here?')\n",
    "    final = ML_Process(df_ML,x)\n",
    "    \n",
    "    print('5- Are we here?')\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1db46d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_Process(df_ML,x):\n",
    "    df_results = x.copy() \n",
    "    print('let the ml starts')\n",
    "  \n",
    "    from sklearn import neighbors, metrics\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    #X = df_finalized[['Time', 'Length','Protocol']].values\n",
    "    X = df_ML.drop('class',axis=1).to_numpy()\n",
    "    #y = df_finalized[['Is_malicious']]\n",
    "    y = df_ML['class'].to_numpy()\n",
    "\n",
    "    print('6- Are we here?')\n",
    "\n",
    "    #print(X,y)\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    Le = LabelEncoder()\n",
    "    for i in range(len(X[0])):\n",
    "        X[:, i] = Le.fit_transform(X[:, i])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=8675309)\n",
    "    print('7- Are we here?')\n",
    "    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    #from xgboost import XGBClassifier\n",
    "    from sklearn import model_selection\n",
    "    from sklearn.utils import class_weight\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    y_train = y_train.ravel()\n",
    "    dfs = []\n",
    "    models = [\n",
    "          ('LogReg', LogisticRegression()), \n",
    "          #('RF', RandomForestClassifier()),\n",
    "          ('KNN', KNeighborsClassifier()),\n",
    "          ('SVM', SVC()), \n",
    "          ('GNB', GaussianNB())\n",
    "          #('XGB', XGBClassifier())\n",
    "            ]\n",
    "    results = []\n",
    "    names = []\n",
    "    scoring = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted', 'roc_auc']\n",
    "    target_names = ['malignant', 'benign']\n",
    "    for name, model in models:\n",
    "        kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state=90210)\n",
    "        cv_results = model_selection.cross_validate(model, X_train, y_train, cv=kfold, \n",
    "                                                    scoring=scoring)\n",
    "        print('8- Are we here?')\n",
    "        clf = model.fit(X_train, y_train)\n",
    "        print('9- Are we here?')\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(name)\n",
    "        print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        this_df = pd.DataFrame(cv_results)\n",
    "        this_df['model'] = name\n",
    "        dfs.append(this_df)\n",
    "        df_resulta = df_results.append(dfs)\n",
    "        final = pd.concat(dfs, ignore_index=True)\n",
    "        print(final)\n",
    "        print('10- Are we here?')\n",
    "\n",
    "    return(final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0a48abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63471c53",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 1217322\n",
      "benign: 2360951\n",
      "0 NAN in malicious!\n",
      "0 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 1217322\n",
      "benign: 2360951\n",
      "1- Are we here?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 160/160 [03:09<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2- Are we here?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 160/160 [06:26<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3- Are we here?\n",
      "4- Are we here?\n",
      "let the ml starts\n",
      "6- Are we here?\n",
      "7- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.99      0.97      0.98     58891\n",
      "      benign       0.95      0.98      0.96     30567\n",
      "\n",
      "    accuracy                           0.97     89458\n",
      "   macro avg       0.97      0.98      0.97     89458\n",
      "weighted avg       0.98      0.97      0.98     89458\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  5.885719    0.147258       0.973824                 0.974110   \n",
      "1  6.390435    0.144355       0.974736                 0.974968   \n",
      "2  6.182196    0.129498       0.975016                 0.975277   \n",
      "3  6.041870    0.184753       0.974438                 0.974625   \n",
      "4  5.999996    0.135466       0.974122                 0.974467   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.973824          0.973897      0.993908  LogReg  \n",
      "1              0.974736          0.974798      0.993402  LogReg  \n",
      "2              0.975016          0.975083      0.994627  LogReg  \n",
      "3              0.974438          0.974492      0.993844  LogReg  \n",
      "4              0.974122          0.974205      0.993496  LogReg  \n",
      "10- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.99      0.98      0.99     58891\n",
      "      benign       0.97      0.98      0.98     30567\n",
      "\n",
      "    accuracy                           0.98     89458\n",
      "   macro avg       0.98      0.98      0.98     89458\n",
      "weighted avg       0.98      0.98      0.98     89458\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  5.885719    0.147258       0.973824                 0.974110   \n",
      "1  6.390435    0.144355       0.974736                 0.974968   \n",
      "2  6.182196    0.129498       0.975016                 0.975277   \n",
      "3  6.041870    0.184753       0.974438                 0.974625   \n",
      "4  5.999996    0.135466       0.974122                 0.974467   \n",
      "5  0.301556  536.756394       0.982282                 0.982384   \n",
      "6  0.361260  527.543367       0.982170                 0.982260   \n",
      "7  0.376128  512.875735       0.982990                 0.983111   \n",
      "8  0.382859  523.782741       0.982468                 0.982555   \n",
      "9  0.454481  533.041439       0.982915                 0.983041   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.973824          0.973897      0.993908  LogReg  \n",
      "1              0.974736          0.974798      0.993402  LogReg  \n",
      "2              0.975016          0.975083      0.994627  LogReg  \n",
      "3              0.974438          0.974492      0.993844  LogReg  \n",
      "4              0.974122          0.974205      0.993496  LogReg  \n",
      "5              0.982282          0.982311      0.993678     KNN  \n",
      "6              0.982170          0.982196      0.993519     KNN  \n",
      "7              0.982990          0.983021      0.993912     KNN  \n",
      "8              0.982468          0.982493      0.993490     KNN  \n",
      "9              0.982915          0.982948      0.993822     KNN  \n",
      "10- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.99      0.98      0.98     58891\n",
      "      benign       0.96      0.98      0.97     30567\n",
      "\n",
      "    accuracy                           0.98     89458\n",
      "   macro avg       0.98      0.98      0.98     89458\n",
      "weighted avg       0.98      0.98      0.98     89458\n",
      "\n",
      "       fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0      5.885719    0.147258       0.973824                 0.974110   \n",
      "1      6.390435    0.144355       0.974736                 0.974968   \n",
      "2      6.182196    0.129498       0.975016                 0.975277   \n",
      "3      6.041870    0.184753       0.974438                 0.974625   \n",
      "4      5.999996    0.135466       0.974122                 0.974467   \n",
      "5      0.301556  536.756394       0.982282                 0.982384   \n",
      "6      0.361260  527.543367       0.982170                 0.982260   \n",
      "7      0.376128  512.875735       0.982990                 0.983111   \n",
      "8      0.382859  523.782741       0.982468                 0.982555   \n",
      "9      0.454481  533.041439       0.982915                 0.983041   \n",
      "10  1278.279216  537.165460       0.978985                 0.979224   \n",
      "11  1256.596927  527.454777       0.978910                 0.979104   \n",
      "12  1241.403784  503.168495       0.979171                 0.979390   \n",
      "13  1233.281948  528.018413       0.978388                 0.978554   \n",
      "14  1409.679246  490.885757       0.978425                 0.978687   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.973824          0.973897      0.993908  LogReg  \n",
      "1               0.974736          0.974798      0.993402  LogReg  \n",
      "2               0.975016          0.975083      0.994627  LogReg  \n",
      "3               0.974438          0.974492      0.993844  LogReg  \n",
      "4               0.974122          0.974205      0.993496  LogReg  \n",
      "5               0.982282          0.982311      0.993678     KNN  \n",
      "6               0.982170          0.982196      0.993519     KNN  \n",
      "7               0.982990          0.983021      0.993912     KNN  \n",
      "8               0.982468          0.982493      0.993490     KNN  \n",
      "9               0.982915          0.982948      0.993822     KNN  \n",
      "10              0.978985          0.979041      0.994971     SVM  \n",
      "11              0.978910          0.978959      0.994668     SVM  \n",
      "12              0.979171          0.979224      0.995306     SVM  \n",
      "13              0.978388          0.978433      0.994792     SVM  \n",
      "14              0.978425          0.978487      0.994652     SVM  \n",
      "10- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.99      1.00      1.00     58891\n",
      "      benign       1.00      0.99      0.99     30567\n",
      "\n",
      "    accuracy                           1.00     89458\n",
      "   macro avg       1.00      0.99      1.00     89458\n",
      "weighted avg       1.00      1.00      1.00     89458\n",
      "\n",
      "       fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0      5.885719    0.147258       0.973824                 0.974110   \n",
      "1      6.390435    0.144355       0.974736                 0.974968   \n",
      "2      6.182196    0.129498       0.975016                 0.975277   \n",
      "3      6.041870    0.184753       0.974438                 0.974625   \n",
      "4      5.999996    0.135466       0.974122                 0.974467   \n",
      "5      0.301556  536.756394       0.982282                 0.982384   \n",
      "6      0.361260  527.543367       0.982170                 0.982260   \n",
      "7      0.376128  512.875735       0.982990                 0.983111   \n",
      "8      0.382859  523.782741       0.982468                 0.982555   \n",
      "9      0.454481  533.041439       0.982915                 0.983041   \n",
      "10  1278.279216  537.165460       0.978985                 0.979224   \n",
      "11  1256.596927  527.454777       0.978910                 0.979104   \n",
      "12  1241.403784  503.168495       0.979171                 0.979390   \n",
      "13  1233.281948  528.018413       0.978388                 0.978554   \n",
      "14  1409.679246  490.885757       0.978425                 0.978687   \n",
      "15     1.030928    0.368719       0.995789                 0.995816   \n",
      "16     1.023033    0.365020       0.995454                 0.995485   \n",
      "17     1.024557    0.360244       0.995212                 0.995246   \n",
      "18     1.026901    0.364163       0.995230                 0.995265   \n",
      "19     1.025287    0.366864       0.995808                 0.995834   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.973824          0.973897      0.993908  LogReg  \n",
      "1               0.974736          0.974798      0.993402  LogReg  \n",
      "2               0.975016          0.975083      0.994627  LogReg  \n",
      "3               0.974438          0.974492      0.993844  LogReg  \n",
      "4               0.974122          0.974205      0.993496  LogReg  \n",
      "5               0.982282          0.982311      0.993678     KNN  \n",
      "6               0.982170          0.982196      0.993519     KNN  \n",
      "7               0.982990          0.983021      0.993912     KNN  \n",
      "8               0.982468          0.982493      0.993490     KNN  \n",
      "9               0.982915          0.982948      0.993822     KNN  \n",
      "10              0.978985          0.979041      0.994971     SVM  \n",
      "11              0.978910          0.978959      0.994668     SVM  \n",
      "12              0.979171          0.979224      0.995306     SVM  \n",
      "13              0.978388          0.978433      0.994792     SVM  \n",
      "14              0.978425          0.978487      0.994652     SVM  \n",
      "15              0.995789          0.995783      0.994606     GNB  \n",
      "16              0.995454          0.995447      0.994288     GNB  \n",
      "17              0.995212          0.995203      0.994082     GNB  \n",
      "18              0.995230          0.995222      0.993920     GNB  \n",
      "19              0.995808          0.995802      0.994724     GNB  \n",
      "10- Are we here?\n",
      "5- Are we here?\n",
      "16013.947954073\n"
     ]
    }
   ],
   "source": [
    "#Scenario 1 :Devices\n",
    "# 1) Server\n",
    " \n",
    "df_malicious = pd.concat([df2,df7,df32])\n",
    "df_benign = pd.concat([df8,df9,df10,df11,df12,df13,df14,df15,df16,df17,df18,df19,df20,df21,df22,df23])\n",
    "\n",
    "\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_server_s1 = run_process(df_malicious,df_benign,df_results)\n",
    "results_server_s1.to_csv('~/results_server_s1.csv')\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe5b485b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 234272\n",
      "benign: 2360951\n",
      "0 NAN in malicious!\n",
      "0 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 234272\n",
      "benign: 2360951\n",
      "1- Are we here?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 160/160 [00:35<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2- Are we here?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 160/160 [06:18<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3- Are we here?\n",
      "4- Are we here?\n",
      "let the ml starts\n",
      "6- Are we here?\n",
      "7- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.96      0.98      0.97     59016\n",
      "      benign       0.78      0.61      0.68      5865\n",
      "\n",
      "    accuracy                           0.95     64881\n",
      "   macro avg       0.87      0.80      0.83     64881\n",
      "weighted avg       0.95      0.95      0.95     64881\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  4.757334    0.128699       0.949472                 0.946176   \n",
      "1  4.025690    0.091039       0.945670                 0.941670   \n",
      "2  4.473391    0.107541       0.948676                 0.944960   \n",
      "3  4.413610    0.128169       0.947005                 0.942676   \n",
      "4  4.230666    0.096663       0.946388                 0.942207   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.949472          0.946990      0.956365  LogReg  \n",
      "1              0.945670          0.942743      0.947920  LogReg  \n",
      "2              0.948676          0.945642      0.947834  LogReg  \n",
      "3              0.947005          0.943167      0.949989  LogReg  \n",
      "4              0.946388          0.943118      0.948756  LogReg  \n",
      "10- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.97      0.99      0.98     59016\n",
      "      benign       0.85      0.72      0.78      5865\n",
      "\n",
      "    accuracy                           0.96     64881\n",
      "   macro avg       0.91      0.85      0.88     64881\n",
      "weighted avg       0.96      0.96      0.96     64881\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  4.757334    0.128699       0.949472                 0.946176   \n",
      "1  4.025690    0.091039       0.945670                 0.941670   \n",
      "2  4.473391    0.107541       0.948676                 0.944960   \n",
      "3  4.413610    0.128169       0.947005                 0.942676   \n",
      "4  4.230666    0.096663       0.946388                 0.942207   \n",
      "5  0.147559  256.925750       0.962778                 0.960966   \n",
      "6  0.165572  272.321404       0.961777                 0.959773   \n",
      "7  0.264182  269.000807       0.962470                 0.960633   \n",
      "8  0.207176  274.847333       0.961031                 0.958965   \n",
      "9  0.183585  260.912403       0.961930                 0.959931   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.949472          0.946990      0.956365  LogReg  \n",
      "1              0.945670          0.942743      0.947920  LogReg  \n",
      "2              0.948676          0.945642      0.947834  LogReg  \n",
      "3              0.947005          0.943167      0.949989  LogReg  \n",
      "4              0.946388          0.943118      0.948756  LogReg  \n",
      "5              0.962778          0.960979      0.940736     KNN  \n",
      "6              0.961777          0.959827      0.935592     KNN  \n",
      "7              0.962470          0.960799      0.943637     KNN  \n",
      "8              0.961031          0.959108      0.938392     KNN  \n",
      "9              0.961930          0.959918      0.935921     KNN  \n",
      "10- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.97      0.99      0.98     59016\n",
      "      benign       0.90      0.67      0.77      5865\n",
      "\n",
      "    accuracy                           0.96     64881\n",
      "   macro avg       0.93      0.83      0.88     64881\n",
      "weighted avg       0.96      0.96      0.96     64881\n",
      "\n",
      "      fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0     4.757334    0.128699       0.949472                 0.946176   \n",
      "1     4.025690    0.091039       0.945670                 0.941670   \n",
      "2     4.473391    0.107541       0.948676                 0.944960   \n",
      "3     4.413610    0.128169       0.947005                 0.942676   \n",
      "4     4.230666    0.096663       0.946388                 0.942207   \n",
      "5     0.147559  256.925750       0.962778                 0.960966   \n",
      "6     0.165572  272.321404       0.961777                 0.959773   \n",
      "7     0.264182  269.000807       0.962470                 0.960633   \n",
      "8     0.207176  274.847333       0.961031                 0.958965   \n",
      "9     0.183585  260.912403       0.961930                 0.959931   \n",
      "10  950.097802  462.001561       0.959336                 0.957441   \n",
      "11  851.864279  440.979091       0.959465                 0.957404   \n",
      "12  830.905761  433.358174       0.960133                 0.958223   \n",
      "13  862.046409  430.009571       0.959309                 0.957335   \n",
      "14  828.196711  430.577536       0.958128                 0.956019   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.949472          0.946990      0.956365  LogReg  \n",
      "1               0.945670          0.942743      0.947920  LogReg  \n",
      "2               0.948676          0.945642      0.947834  LogReg  \n",
      "3               0.947005          0.943167      0.949989  LogReg  \n",
      "4               0.946388          0.943118      0.948756  LogReg  \n",
      "5               0.962778          0.960979      0.940736     KNN  \n",
      "6               0.961777          0.959827      0.935592     KNN  \n",
      "7               0.962470          0.960799      0.943637     KNN  \n",
      "8               0.961031          0.959108      0.938392     KNN  \n",
      "9               0.961930          0.959918      0.935921     KNN  \n",
      "10              0.959336          0.956142      0.952381     SVM  \n",
      "11              0.959465          0.956310      0.956410     SVM  \n",
      "12              0.960133          0.957183      0.956451     SVM  \n",
      "13              0.959309          0.956020      0.954978     SVM  \n",
      "14              0.958128          0.954513      0.953700     SVM  \n",
      "10- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      1.00      1.00     59016\n",
      "      benign       1.00      1.00      1.00      5865\n",
      "\n",
      "    accuracy                           1.00     64881\n",
      "   macro avg       1.00      1.00      1.00     64881\n",
      "weighted avg       1.00      1.00      1.00     64881\n",
      "\n",
      "      fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0     4.757334    0.128699       0.949472                 0.946176   \n",
      "1     4.025690    0.091039       0.945670                 0.941670   \n",
      "2     4.473391    0.107541       0.948676                 0.944960   \n",
      "3     4.413610    0.128169       0.947005                 0.942676   \n",
      "4     4.230666    0.096663       0.946388                 0.942207   \n",
      "5     0.147559  256.925750       0.962778                 0.960966   \n",
      "6     0.165572  272.321404       0.961777                 0.959773   \n",
      "7     0.264182  269.000807       0.962470                 0.960633   \n",
      "8     0.207176  274.847333       0.961031                 0.958965   \n",
      "9     0.183585  260.912403       0.961930                 0.959931   \n",
      "10  950.097802  462.001561       0.959336                 0.957441   \n",
      "11  851.864279  440.979091       0.959465                 0.957404   \n",
      "12  830.905761  433.358174       0.960133                 0.958223   \n",
      "13  862.046409  430.009571       0.959309                 0.957335   \n",
      "14  828.196711  430.577536       0.958128                 0.956019   \n",
      "15    0.612645    0.262095       0.999692                 0.999692   \n",
      "16    0.593307    0.250958       0.999794                 0.999794   \n",
      "17    0.593166    0.261322       0.999949                 0.999949   \n",
      "18    0.590450    0.253000       0.999923                 0.999923   \n",
      "19    0.590158    0.253128       0.999846                 0.999846   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.949472          0.946990      0.956365  LogReg  \n",
      "1               0.945670          0.942743      0.947920  LogReg  \n",
      "2               0.948676          0.945642      0.947834  LogReg  \n",
      "3               0.947005          0.943167      0.949989  LogReg  \n",
      "4               0.946388          0.943118      0.948756  LogReg  \n",
      "5               0.962778          0.960979      0.940736     KNN  \n",
      "6               0.961777          0.959827      0.935592     KNN  \n",
      "7               0.962470          0.960799      0.943637     KNN  \n",
      "8               0.961031          0.959108      0.938392     KNN  \n",
      "9               0.961930          0.959918      0.935921     KNN  \n",
      "10              0.959336          0.956142      0.952381     SVM  \n",
      "11              0.959465          0.956310      0.956410     SVM  \n",
      "12              0.960133          0.957183      0.956451     SVM  \n",
      "13              0.959309          0.956020      0.954978     SVM  \n",
      "14              0.958128          0.954513      0.953700     SVM  \n",
      "15              0.999692          0.999692      0.999915     GNB  \n",
      "16              0.999794          0.999794      0.999943     GNB  \n",
      "17              0.999949          0.999949      0.999859     GNB  \n",
      "18              0.999923          0.999923      0.999857     GNB  \n",
      "19              0.999846          0.999846      0.999698     GNB  \n",
      "10- Are we here?\n",
      "5- Are we here?\n",
      "11229.017679219\n"
     ]
    }
   ],
   "source": [
    " #2) Desktop\n",
    "df_malicious = pd.concat([df35])\n",
    "df_benign = pd.concat([df8,df9,df10,df11,df12,df13,df14,df15,df16,df17,df18,df19,df20,df21,df22,df23])\n",
    "\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_Desktop_s1 = run_process(df_malicious,df_benign,df_results)\n",
    "results_Desktop_s1.to_csv('~/results_Desktop_s1.csv')\n",
    "\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a87937a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 64064\n",
      "benign: 2360951\n",
      "0 NAN in malicious!\n",
      "0 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 64064\n",
      "benign: 2360951\n",
      "1- Are we here?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 157/157 [00:11<00:00, 13.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2- Are we here?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 160/160 [06:11<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3- Are we here?\n",
      "4- Are we here?\n",
      "let the ml starts\n",
      "6- Are we here?\n",
      "7- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.99      1.00      1.00     59042\n",
      "      benign       0.87      0.76      0.81      1584\n",
      "\n",
      "    accuracy                           0.99     60626\n",
      "   macro avg       0.93      0.88      0.90     60626\n",
      "weighted avg       0.99      0.99      0.99     60626\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  4.544640    0.084530       0.991038                 0.990630   \n",
      "1  4.194974    0.099587       0.990186                 0.989694   \n",
      "2  4.384184    0.078094       0.989746                 0.989281   \n",
      "3  4.897751    0.152829       0.991203                 0.990825   \n",
      "4  4.942788    0.095239       0.991340                 0.990976   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.991038          0.990610      0.989950  LogReg  \n",
      "1              0.990186          0.989794      0.987543  LogReg  \n",
      "2              0.989746          0.989412      0.988095  LogReg  \n",
      "3              0.991203          0.990927      0.990531  LogReg  \n",
      "4              0.991340          0.991056      0.989937  LogReg  \n",
      "10- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.99      1.00      0.99     59042\n",
      "      benign       0.81      0.73      0.77      1584\n",
      "\n",
      "    accuracy                           0.99     60626\n",
      "   macro avg       0.90      0.86      0.88     60626\n",
      "weighted avg       0.99      0.99      0.99     60626\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  4.544640    0.084530       0.991038                 0.990630   \n",
      "1  4.194974    0.099587       0.990186                 0.989694   \n",
      "2  4.384184    0.078094       0.989746                 0.989281   \n",
      "3  4.897751    0.152829       0.991203                 0.990825   \n",
      "4  4.942788    0.095239       0.991340                 0.990976   \n",
      "5  0.175233  156.274028       0.987189                 0.986417   \n",
      "6  0.142111  156.919112       0.986310                 0.985566   \n",
      "7  0.141843  173.013926       0.987876                 0.987211   \n",
      "8  0.136896  151.206359       0.988674                 0.988056   \n",
      "9  0.136162  150.954115       0.988646                 0.988162   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.991038          0.990610      0.989950  LogReg  \n",
      "1              0.990186          0.989794      0.987543  LogReg  \n",
      "2              0.989746          0.989412      0.988095  LogReg  \n",
      "3              0.991203          0.990927      0.990531  LogReg  \n",
      "4              0.991340          0.991056      0.989937  LogReg  \n",
      "5              0.987189          0.986637      0.945515     KNN  \n",
      "6              0.986310          0.985840      0.938811     KNN  \n",
      "7              0.987876          0.987406      0.947749     KNN  \n",
      "8              0.988674          0.988249      0.949690     KNN  \n",
      "9              0.988646          0.988339      0.950795     KNN  \n",
      "10- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.99      1.00      0.99     59042\n",
      "      benign       0.91      0.63      0.74      1584\n",
      "\n",
      "    accuracy                           0.99     60626\n",
      "   macro avg       0.95      0.81      0.87     60626\n",
      "weighted avg       0.99      0.99      0.99     60626\n",
      "\n",
      "      fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0     4.544640    0.084530       0.991038                 0.990630   \n",
      "1     4.194974    0.099587       0.990186                 0.989694   \n",
      "2     4.384184    0.078094       0.989746                 0.989281   \n",
      "3     4.897751    0.152829       0.991203                 0.990825   \n",
      "4     4.942788    0.095239       0.991340                 0.990976   \n",
      "5     0.175233  156.274028       0.987189                 0.986417   \n",
      "6     0.142111  156.919112       0.986310                 0.985566   \n",
      "7     0.141843  173.013926       0.987876                 0.987211   \n",
      "8     0.136896  151.206359       0.988674                 0.988056   \n",
      "9     0.136162  150.954115       0.988646                 0.988162   \n",
      "10  262.145374  106.285680       0.987712                 0.987017   \n",
      "11  218.632485  106.380145       0.988124                 0.987444   \n",
      "12  217.491915  104.153506       0.988234                 0.987603   \n",
      "13  213.673453  105.881579       0.989306                 0.988723   \n",
      "14  211.954901  105.477142       0.988619                 0.988031   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.991038          0.990610      0.989950  LogReg  \n",
      "1               0.990186          0.989794      0.987543  LogReg  \n",
      "2               0.989746          0.989412      0.988095  LogReg  \n",
      "3               0.991203          0.990927      0.990531  LogReg  \n",
      "4               0.991340          0.991056      0.989937  LogReg  \n",
      "5               0.987189          0.986637      0.945515     KNN  \n",
      "6               0.986310          0.985840      0.938811     KNN  \n",
      "7               0.987876          0.987406      0.947749     KNN  \n",
      "8               0.988674          0.988249      0.949690     KNN  \n",
      "9               0.988646          0.988339      0.950795     KNN  \n",
      "10              0.987712          0.986516      0.973903     SVM  \n",
      "11              0.988124          0.986960      0.971330     SVM  \n",
      "12              0.988234          0.987160      0.970807     SVM  \n",
      "13              0.989306          0.988345      0.971021     SVM  \n",
      "14              0.988619          0.987539      0.978098     SVM  \n",
      "10- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      1.00      1.00     59042\n",
      "      benign       1.00      0.96      0.98      1584\n",
      "\n",
      "    accuracy                           1.00     60626\n",
      "   macro avg       1.00      0.98      0.99     60626\n",
      "weighted avg       1.00      1.00      1.00     60626\n",
      "\n",
      "      fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0     4.544640    0.084530       0.991038                 0.990630   \n",
      "1     4.194974    0.099587       0.990186                 0.989694   \n",
      "2     4.384184    0.078094       0.989746                 0.989281   \n",
      "3     4.897751    0.152829       0.991203                 0.990825   \n",
      "4     4.942788    0.095239       0.991340                 0.990976   \n",
      "5     0.175233  156.274028       0.987189                 0.986417   \n",
      "6     0.142111  156.919112       0.986310                 0.985566   \n",
      "7     0.141843  173.013926       0.987876                 0.987211   \n",
      "8     0.136896  151.206359       0.988674                 0.988056   \n",
      "9     0.136162  150.954115       0.988646                 0.988162   \n",
      "10  262.145374  106.285680       0.987712                 0.987017   \n",
      "11  218.632485  106.380145       0.988124                 0.987444   \n",
      "12  217.491915  104.153506       0.988234                 0.987603   \n",
      "13  213.673453  105.881579       0.989306                 0.988723   \n",
      "14  211.954901  105.477142       0.988619                 0.988031   \n",
      "15    0.486671    0.205815       0.998983                 0.998984   \n",
      "16    0.482127    0.205031       0.998625                 0.998627   \n",
      "17    0.483738    0.204479       0.998900                 0.998902   \n",
      "18    0.483909    0.205786       0.998928                 0.998929   \n",
      "19    0.483208    0.205234       0.998763                 0.998764   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.991038          0.990610      0.989950  LogReg  \n",
      "1               0.990186          0.989794      0.987543  LogReg  \n",
      "2               0.989746          0.989412      0.988095  LogReg  \n",
      "3               0.991203          0.990927      0.990531  LogReg  \n",
      "4               0.991340          0.991056      0.989937  LogReg  \n",
      "5               0.987189          0.986637      0.945515     KNN  \n",
      "6               0.986310          0.985840      0.938811     KNN  \n",
      "7               0.987876          0.987406      0.947749     KNN  \n",
      "8               0.988674          0.988249      0.949690     KNN  \n",
      "9               0.988646          0.988339      0.950795     KNN  \n",
      "10              0.987712          0.986516      0.973903     SVM  \n",
      "11              0.988124          0.986960      0.971330     SVM  \n",
      "12              0.988234          0.987160      0.970807     SVM  \n",
      "13              0.989306          0.988345      0.971021     SVM  \n",
      "14              0.988619          0.987539      0.978098     SVM  \n",
      "15              0.998983          0.998973      0.999498     GNB  \n",
      "16              0.998625          0.998608      0.995303     GNB  \n",
      "17              0.998900          0.998889      0.996991     GNB  \n",
      "18              0.998928          0.998916      0.998904     GNB  \n",
      "19              0.998763          0.998748      0.995833     GNB  \n",
      "10- Are we here?\n",
      "5- Are we here?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4091.5317650009965\n"
     ]
    }
   ],
   "source": [
    "#3) Rasberry\n",
    "df_malicious = pd.concat([df3,df4,df5,df6,df33,df34])\n",
    "df_benign = pd.concat([df8,df9,df10,df11,df12,df13,df14,df15,df16,df17,df18,df19,df20,df21,df22,df23])\n",
    "\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_Raspberry_s1 = run_process(df_malicious,df_benign,df_results)\n",
    "results_Raspberry_s1.to_csv('~/results_Raspberry_s1.csv')\n",
    "\n",
    "\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c855ef68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 41572\n",
      "benign: 2360951\n",
      "0 NAN in malicious!\n",
      "0 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 41572\n",
      "benign: 2360951\n",
      "1- Are we here?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 160/160 [00:08<00:00, 19.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2- Are we here?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 160/160 [06:23<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3- Are we here?\n",
      "4- Are we here?\n",
      "let the ml starts\n",
      "6- Are we here?\n",
      "7- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.99      1.00      0.99     59050\n",
      "      benign       0.75      0.18      0.30      1014\n",
      "\n",
      "    accuracy                           0.99     60064\n",
      "   macro avg       0.87      0.59      0.64     60064\n",
      "weighted avg       0.98      0.99      0.98     60064\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  4.572218    0.076425       0.983295                 0.978211   \n",
      "1  4.842303    0.075114       0.983462                 0.978949   \n",
      "2  4.614810    0.080181       0.984128                 0.980540   \n",
      "3  4.533546    0.082629       0.984100                 0.981439   \n",
      "4  4.584907    0.084085       0.984516                 0.980583   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.983295          0.977333      0.969820  LogReg  \n",
      "1              0.983462          0.978462      0.962857  LogReg  \n",
      "2              0.984128          0.979131      0.967446  LogReg  \n",
      "3              0.984100          0.978077      0.964359  LogReg  \n",
      "4              0.984516          0.979905      0.967691  LogReg  \n",
      "10- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.99      1.00      0.99     59050\n",
      "      benign       0.65      0.34      0.44      1014\n",
      "\n",
      "    accuracy                           0.99     60064\n",
      "   macro avg       0.82      0.67      0.72     60064\n",
      "weighted avg       0.98      0.99      0.98     60064\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  4.572218    0.076425       0.983295                 0.978211   \n",
      "1  4.842303    0.075114       0.983462                 0.978949   \n",
      "2  4.614810    0.080181       0.984128                 0.980540   \n",
      "3  4.533546    0.082629       0.984100                 0.981439   \n",
      "4  4.584907    0.084085       0.984516                 0.980583   \n",
      "5  0.128077  161.650461       0.984627                 0.981583   \n",
      "6  0.168063  156.592682       0.984572                 0.981709   \n",
      "7  0.328474  161.192153       0.983850                 0.980340   \n",
      "8  0.151104  150.915503       0.985127                 0.982058   \n",
      "9  0.156611  144.906479       0.985127                 0.982023   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.983295          0.977333      0.969820  LogReg  \n",
      "1              0.983462          0.978462      0.962857  LogReg  \n",
      "2              0.984128          0.979131      0.967446  LogReg  \n",
      "3              0.984100          0.978077      0.964359  LogReg  \n",
      "4              0.984516          0.979905      0.967691  LogReg  \n",
      "5              0.984627          0.982340      0.853540     KNN  \n",
      "6              0.984572          0.982455      0.846693     KNN  \n",
      "7              0.983850          0.981256      0.838529     KNN  \n",
      "8              0.985127          0.982553      0.856238     KNN  \n",
      "9              0.985127          0.982658      0.847502     KNN  \n",
      "10- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      1.00      0.99     59050\n",
      "      benign       0.00      0.00      0.00      1014\n",
      "\n",
      "    accuracy                           0.98     60064\n",
      "   macro avg       0.49      0.50      0.50     60064\n",
      "weighted avg       0.97      0.98      0.97     60064\n",
      "\n",
      "      fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0     4.572218    0.076425       0.983295                 0.978211   \n",
      "1     4.842303    0.075114       0.983462                 0.978949   \n",
      "2     4.614810    0.080181       0.984128                 0.980540   \n",
      "3     4.533546    0.082629       0.984100                 0.981439   \n",
      "4     4.584907    0.084085       0.984516                 0.980583   \n",
      "5     0.128077  161.650461       0.984627                 0.981583   \n",
      "6     0.168063  156.592682       0.984572                 0.981709   \n",
      "7     0.328474  161.192153       0.983850                 0.980340   \n",
      "8     0.151104  150.915503       0.985127                 0.982058   \n",
      "9     0.156611  144.906479       0.985127                 0.982023   \n",
      "10  748.070608  105.154511       0.982518                 0.965343   \n",
      "11  265.172021  104.684740       0.982158                 0.964634   \n",
      "12  685.061405  101.206316       0.982380                 0.965070   \n",
      "13  257.534674  101.969549       0.982685                 0.965670   \n",
      "14  296.286414  102.595312       0.983018                 0.966324   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.983295          0.977333      0.969820  LogReg  \n",
      "1               0.983462          0.978462      0.962857  LogReg  \n",
      "2               0.984128          0.979131      0.967446  LogReg  \n",
      "3               0.984100          0.978077      0.964359  LogReg  \n",
      "4               0.984516          0.979905      0.967691  LogReg  \n",
      "5               0.984627          0.982340      0.853540     KNN  \n",
      "6               0.984572          0.982455      0.846693     KNN  \n",
      "7               0.983850          0.981256      0.838529     KNN  \n",
      "8               0.985127          0.982553      0.856238     KNN  \n",
      "9               0.985127          0.982658      0.847502     KNN  \n",
      "10              0.982518          0.973855      0.933241     SVM  \n",
      "11              0.982158          0.973317      0.954211     SVM  \n",
      "12              0.982380          0.973648      0.926441     SVM  \n",
      "13              0.982685          0.974103      0.958800     SVM  \n",
      "14              0.983018          0.974600      0.955804     SVM  \n",
      "10- Are we here?\n",
      "8- Are we here?\n",
      "9- Are we here?\n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      0.90      0.95     59050\n",
      "      benign       0.14      0.92      0.24      1014\n",
      "\n",
      "    accuracy                           0.90     60064\n",
      "   macro avg       0.57      0.91      0.59     60064\n",
      "weighted avg       0.98      0.90      0.93     60064\n",
      "\n",
      "      fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0     4.572218    0.076425       0.983295                 0.978211   \n",
      "1     4.842303    0.075114       0.983462                 0.978949   \n",
      "2     4.614810    0.080181       0.984128                 0.980540   \n",
      "3     4.533546    0.082629       0.984100                 0.981439   \n",
      "4     4.584907    0.084085       0.984516                 0.980583   \n",
      "5     0.128077  161.650461       0.984627                 0.981583   \n",
      "6     0.168063  156.592682       0.984572                 0.981709   \n",
      "7     0.328474  161.192153       0.983850                 0.980340   \n",
      "8     0.151104  150.915503       0.985127                 0.982058   \n",
      "9     0.156611  144.906479       0.985127                 0.982023   \n",
      "10  748.070608  105.154511       0.982518                 0.965343   \n",
      "11  265.172021  104.684740       0.982158                 0.964634   \n",
      "12  685.061405  101.206316       0.982380                 0.965070   \n",
      "13  257.534674  101.969549       0.982685                 0.965670   \n",
      "14  296.286414  102.595312       0.983018                 0.966324   \n",
      "15    0.494156    0.207618       0.899328                 0.983619   \n",
      "16    0.482530    0.207654       0.896359                 0.982916   \n",
      "17    0.480516    0.207024       0.896803                 0.983325   \n",
      "18    0.484027    0.208104       0.900161                 0.983523   \n",
      "19    0.482404    0.206846       0.899689                 0.983858   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.983295          0.977333      0.969820  LogReg  \n",
      "1               0.983462          0.978462      0.962857  LogReg  \n",
      "2               0.984128          0.979131      0.967446  LogReg  \n",
      "3               0.984100          0.978077      0.964359  LogReg  \n",
      "4               0.984516          0.979905      0.967691  LogReg  \n",
      "5               0.984627          0.982340      0.853540     KNN  \n",
      "6               0.984572          0.982455      0.846693     KNN  \n",
      "7               0.983850          0.981256      0.838529     KNN  \n",
      "8               0.985127          0.982553      0.856238     KNN  \n",
      "9               0.985127          0.982658      0.847502     KNN  \n",
      "10              0.982518          0.973855      0.933241     SVM  \n",
      "11              0.982158          0.973317      0.954211     SVM  \n",
      "12              0.982380          0.973648      0.926441     SVM  \n",
      "13              0.982685          0.974103      0.958800     SVM  \n",
      "14              0.983018          0.974600      0.955804     SVM  \n",
      "15              0.899328          0.933802      0.940361     GNB  \n",
      "16              0.896359          0.931813      0.937374     GNB  \n",
      "17              0.896803          0.932227      0.939377     GNB  \n",
      "18              0.900161          0.934356      0.936860     GNB  \n",
      "19              0.899689          0.934280      0.941596     GNB  \n",
      "10- Are we here?\n",
      "5- Are we here?\n",
      "5512.809060914995\n"
     ]
    }
   ],
   "source": [
    "#4) WebOS\n",
    "df_malicious = pd.concat([df1])\n",
    "df_benign = pd.concat([df8,df9,df10,df11,df12,df13,df14,df15,df16,df17,df18,df19,df20,df21,df22,df23])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_WebOS_s1 = run_process(df_malicious,df_benign,df_results)\n",
    "results_WebOS_s1.to_csv('~/results_WebOS_s1.csv')\n",
    "\n",
    "\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dd50e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_S1 = pd.concat([results_Raspberry_s1,results_Desktop_s1,results_server_s1,results_WebOS_s1])\n",
    "df_S1.to_csv('~/df_S1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
