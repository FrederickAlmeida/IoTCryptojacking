{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tsfresh\n",
    "import os\n",
    "import json\n",
    "import scapy\n",
    "import numpy as np\n",
    "import warnings\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from scapy.all import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") #ignore warnings caused by \n",
    "\n",
    "\n",
    "#################################################################\n",
    "#                                                               #\n",
    "#               malicious csv files import                      #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "\n",
    "df1 = pd.read_csv('../Data/malicious/WebOS_binary.csv') #\n",
    "df2 = pd.read_csv('../Data/malicious/Server_Binary.csv') #\n",
    "df3 = pd.read_csv('../Data/malicious/Raspberry_Webmine_Robust.csv')\n",
    "df4 = pd.read_csv('../Data/malicious/Raspberry_Binary.csv') #\n",
    "df5 = pd.read_csv('../Data/malicious/Raspberry_Webmine_Aggressive.csv')\n",
    "df6 = pd.read_csv('../Data/malicious/Raspberry_WebminePool_Aggressive.csv')\n",
    "df7 = pd.read_csv('../Data/malicious/Server_WebminePool_Aggressive.csv') #\n",
    "df32 = pd.read_csv('../Data/malicious/Server_WebminePool_Robust.csv') #\n",
    "df33 = pd.read_csv('../Data/malicious/Raspberry_WebminePool_Stealthy.csv') #\n",
    "df34 = pd.read_csv('../Data/malicious/Raspberry_WebminePool_Robust.csv') #\n",
    "df35 = pd.read_csv('../Data/malicious/Desktop_WebminePool_Aggressive.csv') #\n",
    "\n",
    "\n",
    "#################################################################\n",
    "#                                                               #\n",
    "#               benign-1 csv files import                         #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "df8 = pd.read_csv('../Data/benign-1/interactive_01.csv') #\n",
    "df9 = pd.read_csv('../Data/benign-1/interactive_02.csv') #\n",
    "df10 = pd.read_csv('../Data/benign-1/interactive_03.csv') #\n",
    "df11 = pd.read_csv('../Data/benign-1/interactive_04.csv') #\n",
    "df12 = pd.read_csv('../Data/benign-1/interactive_05.csv') #\n",
    "df13 = pd.read_csv('../Data/benign-1/interactive_06.csv') #\n",
    "df14 = pd.read_csv('../Data/benign-1/web_1page_01.csv') #\n",
    "df15 = pd.read_csv('../Data/benign-1/web_1page_02.csv') #\n",
    "df16 = pd.read_csv('../Data/benign-1/web_1page_03.csv') #\n",
    "df17 = pd.read_csv('../Data/benign-1/web_1page_04.csv') #\n",
    "df18 = pd.read_csv('../Data/benign-1/web_1page_05.csv') #\n",
    "df19 = pd.read_csv('../Data/benign-1/bulk_xs_04.csv') #\n",
    "df20 = pd.read_csv('../Data/benign-1/bulk_xs_05.csv') #\n",
    "df21 = pd.read_csv('../Data/benign-1/video_180s480p_01.csv') #\n",
    "df22 = pd.read_csv('../Data/benign-1/video_180s480p_02.csv') #\n",
    "df23 = pd.read_csv('../Data/benign-1/video_x1_04.csv') #\n",
    "df24 = pd.read_csv('../Data/benign-1/web_multiple_04.csv') #\n",
    "df25 = pd.read_csv('../Data/benign-1/bulk_xs_01.csv') #\n",
    "df26 = pd.read_csv('../Data/benign-1/bulk_xs_09.csv') #\n",
    "df27 = pd.read_csv('../Data/benign-1/bulk_xs_06.csv') #\n",
    "df28 = pd.read_csv('../Data/benign-1/bulk_xs_03.csv') #\n",
    "df29 = pd.read_csv('../Data/benign-1/web_multiple_03.csv') #\n",
    "df30 = pd.read_csv('../Data/benign-1/web_multiple_05.csv') #\n",
    "df31 = pd.read_csv('../Data/benign-1/web_multiple_06.csv') #\n",
    "\n",
    "df_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 -->> 43173\n",
      "df2 -->> 1213354\n",
      "df3 -->> 3621\n",
      "df4 -->> 22111\n",
      "df5 -->> 14156\n",
      "df6 -->> 24476\n",
      "df7 -->> 3106\n",
      "df32 -->> 18460\n",
      "df33 -->> 10285\n",
      "df34 -->> 7708\n",
      "df35 -->> 234892\n",
      "/////////////////////////////////////////////////\n",
      "df8 -->> 4550\n",
      "df9 -->> 3869\n",
      "df10 -->> 5327\n",
      "df11 -->> 4727\n",
      "df12 -->> 4190\n",
      "df13 -->> 3481\n",
      "df14 -->> 38576\n",
      "df15 -->> 5961\n",
      "df16 -->> 1803\n",
      "df17 -->> 7029\n",
      "df18 -->> 1012\n",
      "df19 -->> 96545\n",
      "df20 -->> 108065\n",
      "df21 -->> 25138\n",
      "df22 -->> 91274\n",
      "df23 -->> 23597\n",
      "df24 -->> 59635\n",
      "df25 -->> 625216\n",
      "df26 -->> 266935\n",
      "df27 -->> 453471\n",
      "df28 -->> 654495\n",
      "df29 -->> 6764\n",
      "df30 -->> 25300\n",
      "df31 -->> 3689\n"
     ]
    }
   ],
   "source": [
    "print(\"df1 -->> {}\".format(len(df1)))\n",
    "print(\"df2 -->> {}\".format(len(df2)))\n",
    "print(\"df3 -->> {}\".format(len(df3)))\n",
    "print(\"df4 -->> {}\".format(len(df4)))\n",
    "print(\"df5 -->> {}\".format(len(df5)))\n",
    "print(\"df6 -->> {}\".format(len(df6)))\n",
    "print(\"df7 -->> {}\".format(len(df7)))\n",
    "print(\"df32 -->> {}\".format(len(df32)))\n",
    "print(\"df33 -->> {}\".format(len(df33)))\n",
    "print(\"df34 -->> {}\".format(len(df34)))\n",
    "print(\"df35 -->> {}\".format(len(df35)))\n",
    "print(\"/////////////////////////////////////////////////\")\n",
    "\n",
    "\n",
    "print(\"df8 -->> {}\".format(len(df8)))\n",
    "print(\"df9 -->> {}\".format(len(df9)))\n",
    "print(\"df10 -->> {}\".format(len(df10)))\n",
    "print(\"df11 -->> {}\".format(len(df11)))\n",
    "print(\"df12 -->> {}\".format(len(df12)))\n",
    "print(\"df13 -->> {}\".format(len(df13)))\n",
    "print(\"df14 -->> {}\".format(len(df14)))\n",
    "print(\"df15 -->> {}\".format(len(df15)))\n",
    "print(\"df16 -->> {}\".format(len(df16)))\n",
    "print(\"df17 -->> {}\".format(len(df17)))\n",
    "print(\"df18 -->> {}\".format(len(df18)))\n",
    "print(\"df19 -->> {}\".format(len(df19)))\n",
    "print(\"df20 -->> {}\".format(len(df20)))\n",
    "print(\"df21 -->> {}\".format(len(df21)))\n",
    "print(\"df22 -->> {}\".format(len(df22)))\n",
    "print(\"df23 -->> {}\".format(len(df23)))\n",
    "print(\"df24 -->> {}\".format(len(df24)))\n",
    "print(\"df25 -->> {}\".format(len(df25)))\n",
    "print(\"df26 -->> {}\".format(len(df26)))\n",
    "print(\"df27 -->> {}\".format(len(df27)))\n",
    "print(\"df28 -->> {}\".format(len(df28)))\n",
    "print(\"df29 -->> {}\".format(len(df29)))\n",
    "print(\"df30 -->> {}\".format(len(df30)))\n",
    "print(\"df31 -->> {}\".format(len(df31)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#                                                               #\n",
    "#                     Filtering                                 #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "# For WebOS = 18:56:80:17:d0:ef\n",
    "index_names = df1[((df1['HW_dst'] != '18:56:80:17:d0:ef') & (df1['Hw_src'] != '18:56:80:17:d0:ef'))].index\n",
    "df1.drop(index_names, inplace = True)\n",
    "\n",
    "# Big_Server_Monero_mining_data = a4:bb:6d:ac:e1:fd\n",
    "\n",
    "index_names = df2[((df2['HW_dst'] != 'a4:bb:6d:ac:e1:fd') & (df2['Hw_src'] != 'a4:bb:6d:ac:e1:fd'))].index\n",
    "df2.drop(index_names, inplace = True)\n",
    "\n",
    "# ege_data_rasberry = dc:a6:32:67:66:4b\t\n",
    "\n",
    "index_names = df3[((df3['HW_dst'] != 'dc:a6:32:67:66:4b') & (df3['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df3.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_binary_monero_mining = dc:a6:32:68:35:8a\n",
    "\n",
    "index_names = df4[((df4['HW_dst'] != 'dc:a6:32:68:35:8a') & (df4['Hw_src'] != 'dc:a6:32:68:35:8a'))].index\n",
    "df4.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_network_data_2 = dc:a6:32:67:66:4b\n",
    "\n",
    "index_names = df5[((df5['HW_dst'] != 'dc:a6:32:67:66:4b') & (df5['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df5.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry-Webmine = dc:a6:32:67:66:4b\n",
    "index_names = df6[((df6['HW_dst'] != 'dc:a6:32:67:66:4b') & (df6['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df6.drop(index_names, inplace = True)\n",
    "\n",
    "# Server_Webmine_Network_data = a4:bb:6d:ac:e1:fd\n",
    "\n",
    "index_names = df7[((df7['HW_dst'] != 'a4:bb:6d:ac:e1:fd') & (df7['Hw_src'] != 'a4:bb:6d:ac:e1:fd'))].index\n",
    "df7.drop(index_names, inplace = True)\n",
    "\n",
    "# Server_%50_Mining = a4:bb:6d:ac:e1:fd\n",
    "\n",
    "index_names = df32[((df32['HW_dst'] != 'a4:bb:6d:ac:e1:fd') & (df32['Hw_src'] != 'a4:bb:6d:ac:e1:fd'))].index\n",
    "df32.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_webmine_%10 = dc:a6:32:67:66:4b\n",
    "\n",
    "index_names = df33[((df33['HW_dst'] != 'dc:a6:32:67:66:4b') & (df33['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df33.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_webmine_%50 = dc:a6:32:68:35:8a\n",
    "\n",
    "index_names = df34[((df34['HW_dst'] != 'dc:a6:32:68:35:8a') & (df34['Hw_src'] != 'dc:a6:32:68:35:8a'))].index\n",
    "df34.drop(index_names, inplace = True)\n",
    "\n",
    "# Desktop_Webmine_%100 = dc:a6:32:68:35:8a\n",
    "\n",
    "index_names = df35[((df35['HW_dst'] != 'd8:3b:bf:8f:ba:ba') & (df35['Hw_src'] != 'd8:3b:bf:8f:ba:ba'))].index\n",
    "df35.drop(index_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#                                                               #\n",
    "#      Labeling Features for further calculations               #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "df1.insert(7, \"Is_malicious\", 1)\n",
    "df2.insert(7, \"Is_malicious\", 1)\n",
    "df3.insert(7, \"Is_malicious\", 1)\n",
    "df4.insert(7, \"Is_malicious\", 1)\n",
    "df5.insert(7, \"Is_malicious\", 1)\n",
    "df6.insert(7, \"Is_malicious\", 1)\n",
    "df7.insert(7, \"Is_malicious\", 1)\n",
    "\n",
    "# ========================================================\n",
    "\n",
    "df8.insert(7, \"Is_malicious\", 0)\n",
    "df9.insert(7, \"Is_malicious\", 0)\n",
    "df10.insert(7, \"Is_malicious\", 0)\n",
    "df11.insert(7, \"Is_malicious\", 0)\n",
    "df12.insert(7, \"Is_malicious\", 0)\n",
    "df13.insert(7, \"Is_malicious\", 0)\n",
    "df14.insert(7, \"Is_malicious\", 0)\n",
    "df15.insert(7, \"Is_malicious\", 0)\n",
    "df16.insert(7, \"Is_malicious\", 0)\n",
    "df17.insert(7, \"Is_malicious\", 0)\n",
    "df18.insert(7, \"Is_malicious\", 0)\n",
    "df19.insert(7, \"Is_malicious\", 0)\n",
    "df20.insert(7, \"Is_malicious\", 0)\n",
    "df21.insert(7, \"Is_malicious\", 0)\n",
    "df22.insert(7, \"Is_malicious\", 0)\n",
    "df23.insert(7, \"Is_malicious\", 0)\n",
    "df24.insert(7, \"Is_malicious\", 0)\n",
    "\n",
    "\n",
    "# ========================================================\n",
    "\n",
    "df25.insert(7, \"Is_malicious\", 0)\n",
    "df26.insert(7, \"Is_malicious\", 0)\n",
    "df27.insert(7, \"Is_malicious\", 0)\n",
    "df28.insert(7, \"Is_malicious\", 0)\n",
    "df29.insert(7, \"Is_malicious\", 0)\n",
    "df30.insert(7, \"Is_malicious\", 0)\n",
    "df31.insert(7, \"Is_malicious\", 0)\n",
    "\n",
    "df32.insert(7, \"Is_malicious\", 1)\n",
    "df33.insert(7, \"Is_malicious\", 1)\n",
    "df34.insert(7, \"Is_malicious\", 1)\n",
    "df35.insert(7, \"Is_malicious\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 -->> 41572\n",
      "df2 -->> 1198039\n",
      "df3 -->> 3519\n",
      "df4 -->> 11745\n",
      "df5 -->> 12871\n",
      "df6 -->> 19643\n",
      "df7 -->> 2539\n",
      "df8 -->> 4550\n",
      "df9 -->> 3869\n",
      "df10 -->> 5327\n",
      "df11 -->> 4727\n",
      "df12 -->> 4190\n",
      "df13 -->> 3481\n",
      "df14 -->> 38576\n",
      "df15 -->> 5961\n",
      "df16 -->> 1803\n",
      "df17 -->> 7029\n",
      "df18 -->> 1012\n",
      "df19 -->> 96545\n",
      "df20 -->> 108065\n",
      "df21 -->> 25138\n",
      "df22 -->> 91274\n",
      "df23 -->> 23597\n",
      "df24 -->> 59619\n",
      "df25 -->> 625194\n",
      "df26 -->> 266935\n",
      "df27 -->> 453466\n",
      "df28 -->> 654479\n",
      "df29 -->> 6764\n",
      "df30 -->> 25288\n",
      "df31 -->> 3689\n",
      "df32 -->> 16744\n",
      "df33 -->> 9880\n",
      "df34 -->> 6406\n",
      "df35 -->> 234272\n"
     ]
    }
   ],
   "source": [
    "print(\"df1 -->> {}\".format(len(df1.dropna())))\n",
    "print(\"df2 -->> {}\".format(len(df2.dropna())))\n",
    "print(\"df3 -->> {}\".format(len(df3.dropna())))\n",
    "print(\"df4 -->> {}\".format(len(df4.dropna())))\n",
    "print(\"df5 -->> {}\".format(len(df5.dropna())))\n",
    "print(\"df6 -->> {}\".format(len(df6.dropna())))\n",
    "print(\"df7 -->> {}\".format(len(df7.dropna())))\n",
    "print(\"df8 -->> {}\".format(len(df8.dropna())))\n",
    "print(\"df9 -->> {}\".format(len(df9.dropna())))\n",
    "print(\"df10 -->> {}\".format(len(df10.dropna())))\n",
    "print(\"df11 -->> {}\".format(len(df11.dropna())))\n",
    "print(\"df12 -->> {}\".format(len(df12.dropna())))\n",
    "print(\"df13 -->> {}\".format(len(df13.dropna())))\n",
    "print(\"df14 -->> {}\".format(len(df14.dropna())))\n",
    "print(\"df15 -->> {}\".format(len(df15.dropna())))\n",
    "print(\"df16 -->> {}\".format(len(df16.dropna())))\n",
    "print(\"df17 -->> {}\".format(len(df17.dropna())))\n",
    "print(\"df18 -->> {}\".format(len(df18.dropna())))\n",
    "print(\"df19 -->> {}\".format(len(df19.dropna())))\n",
    "print(\"df20 -->> {}\".format(len(df20.dropna())))\n",
    "print(\"df21 -->> {}\".format(len(df21.dropna())))\n",
    "print(\"df22 -->> {}\".format(len(df22.dropna())))\n",
    "print(\"df23 -->> {}\".format(len(df23.dropna())))\n",
    "print(\"df24 -->> {}\".format(len(df24.dropna())))\n",
    "print(\"df25 -->> {}\".format(len(df25.dropna())))\n",
    "print(\"df26 -->> {}\".format(len(df26.dropna())))\n",
    "print(\"df27 -->> {}\".format(len(df27.dropna())))\n",
    "print(\"df28 -->> {}\".format(len(df28.dropna())))\n",
    "print(\"df29 -->> {}\".format(len(df29.dropna())))\n",
    "print(\"df30 -->> {}\".format(len(df30.dropna())))\n",
    "print(\"df31 -->> {}\".format(len(df31.dropna())))\n",
    "print(\"df32 -->> {}\".format(len(df32.dropna())))\n",
    "print(\"df33 -->> {}\".format(len(df33.dropna())))\n",
    "print(\"df34 -->> {}\".format(len(df34.dropna())))\n",
    "print(\"df35 -->> {}\".format(len(df35.dropna())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_process(a,b,x):\n",
    "    \n",
    "    df_malicious = a.copy()\n",
    "    df_benign    = b.copy()\n",
    "    \n",
    "    from tsfresh import extract_features, select_features\n",
    "    from tsfresh.utilities.dataframe_functions import impute\n",
    "    from tsfresh import extract_features\n",
    "    from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "\n",
    "\n",
    "    df_malicious.reset_index(drop=True, inplace=True) #reset index\n",
    "    df_malicious['id']= np.floor(df_malicious.index.array/10)\n",
    "    df_benign.reset_index(drop=True, inplace=True) #reset index\n",
    "    df_benign['id']= np.floor(df_benign.index.array/10)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    tf1=tsfresh.extract_features(df_malicious,impute_function=impute, column_kind='Is_malicious',\n",
    "                                 column_id='id',column_sort=\"Time\",column_value = \"Length\")\n",
    "    tf1['class']= 1\n",
    "\n",
    "    \n",
    "    \n",
    "    tf2=tsfresh.extract_features(df_benign,impute_function=impute, column_kind='Is_malicious',\n",
    "                                 column_id='id',column_sort=\"Time\",column_value = \"Length\")\n",
    "    tf2['class']= 0\n",
    "\n",
    "\n",
    "    tf2.columns = tf1.columns\n",
    "\n",
    "    features=pd.concat([tf1,tf2])\n",
    "\n",
    "\n",
    "    features2 = features.copy()\n",
    "    features2.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    y = pd.Series(data = features2['class'], index=features2.index)\n",
    "    \n",
    "    from tsfresh.examples import load_robot_execution_failures\n",
    "    from tsfresh import extract_features, select_features\n",
    "    from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "\n",
    "    relevance_table = calculate_relevance_table(features2, y)\n",
    "    relevance_table = relevance_table[relevance_table.relevant]\n",
    "    relevance_table.sort_values(\"p_value\", inplace=True)\n",
    "\n",
    "    relevance_table\n",
    "    \n",
    "    best_features = relevance_table[relevance_table['p_value'] <= 0.05]\n",
    "\n",
    "    df_ML = pd.DataFrame()\n",
    "\n",
    "    for pkt in best_features:\n",
    "        df_ML[best_features.feature] = features[best_features.feature]\n",
    "\n",
    "    final = ML_Process(df_ML,x)\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_Process(df_ML,x):\n",
    "    df_results = x.copy() \n",
    "    print('let the ml starts')\n",
    "  \n",
    "    from sklearn import neighbors, metrics\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    #X = df_finalized[['Time', 'Length','Protocol']].values\n",
    "    X = df_ML.drop('class',axis=1).to_numpy()\n",
    "    #y = df_finalized[['Is_malicious']]\n",
    "    y = df_ML['class'].to_numpy()\n",
    "\n",
    "\n",
    "    #print(X,y)\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    Le = LabelEncoder()\n",
    "    for i in range(len(X[0])):\n",
    "        X[:, i] = Le.fit_transform(X[:, i])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=8675309)\n",
    "\n",
    "    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    #from xgboost import XGBClassifier\n",
    "    from sklearn import model_selection\n",
    "    from sklearn.utils import class_weight\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    y_train = y_train.ravel()\n",
    "    dfs = []\n",
    "    models = [\n",
    "        ('SVM-linear-scale-1', SVC(C = 1, kernel = 'linear',gamma ='scale')),\n",
    "        ('SVM-poly-scale-1', SVC(C = 1, kernel = 'poly',gamma ='scale')),\n",
    "        ('SVM-rbf-scale-1', SVC(C = 1, kernel = 'rbf',gamma ='scale')),\n",
    "        ('SVM-sigmoid-scale-1', SVC(C = 1, kernel = 'sigmoid',gamma ='scale')),\n",
    "        ('SVM-linear-auto-1', SVC(C = 1, kernel = 'linear',gamma ='auto')),\n",
    "        ('SVM-poly-auto-1', SVC(C = 1, kernel = 'poly',gamma ='auto')),\n",
    "        ('SVM-rbf-auto-1', SVC(C = 1, kernel = 'rbf',gamma ='auto')),\n",
    "        ('SVM-sigmoid-auto-1', SVC(C = 1, kernel = 'sigmoid',gamma ='auto')),\n",
    "        ('SVM-linear-scale-2', SVC(C = 2, kernel = 'linear',gamma ='scale')),\n",
    "        ('SVM-poly-scale-2', SVC(C = 2, kernel = 'poly',gamma ='scale')),\n",
    "        ('SVM-rbf-scale-2', SVC(C = 2, kernel = 'rbf',gamma ='scale')),\n",
    "        ('SVM-sigmoid-scale-2', SVC(C = 2, kernel = 'sigmoid',gamma ='scale')),\n",
    "        ('SVM-linear-auto-2', SVC(C = 2, kernel = 'linear',gamma ='auto')),\n",
    "        ('SVM-poly-auto-2', SVC(C = 2, kernel = 'poly',gamma ='auto')),\n",
    "        ('SVM-rbf-auto-2', SVC(C = 2, kernel = 'rbf',gamma ='auto')),\n",
    "        ('SVM-sigmoid-auto-2', SVC(C = 2, kernel = 'sigmoid',gamma ='auto'))\n",
    "            ]\n",
    "    results = []\n",
    "    names = []\n",
    "    scoring = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted', 'roc_auc']\n",
    "    target_names = ['malignant', 'benign']\n",
    "    for name, model in models:\n",
    "        kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state=90210)\n",
    "        cv_results = model_selection.cross_validate(model, X_train, y_train, cv=kfold, \n",
    "                                                    scoring=scoring)\n",
    "\n",
    "        clf = model.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(name)\n",
    "        print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        this_df = pd.DataFrame(cv_results)\n",
    "        this_df['model'] = name\n",
    "        dfs.append(this_df)\n",
    "        final = pd.concat(dfs, ignore_index=True)\n",
    "        print(final)\n",
    "\n",
    "    return(final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 1000\n",
      "benign: 1000\n",
      "0 NAN in malicious!\n",
      "0 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 1000\n",
      "benign: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 34/34 [00:04<00:00,  8.22it/s]\n",
      "Feature Extraction: 100%|██████████| 34/34 [00:03<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let the ml starts\n",
      "SVM-linear-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.77      0.87      0.82        23\n",
      "      benign       0.88      0.78      0.82        27\n",
      "\n",
      "    accuracy                           0.82        50\n",
      "   macro avg       0.82      0.82      0.82        50\n",
      "weighted avg       0.83      0.82      0.82        50\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  0.003488    0.007741       0.800000                 0.800000   \n",
      "1  0.003334    0.006048       0.866667                 0.866667   \n",
      "2  0.002480    0.005830       0.800000                 0.807143   \n",
      "3  0.003535    0.006545       0.766667                 0.767857   \n",
      "4  0.006017    0.006110       0.700000                 0.708333   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0              0.800000          0.800000      0.861607  SVM-linear-scale-1  \n",
      "1              0.866667          0.866667      0.828054  SVM-linear-scale-1  \n",
      "2              0.800000          0.800000      0.857143  SVM-linear-scale-1  \n",
      "3              0.766667          0.766407      0.768889  SVM-linear-scale-1  \n",
      "4              0.700000          0.696970      0.826667  SVM-linear-scale-1  \n",
      "SVM-poly-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.88      0.96      0.92        23\n",
      "      benign       0.96      0.89      0.92        27\n",
      "\n",
      "    accuracy                           0.92        50\n",
      "   macro avg       0.92      0.92      0.92        50\n",
      "weighted avg       0.92      0.92      0.92        50\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  0.003488    0.007741       0.800000                 0.800000   \n",
      "1  0.003334    0.006048       0.866667                 0.866667   \n",
      "2  0.002480    0.005830       0.800000                 0.807143   \n",
      "3  0.003535    0.006545       0.766667                 0.767857   \n",
      "4  0.006017    0.006110       0.700000                 0.708333   \n",
      "5  0.001961    0.006303       0.900000                 0.902222   \n",
      "6  0.001191    0.005944       0.833333                 0.851190   \n",
      "7  0.001160    0.006181       0.933333                 0.933333   \n",
      "8  0.001349    0.006564       0.866667                 0.866667   \n",
      "9  0.001328    0.006661       0.900000                 0.901786   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0              0.800000          0.800000      0.861607  SVM-linear-scale-1  \n",
      "1              0.866667          0.866667      0.828054  SVM-linear-scale-1  \n",
      "2              0.800000          0.800000      0.857143  SVM-linear-scale-1  \n",
      "3              0.766667          0.766407      0.768889  SVM-linear-scale-1  \n",
      "4              0.700000          0.696970      0.826667  SVM-linear-scale-1  \n",
      "5              0.900000          0.900111      0.848214    SVM-poly-scale-1  \n",
      "6              0.833333          0.833890      0.841629    SVM-poly-scale-1  \n",
      "7              0.933333          0.933333      0.924107    SVM-poly-scale-1  \n",
      "8              0.866667          0.866667      0.866667    SVM-poly-scale-1  \n",
      "9              0.900000          0.899889      0.977778    SVM-poly-scale-1  \n",
      "SVM-rbf-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.85      1.00      0.92        23\n",
      "      benign       1.00      0.85      0.92        27\n",
      "\n",
      "    accuracy                           0.92        50\n",
      "   macro avg       0.93      0.93      0.92        50\n",
      "weighted avg       0.93      0.92      0.92        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.003488    0.007741       0.800000                 0.800000   \n",
      "1   0.003334    0.006048       0.866667                 0.866667   \n",
      "2   0.002480    0.005830       0.800000                 0.807143   \n",
      "3   0.003535    0.006545       0.766667                 0.767857   \n",
      "4   0.006017    0.006110       0.700000                 0.708333   \n",
      "5   0.001961    0.006303       0.900000                 0.902222   \n",
      "6   0.001191    0.005944       0.833333                 0.851190   \n",
      "7   0.001160    0.006181       0.933333                 0.933333   \n",
      "8   0.001349    0.006564       0.866667                 0.866667   \n",
      "9   0.001328    0.006661       0.900000                 0.901786   \n",
      "10  0.002751    0.006146       0.866667                 0.866667   \n",
      "11  0.001028    0.006298       0.800000                 0.800000   \n",
      "12  0.001002    0.006042       0.866667                 0.866667   \n",
      "13  0.000986    0.006017       0.800000                 0.805430   \n",
      "14  0.001088    0.006094       0.933333                 0.933333   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               0.800000          0.800000      0.861607  SVM-linear-scale-1  \n",
      "1               0.866667          0.866667      0.828054  SVM-linear-scale-1  \n",
      "2               0.800000          0.800000      0.857143  SVM-linear-scale-1  \n",
      "3               0.766667          0.766407      0.768889  SVM-linear-scale-1  \n",
      "4               0.700000          0.696970      0.826667  SVM-linear-scale-1  \n",
      "5               0.900000          0.900111      0.848214    SVM-poly-scale-1  \n",
      "6               0.833333          0.833890      0.841629    SVM-poly-scale-1  \n",
      "7               0.933333          0.933333      0.924107    SVM-poly-scale-1  \n",
      "8               0.866667          0.866667      0.866667    SVM-poly-scale-1  \n",
      "9               0.900000          0.899889      0.977778    SVM-poly-scale-1  \n",
      "10              0.866667          0.866667      0.910714     SVM-rbf-scale-1  \n",
      "11              0.800000          0.800000      0.914027     SVM-rbf-scale-1  \n",
      "12              0.866667          0.866667      0.919643     SVM-rbf-scale-1  \n",
      "13              0.800000          0.799107      0.902222     SVM-rbf-scale-1  \n",
      "14              0.933333          0.933333      0.986667     SVM-rbf-scale-1  \n",
      "SVM-sigmoid-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.56      0.65      0.60        23\n",
      "      benign       0.65      0.56      0.60        27\n",
      "\n",
      "    accuracy                           0.60        50\n",
      "   macro avg       0.60      0.60      0.60        50\n",
      "weighted avg       0.61      0.60      0.60        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.003488    0.007741       0.800000                 0.800000   \n",
      "1   0.003334    0.006048       0.866667                 0.866667   \n",
      "2   0.002480    0.005830       0.800000                 0.807143   \n",
      "3   0.003535    0.006545       0.766667                 0.767857   \n",
      "4   0.006017    0.006110       0.700000                 0.708333   \n",
      "5   0.001961    0.006303       0.900000                 0.902222   \n",
      "6   0.001191    0.005944       0.833333                 0.851190   \n",
      "7   0.001160    0.006181       0.933333                 0.933333   \n",
      "8   0.001349    0.006564       0.866667                 0.866667   \n",
      "9   0.001328    0.006661       0.900000                 0.901786   \n",
      "10  0.002751    0.006146       0.866667                 0.866667   \n",
      "11  0.001028    0.006298       0.800000                 0.800000   \n",
      "12  0.001002    0.006042       0.866667                 0.866667   \n",
      "13  0.000986    0.006017       0.800000                 0.805430   \n",
      "14  0.001088    0.006094       0.933333                 0.933333   \n",
      "15  0.002041    0.005966       0.600000                 0.598148   \n",
      "16  0.001482    0.006200       0.433333                 0.451852   \n",
      "17  0.001376    0.005934       0.466667                 0.478788   \n",
      "18  0.001431    0.006403       0.633333                 0.633929   \n",
      "19  0.001770    0.007085       0.633333                 0.638889   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.800000          0.800000      0.861607   SVM-linear-scale-1  \n",
      "1               0.866667          0.866667      0.828054   SVM-linear-scale-1  \n",
      "2               0.800000          0.800000      0.857143   SVM-linear-scale-1  \n",
      "3               0.766667          0.766407      0.768889   SVM-linear-scale-1  \n",
      "4               0.700000          0.696970      0.826667   SVM-linear-scale-1  \n",
      "5               0.900000          0.900111      0.848214     SVM-poly-scale-1  \n",
      "6               0.833333          0.833890      0.841629     SVM-poly-scale-1  \n",
      "7               0.933333          0.933333      0.924107     SVM-poly-scale-1  \n",
      "8               0.866667          0.866667      0.866667     SVM-poly-scale-1  \n",
      "9               0.900000          0.899889      0.977778     SVM-poly-scale-1  \n",
      "10              0.866667          0.866667      0.910714      SVM-rbf-scale-1  \n",
      "11              0.800000          0.800000      0.914027      SVM-rbf-scale-1  \n",
      "12              0.866667          0.866667      0.919643      SVM-rbf-scale-1  \n",
      "13              0.800000          0.799107      0.902222      SVM-rbf-scale-1  \n",
      "14              0.933333          0.933333      0.986667      SVM-rbf-scale-1  \n",
      "15              0.600000          0.596380      0.580357  SVM-sigmoid-scale-1  \n",
      "16              0.433333          0.430182      0.389140  SVM-sigmoid-scale-1  \n",
      "17              0.466667          0.437037      0.366071  SVM-sigmoid-scale-1  \n",
      "18              0.633333          0.632925      0.653333  SVM-sigmoid-scale-1  \n",
      "19              0.633333          0.629630      0.631111  SVM-sigmoid-scale-1  \n",
      "SVM-linear-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.77      0.87      0.82        23\n",
      "      benign       0.88      0.78      0.82        27\n",
      "\n",
      "    accuracy                           0.82        50\n",
      "   macro avg       0.82      0.82      0.82        50\n",
      "weighted avg       0.83      0.82      0.82        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.003488    0.007741       0.800000                 0.800000   \n",
      "1   0.003334    0.006048       0.866667                 0.866667   \n",
      "2   0.002480    0.005830       0.800000                 0.807143   \n",
      "3   0.003535    0.006545       0.766667                 0.767857   \n",
      "4   0.006017    0.006110       0.700000                 0.708333   \n",
      "5   0.001961    0.006303       0.900000                 0.902222   \n",
      "6   0.001191    0.005944       0.833333                 0.851190   \n",
      "7   0.001160    0.006181       0.933333                 0.933333   \n",
      "8   0.001349    0.006564       0.866667                 0.866667   \n",
      "9   0.001328    0.006661       0.900000                 0.901786   \n",
      "10  0.002751    0.006146       0.866667                 0.866667   \n",
      "11  0.001028    0.006298       0.800000                 0.800000   \n",
      "12  0.001002    0.006042       0.866667                 0.866667   \n",
      "13  0.000986    0.006017       0.800000                 0.805430   \n",
      "14  0.001088    0.006094       0.933333                 0.933333   \n",
      "15  0.002041    0.005966       0.600000                 0.598148   \n",
      "16  0.001482    0.006200       0.433333                 0.451852   \n",
      "17  0.001376    0.005934       0.466667                 0.478788   \n",
      "18  0.001431    0.006403       0.633333                 0.633929   \n",
      "19  0.001770    0.007085       0.633333                 0.638889   \n",
      "20  0.004808    0.006425       0.800000                 0.800000   \n",
      "21  0.003999    0.007776       0.866667                 0.866667   \n",
      "22  0.001664    0.006598       0.800000                 0.807143   \n",
      "23  0.003714    0.006263       0.766667                 0.767857   \n",
      "24  0.007159    0.006453       0.700000                 0.708333   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.800000          0.800000      0.861607   SVM-linear-scale-1  \n",
      "1               0.866667          0.866667      0.828054   SVM-linear-scale-1  \n",
      "2               0.800000          0.800000      0.857143   SVM-linear-scale-1  \n",
      "3               0.766667          0.766407      0.768889   SVM-linear-scale-1  \n",
      "4               0.700000          0.696970      0.826667   SVM-linear-scale-1  \n",
      "5               0.900000          0.900111      0.848214     SVM-poly-scale-1  \n",
      "6               0.833333          0.833890      0.841629     SVM-poly-scale-1  \n",
      "7               0.933333          0.933333      0.924107     SVM-poly-scale-1  \n",
      "8               0.866667          0.866667      0.866667     SVM-poly-scale-1  \n",
      "9               0.900000          0.899889      0.977778     SVM-poly-scale-1  \n",
      "10              0.866667          0.866667      0.910714      SVM-rbf-scale-1  \n",
      "11              0.800000          0.800000      0.914027      SVM-rbf-scale-1  \n",
      "12              0.866667          0.866667      0.919643      SVM-rbf-scale-1  \n",
      "13              0.800000          0.799107      0.902222      SVM-rbf-scale-1  \n",
      "14              0.933333          0.933333      0.986667      SVM-rbf-scale-1  \n",
      "15              0.600000          0.596380      0.580357  SVM-sigmoid-scale-1  \n",
      "16              0.433333          0.430182      0.389140  SVM-sigmoid-scale-1  \n",
      "17              0.466667          0.437037      0.366071  SVM-sigmoid-scale-1  \n",
      "18              0.633333          0.632925      0.653333  SVM-sigmoid-scale-1  \n",
      "19              0.633333          0.629630      0.631111  SVM-sigmoid-scale-1  \n",
      "20              0.800000          0.800000      0.861607    SVM-linear-auto-1  \n",
      "21              0.866667          0.866667      0.828054    SVM-linear-auto-1  \n",
      "22              0.800000          0.800000      0.857143    SVM-linear-auto-1  \n",
      "23              0.766667          0.766407      0.768889    SVM-linear-auto-1  \n",
      "24              0.700000          0.696970      0.826667    SVM-linear-auto-1  \n",
      "SVM-poly-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.77      0.87      0.82        23\n",
      "      benign       0.88      0.78      0.82        27\n",
      "\n",
      "    accuracy                           0.82        50\n",
      "   macro avg       0.82      0.82      0.82        50\n",
      "weighted avg       0.83      0.82      0.82        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.003488    0.007741       0.800000                 0.800000   \n",
      "1   0.003334    0.006048       0.866667                 0.866667   \n",
      "2   0.002480    0.005830       0.800000                 0.807143   \n",
      "3   0.003535    0.006545       0.766667                 0.767857   \n",
      "4   0.006017    0.006110       0.700000                 0.708333   \n",
      "5   0.001961    0.006303       0.900000                 0.902222   \n",
      "6   0.001191    0.005944       0.833333                 0.851190   \n",
      "7   0.001160    0.006181       0.933333                 0.933333   \n",
      "8   0.001349    0.006564       0.866667                 0.866667   \n",
      "9   0.001328    0.006661       0.900000                 0.901786   \n",
      "10  0.002751    0.006146       0.866667                 0.866667   \n",
      "11  0.001028    0.006298       0.800000                 0.800000   \n",
      "12  0.001002    0.006042       0.866667                 0.866667   \n",
      "13  0.000986    0.006017       0.800000                 0.805430   \n",
      "14  0.001088    0.006094       0.933333                 0.933333   \n",
      "15  0.002041    0.005966       0.600000                 0.598148   \n",
      "16  0.001482    0.006200       0.433333                 0.451852   \n",
      "17  0.001376    0.005934       0.466667                 0.478788   \n",
      "18  0.001431    0.006403       0.633333                 0.633929   \n",
      "19  0.001770    0.007085       0.633333                 0.638889   \n",
      "20  0.004808    0.006425       0.800000                 0.800000   \n",
      "21  0.003999    0.007776       0.866667                 0.866667   \n",
      "22  0.001664    0.006598       0.800000                 0.807143   \n",
      "23  0.003714    0.006263       0.766667                 0.767857   \n",
      "24  0.007159    0.006453       0.700000                 0.708333   \n",
      "25  0.002162    0.007679       0.866667                 0.874405   \n",
      "26  0.001603    0.008861       0.833333                 0.833333   \n",
      "27  0.001338    0.007427       0.833333                 0.835556   \n",
      "28  0.001296    0.007241       0.700000                 0.708333   \n",
      "29  0.001514    0.006548       0.833333                 0.847222   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.800000          0.800000      0.861607   SVM-linear-scale-1  \n",
      "1               0.866667          0.866667      0.828054   SVM-linear-scale-1  \n",
      "2               0.800000          0.800000      0.857143   SVM-linear-scale-1  \n",
      "3               0.766667          0.766407      0.768889   SVM-linear-scale-1  \n",
      "4               0.700000          0.696970      0.826667   SVM-linear-scale-1  \n",
      "5               0.900000          0.900111      0.848214     SVM-poly-scale-1  \n",
      "6               0.833333          0.833890      0.841629     SVM-poly-scale-1  \n",
      "7               0.933333          0.933333      0.924107     SVM-poly-scale-1  \n",
      "8               0.866667          0.866667      0.866667     SVM-poly-scale-1  \n",
      "9               0.900000          0.899889      0.977778     SVM-poly-scale-1  \n",
      "10              0.866667          0.866667      0.910714      SVM-rbf-scale-1  \n",
      "11              0.800000          0.800000      0.914027      SVM-rbf-scale-1  \n",
      "12              0.866667          0.866667      0.919643      SVM-rbf-scale-1  \n",
      "13              0.800000          0.799107      0.902222      SVM-rbf-scale-1  \n",
      "14              0.933333          0.933333      0.986667      SVM-rbf-scale-1  \n",
      "15              0.600000          0.596380      0.580357  SVM-sigmoid-scale-1  \n",
      "16              0.433333          0.430182      0.389140  SVM-sigmoid-scale-1  \n",
      "17              0.466667          0.437037      0.366071  SVM-sigmoid-scale-1  \n",
      "18              0.633333          0.632925      0.653333  SVM-sigmoid-scale-1  \n",
      "19              0.633333          0.629630      0.631111  SVM-sigmoid-scale-1  \n",
      "20              0.800000          0.800000      0.861607    SVM-linear-auto-1  \n",
      "21              0.866667          0.866667      0.828054    SVM-linear-auto-1  \n",
      "22              0.800000          0.800000      0.857143    SVM-linear-auto-1  \n",
      "23              0.766667          0.766407      0.768889    SVM-linear-auto-1  \n",
      "24              0.700000          0.696970      0.826667    SVM-linear-auto-1  \n",
      "25              0.866667          0.866667      0.834821      SVM-poly-auto-1  \n",
      "26              0.833333          0.832381      0.841629      SVM-poly-auto-1  \n",
      "27              0.833333          0.833519      0.852679      SVM-poly-auto-1  \n",
      "28              0.700000          0.696970      0.697778      SVM-poly-auto-1  \n",
      "29              0.833333          0.831650      0.875556      SVM-poly-auto-1  \n",
      "SVM-rbf-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.47      1.00      0.64        23\n",
      "      benign       1.00      0.04      0.07        27\n",
      "\n",
      "    accuracy                           0.48        50\n",
      "   macro avg       0.73      0.52      0.36        50\n",
      "weighted avg       0.76      0.48      0.33        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.003488    0.007741       0.800000                 0.800000   \n",
      "1   0.003334    0.006048       0.866667                 0.866667   \n",
      "2   0.002480    0.005830       0.800000                 0.807143   \n",
      "3   0.003535    0.006545       0.766667                 0.767857   \n",
      "4   0.006017    0.006110       0.700000                 0.708333   \n",
      "5   0.001961    0.006303       0.900000                 0.902222   \n",
      "6   0.001191    0.005944       0.833333                 0.851190   \n",
      "7   0.001160    0.006181       0.933333                 0.933333   \n",
      "8   0.001349    0.006564       0.866667                 0.866667   \n",
      "9   0.001328    0.006661       0.900000                 0.901786   \n",
      "10  0.002751    0.006146       0.866667                 0.866667   \n",
      "11  0.001028    0.006298       0.800000                 0.800000   \n",
      "12  0.001002    0.006042       0.866667                 0.866667   \n",
      "13  0.000986    0.006017       0.800000                 0.805430   \n",
      "14  0.001088    0.006094       0.933333                 0.933333   \n",
      "15  0.002041    0.005966       0.600000                 0.598148   \n",
      "16  0.001482    0.006200       0.433333                 0.451852   \n",
      "17  0.001376    0.005934       0.466667                 0.478788   \n",
      "18  0.001431    0.006403       0.633333                 0.633929   \n",
      "19  0.001770    0.007085       0.633333                 0.638889   \n",
      "20  0.004808    0.006425       0.800000                 0.800000   \n",
      "21  0.003999    0.007776       0.866667                 0.866667   \n",
      "22  0.001664    0.006598       0.800000                 0.807143   \n",
      "23  0.003714    0.006263       0.766667                 0.767857   \n",
      "24  0.007159    0.006453       0.700000                 0.708333   \n",
      "25  0.002162    0.007679       0.866667                 0.874405   \n",
      "26  0.001603    0.008861       0.833333                 0.833333   \n",
      "27  0.001338    0.007427       0.833333                 0.835556   \n",
      "28  0.001296    0.007241       0.700000                 0.708333   \n",
      "29  0.001514    0.006548       0.833333                 0.847222   \n",
      "30  0.002358    0.006729       0.533333                 0.284444   \n",
      "31  0.001732    0.007047       0.566667                 0.321111   \n",
      "32  0.001492    0.007006       0.466667                 0.217778   \n",
      "33  0.001550    0.007166       0.500000                 0.250000   \n",
      "34  0.001464    0.007387       0.500000                 0.250000   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.800000          0.800000      0.861607   SVM-linear-scale-1  \n",
      "1               0.866667          0.866667      0.828054   SVM-linear-scale-1  \n",
      "2               0.800000          0.800000      0.857143   SVM-linear-scale-1  \n",
      "3               0.766667          0.766407      0.768889   SVM-linear-scale-1  \n",
      "4               0.700000          0.696970      0.826667   SVM-linear-scale-1  \n",
      "5               0.900000          0.900111      0.848214     SVM-poly-scale-1  \n",
      "6               0.833333          0.833890      0.841629     SVM-poly-scale-1  \n",
      "7               0.933333          0.933333      0.924107     SVM-poly-scale-1  \n",
      "8               0.866667          0.866667      0.866667     SVM-poly-scale-1  \n",
      "9               0.900000          0.899889      0.977778     SVM-poly-scale-1  \n",
      "10              0.866667          0.866667      0.910714      SVM-rbf-scale-1  \n",
      "11              0.800000          0.800000      0.914027      SVM-rbf-scale-1  \n",
      "12              0.866667          0.866667      0.919643      SVM-rbf-scale-1  \n",
      "13              0.800000          0.799107      0.902222      SVM-rbf-scale-1  \n",
      "14              0.933333          0.933333      0.986667      SVM-rbf-scale-1  \n",
      "15              0.600000          0.596380      0.580357  SVM-sigmoid-scale-1  \n",
      "16              0.433333          0.430182      0.389140  SVM-sigmoid-scale-1  \n",
      "17              0.466667          0.437037      0.366071  SVM-sigmoid-scale-1  \n",
      "18              0.633333          0.632925      0.653333  SVM-sigmoid-scale-1  \n",
      "19              0.633333          0.629630      0.631111  SVM-sigmoid-scale-1  \n",
      "20              0.800000          0.800000      0.861607    SVM-linear-auto-1  \n",
      "21              0.866667          0.866667      0.828054    SVM-linear-auto-1  \n",
      "22              0.800000          0.800000      0.857143    SVM-linear-auto-1  \n",
      "23              0.766667          0.766407      0.768889    SVM-linear-auto-1  \n",
      "24              0.700000          0.696970      0.826667    SVM-linear-auto-1  \n",
      "25              0.866667          0.866667      0.834821      SVM-poly-auto-1  \n",
      "26              0.833333          0.832381      0.841629      SVM-poly-auto-1  \n",
      "27              0.833333          0.833519      0.852679      SVM-poly-auto-1  \n",
      "28              0.700000          0.696970      0.697778      SVM-poly-auto-1  \n",
      "29              0.833333          0.831650      0.875556      SVM-poly-auto-1  \n",
      "30              0.533333          0.371014      0.593750       SVM-rbf-auto-1  \n",
      "31              0.566667          0.409929      0.558824       SVM-rbf-auto-1  \n",
      "32              0.466667          0.296970      0.531250       SVM-rbf-auto-1  \n",
      "33              0.500000          0.333333      0.566667       SVM-rbf-auto-1  \n",
      "34              0.500000          0.333333      0.500000       SVM-rbf-auto-1  \n",
      "SVM-sigmoid-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.46      1.00      0.63        23\n",
      "      benign       0.00      0.00      0.00        27\n",
      "\n",
      "    accuracy                           0.46        50\n",
      "   macro avg       0.23      0.50      0.32        50\n",
      "weighted avg       0.21      0.46      0.29        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.003488    0.007741       0.800000                 0.800000   \n",
      "1   0.003334    0.006048       0.866667                 0.866667   \n",
      "2   0.002480    0.005830       0.800000                 0.807143   \n",
      "3   0.003535    0.006545       0.766667                 0.767857   \n",
      "4   0.006017    0.006110       0.700000                 0.708333   \n",
      "5   0.001961    0.006303       0.900000                 0.902222   \n",
      "6   0.001191    0.005944       0.833333                 0.851190   \n",
      "7   0.001160    0.006181       0.933333                 0.933333   \n",
      "8   0.001349    0.006564       0.866667                 0.866667   \n",
      "9   0.001328    0.006661       0.900000                 0.901786   \n",
      "10  0.002751    0.006146       0.866667                 0.866667   \n",
      "11  0.001028    0.006298       0.800000                 0.800000   \n",
      "12  0.001002    0.006042       0.866667                 0.866667   \n",
      "13  0.000986    0.006017       0.800000                 0.805430   \n",
      "14  0.001088    0.006094       0.933333                 0.933333   \n",
      "15  0.002041    0.005966       0.600000                 0.598148   \n",
      "16  0.001482    0.006200       0.433333                 0.451852   \n",
      "17  0.001376    0.005934       0.466667                 0.478788   \n",
      "18  0.001431    0.006403       0.633333                 0.633929   \n",
      "19  0.001770    0.007085       0.633333                 0.638889   \n",
      "20  0.004808    0.006425       0.800000                 0.800000   \n",
      "21  0.003999    0.007776       0.866667                 0.866667   \n",
      "22  0.001664    0.006598       0.800000                 0.807143   \n",
      "23  0.003714    0.006263       0.766667                 0.767857   \n",
      "24  0.007159    0.006453       0.700000                 0.708333   \n",
      "25  0.002162    0.007679       0.866667                 0.874405   \n",
      "26  0.001603    0.008861       0.833333                 0.833333   \n",
      "27  0.001338    0.007427       0.833333                 0.835556   \n",
      "28  0.001296    0.007241       0.700000                 0.708333   \n",
      "29  0.001514    0.006548       0.833333                 0.847222   \n",
      "30  0.002358    0.006729       0.533333                 0.284444   \n",
      "31  0.001732    0.007047       0.566667                 0.321111   \n",
      "32  0.001492    0.007006       0.466667                 0.217778   \n",
      "33  0.001550    0.007166       0.500000                 0.250000   \n",
      "34  0.001464    0.007387       0.500000                 0.250000   \n",
      "35  0.002136    0.006567       0.533333                 0.284444   \n",
      "36  0.001074    0.006218       0.433333                 0.187778   \n",
      "37  0.001045    0.006675       0.466667                 0.217778   \n",
      "38  0.001083    0.006319       0.500000                 0.250000   \n",
      "39  0.001072    0.006569       0.500000                 0.250000   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.800000          0.800000      0.861607   SVM-linear-scale-1  \n",
      "1               0.866667          0.866667      0.828054   SVM-linear-scale-1  \n",
      "2               0.800000          0.800000      0.857143   SVM-linear-scale-1  \n",
      "3               0.766667          0.766407      0.768889   SVM-linear-scale-1  \n",
      "4               0.700000          0.696970      0.826667   SVM-linear-scale-1  \n",
      "5               0.900000          0.900111      0.848214     SVM-poly-scale-1  \n",
      "6               0.833333          0.833890      0.841629     SVM-poly-scale-1  \n",
      "7               0.933333          0.933333      0.924107     SVM-poly-scale-1  \n",
      "8               0.866667          0.866667      0.866667     SVM-poly-scale-1  \n",
      "9               0.900000          0.899889      0.977778     SVM-poly-scale-1  \n",
      "10              0.866667          0.866667      0.910714      SVM-rbf-scale-1  \n",
      "11              0.800000          0.800000      0.914027      SVM-rbf-scale-1  \n",
      "12              0.866667          0.866667      0.919643      SVM-rbf-scale-1  \n",
      "13              0.800000          0.799107      0.902222      SVM-rbf-scale-1  \n",
      "14              0.933333          0.933333      0.986667      SVM-rbf-scale-1  \n",
      "15              0.600000          0.596380      0.580357  SVM-sigmoid-scale-1  \n",
      "16              0.433333          0.430182      0.389140  SVM-sigmoid-scale-1  \n",
      "17              0.466667          0.437037      0.366071  SVM-sigmoid-scale-1  \n",
      "18              0.633333          0.632925      0.653333  SVM-sigmoid-scale-1  \n",
      "19              0.633333          0.629630      0.631111  SVM-sigmoid-scale-1  \n",
      "20              0.800000          0.800000      0.861607    SVM-linear-auto-1  \n",
      "21              0.866667          0.866667      0.828054    SVM-linear-auto-1  \n",
      "22              0.800000          0.800000      0.857143    SVM-linear-auto-1  \n",
      "23              0.766667          0.766407      0.768889    SVM-linear-auto-1  \n",
      "24              0.700000          0.696970      0.826667    SVM-linear-auto-1  \n",
      "25              0.866667          0.866667      0.834821      SVM-poly-auto-1  \n",
      "26              0.833333          0.832381      0.841629      SVM-poly-auto-1  \n",
      "27              0.833333          0.833519      0.852679      SVM-poly-auto-1  \n",
      "28              0.700000          0.696970      0.697778      SVM-poly-auto-1  \n",
      "29              0.833333          0.831650      0.875556      SVM-poly-auto-1  \n",
      "30              0.533333          0.371014      0.593750       SVM-rbf-auto-1  \n",
      "31              0.566667          0.409929      0.558824       SVM-rbf-auto-1  \n",
      "32              0.466667          0.296970      0.531250       SVM-rbf-auto-1  \n",
      "33              0.500000          0.333333      0.566667       SVM-rbf-auto-1  \n",
      "34              0.500000          0.333333      0.500000       SVM-rbf-auto-1  \n",
      "35              0.533333          0.371014      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.433333          0.262016      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.466667          0.296970      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.500000          0.333333      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.500000          0.333333      0.500000   SVM-sigmoid-auto-1  \n",
      "SVM-linear-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.77      0.87      0.82        23\n",
      "      benign       0.88      0.78      0.82        27\n",
      "\n",
      "    accuracy                           0.82        50\n",
      "   macro avg       0.82      0.82      0.82        50\n",
      "weighted avg       0.83      0.82      0.82        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.003488    0.007741       0.800000                 0.800000   \n",
      "1   0.003334    0.006048       0.866667                 0.866667   \n",
      "2   0.002480    0.005830       0.800000                 0.807143   \n",
      "3   0.003535    0.006545       0.766667                 0.767857   \n",
      "4   0.006017    0.006110       0.700000                 0.708333   \n",
      "5   0.001961    0.006303       0.900000                 0.902222   \n",
      "6   0.001191    0.005944       0.833333                 0.851190   \n",
      "7   0.001160    0.006181       0.933333                 0.933333   \n",
      "8   0.001349    0.006564       0.866667                 0.866667   \n",
      "9   0.001328    0.006661       0.900000                 0.901786   \n",
      "10  0.002751    0.006146       0.866667                 0.866667   \n",
      "11  0.001028    0.006298       0.800000                 0.800000   \n",
      "12  0.001002    0.006042       0.866667                 0.866667   \n",
      "13  0.000986    0.006017       0.800000                 0.805430   \n",
      "14  0.001088    0.006094       0.933333                 0.933333   \n",
      "15  0.002041    0.005966       0.600000                 0.598148   \n",
      "16  0.001482    0.006200       0.433333                 0.451852   \n",
      "17  0.001376    0.005934       0.466667                 0.478788   \n",
      "18  0.001431    0.006403       0.633333                 0.633929   \n",
      "19  0.001770    0.007085       0.633333                 0.638889   \n",
      "20  0.004808    0.006425       0.800000                 0.800000   \n",
      "21  0.003999    0.007776       0.866667                 0.866667   \n",
      "22  0.001664    0.006598       0.800000                 0.807143   \n",
      "23  0.003714    0.006263       0.766667                 0.767857   \n",
      "24  0.007159    0.006453       0.700000                 0.708333   \n",
      "25  0.002162    0.007679       0.866667                 0.874405   \n",
      "26  0.001603    0.008861       0.833333                 0.833333   \n",
      "27  0.001338    0.007427       0.833333                 0.835556   \n",
      "28  0.001296    0.007241       0.700000                 0.708333   \n",
      "29  0.001514    0.006548       0.833333                 0.847222   \n",
      "30  0.002358    0.006729       0.533333                 0.284444   \n",
      "31  0.001732    0.007047       0.566667                 0.321111   \n",
      "32  0.001492    0.007006       0.466667                 0.217778   \n",
      "33  0.001550    0.007166       0.500000                 0.250000   \n",
      "34  0.001464    0.007387       0.500000                 0.250000   \n",
      "35  0.002136    0.006567       0.533333                 0.284444   \n",
      "36  0.001074    0.006218       0.433333                 0.187778   \n",
      "37  0.001045    0.006675       0.466667                 0.217778   \n",
      "38  0.001083    0.006319       0.500000                 0.250000   \n",
      "39  0.001072    0.006569       0.500000                 0.250000   \n",
      "40  0.004372    0.006215       0.800000                 0.800000   \n",
      "41  0.003687    0.006250       0.866667                 0.866667   \n",
      "42  0.001746    0.006280       0.800000                 0.807143   \n",
      "43  0.003926    0.006144       0.766667                 0.767857   \n",
      "44  0.006424    0.006559       0.700000                 0.708333   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.800000          0.800000      0.861607   SVM-linear-scale-1  \n",
      "1               0.866667          0.866667      0.828054   SVM-linear-scale-1  \n",
      "2               0.800000          0.800000      0.857143   SVM-linear-scale-1  \n",
      "3               0.766667          0.766407      0.768889   SVM-linear-scale-1  \n",
      "4               0.700000          0.696970      0.826667   SVM-linear-scale-1  \n",
      "5               0.900000          0.900111      0.848214     SVM-poly-scale-1  \n",
      "6               0.833333          0.833890      0.841629     SVM-poly-scale-1  \n",
      "7               0.933333          0.933333      0.924107     SVM-poly-scale-1  \n",
      "8               0.866667          0.866667      0.866667     SVM-poly-scale-1  \n",
      "9               0.900000          0.899889      0.977778     SVM-poly-scale-1  \n",
      "10              0.866667          0.866667      0.910714      SVM-rbf-scale-1  \n",
      "11              0.800000          0.800000      0.914027      SVM-rbf-scale-1  \n",
      "12              0.866667          0.866667      0.919643      SVM-rbf-scale-1  \n",
      "13              0.800000          0.799107      0.902222      SVM-rbf-scale-1  \n",
      "14              0.933333          0.933333      0.986667      SVM-rbf-scale-1  \n",
      "15              0.600000          0.596380      0.580357  SVM-sigmoid-scale-1  \n",
      "16              0.433333          0.430182      0.389140  SVM-sigmoid-scale-1  \n",
      "17              0.466667          0.437037      0.366071  SVM-sigmoid-scale-1  \n",
      "18              0.633333          0.632925      0.653333  SVM-sigmoid-scale-1  \n",
      "19              0.633333          0.629630      0.631111  SVM-sigmoid-scale-1  \n",
      "20              0.800000          0.800000      0.861607    SVM-linear-auto-1  \n",
      "21              0.866667          0.866667      0.828054    SVM-linear-auto-1  \n",
      "22              0.800000          0.800000      0.857143    SVM-linear-auto-1  \n",
      "23              0.766667          0.766407      0.768889    SVM-linear-auto-1  \n",
      "24              0.700000          0.696970      0.826667    SVM-linear-auto-1  \n",
      "25              0.866667          0.866667      0.834821      SVM-poly-auto-1  \n",
      "26              0.833333          0.832381      0.841629      SVM-poly-auto-1  \n",
      "27              0.833333          0.833519      0.852679      SVM-poly-auto-1  \n",
      "28              0.700000          0.696970      0.697778      SVM-poly-auto-1  \n",
      "29              0.833333          0.831650      0.875556      SVM-poly-auto-1  \n",
      "30              0.533333          0.371014      0.593750       SVM-rbf-auto-1  \n",
      "31              0.566667          0.409929      0.558824       SVM-rbf-auto-1  \n",
      "32              0.466667          0.296970      0.531250       SVM-rbf-auto-1  \n",
      "33              0.500000          0.333333      0.566667       SVM-rbf-auto-1  \n",
      "34              0.500000          0.333333      0.500000       SVM-rbf-auto-1  \n",
      "35              0.533333          0.371014      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.433333          0.262016      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.466667          0.296970      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.500000          0.333333      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.500000          0.333333      0.500000   SVM-sigmoid-auto-1  \n",
      "40              0.800000          0.800000      0.861607   SVM-linear-scale-2  \n",
      "41              0.866667          0.866667      0.828054   SVM-linear-scale-2  \n",
      "42              0.800000          0.800000      0.857143   SVM-linear-scale-2  \n",
      "43              0.766667          0.766407      0.768889   SVM-linear-scale-2  \n",
      "44              0.700000          0.696970      0.826667   SVM-linear-scale-2  \n",
      "SVM-poly-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.85      0.96      0.90        23\n",
      "      benign       0.96      0.85      0.90        27\n",
      "\n",
      "    accuracy                           0.90        50\n",
      "   macro avg       0.90      0.90      0.90        50\n",
      "weighted avg       0.91      0.90      0.90        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.003488    0.007741       0.800000                 0.800000   \n",
      "1   0.003334    0.006048       0.866667                 0.866667   \n",
      "2   0.002480    0.005830       0.800000                 0.807143   \n",
      "3   0.003535    0.006545       0.766667                 0.767857   \n",
      "4   0.006017    0.006110       0.700000                 0.708333   \n",
      "5   0.001961    0.006303       0.900000                 0.902222   \n",
      "6   0.001191    0.005944       0.833333                 0.851190   \n",
      "7   0.001160    0.006181       0.933333                 0.933333   \n",
      "8   0.001349    0.006564       0.866667                 0.866667   \n",
      "9   0.001328    0.006661       0.900000                 0.901786   \n",
      "10  0.002751    0.006146       0.866667                 0.866667   \n",
      "11  0.001028    0.006298       0.800000                 0.800000   \n",
      "12  0.001002    0.006042       0.866667                 0.866667   \n",
      "13  0.000986    0.006017       0.800000                 0.805430   \n",
      "14  0.001088    0.006094       0.933333                 0.933333   \n",
      "15  0.002041    0.005966       0.600000                 0.598148   \n",
      "16  0.001482    0.006200       0.433333                 0.451852   \n",
      "17  0.001376    0.005934       0.466667                 0.478788   \n",
      "18  0.001431    0.006403       0.633333                 0.633929   \n",
      "19  0.001770    0.007085       0.633333                 0.638889   \n",
      "20  0.004808    0.006425       0.800000                 0.800000   \n",
      "21  0.003999    0.007776       0.866667                 0.866667   \n",
      "22  0.001664    0.006598       0.800000                 0.807143   \n",
      "23  0.003714    0.006263       0.766667                 0.767857   \n",
      "24  0.007159    0.006453       0.700000                 0.708333   \n",
      "25  0.002162    0.007679       0.866667                 0.874405   \n",
      "26  0.001603    0.008861       0.833333                 0.833333   \n",
      "27  0.001338    0.007427       0.833333                 0.835556   \n",
      "28  0.001296    0.007241       0.700000                 0.708333   \n",
      "29  0.001514    0.006548       0.833333                 0.847222   \n",
      "30  0.002358    0.006729       0.533333                 0.284444   \n",
      "31  0.001732    0.007047       0.566667                 0.321111   \n",
      "32  0.001492    0.007006       0.466667                 0.217778   \n",
      "33  0.001550    0.007166       0.500000                 0.250000   \n",
      "34  0.001464    0.007387       0.500000                 0.250000   \n",
      "35  0.002136    0.006567       0.533333                 0.284444   \n",
      "36  0.001074    0.006218       0.433333                 0.187778   \n",
      "37  0.001045    0.006675       0.466667                 0.217778   \n",
      "38  0.001083    0.006319       0.500000                 0.250000   \n",
      "39  0.001072    0.006569       0.500000                 0.250000   \n",
      "40  0.004372    0.006215       0.800000                 0.800000   \n",
      "41  0.003687    0.006250       0.866667                 0.866667   \n",
      "42  0.001746    0.006280       0.800000                 0.807143   \n",
      "43  0.003926    0.006144       0.766667                 0.767857   \n",
      "44  0.006424    0.006559       0.700000                 0.708333   \n",
      "45  0.002481    0.006235       0.866667                 0.874405   \n",
      "46  0.001231    0.006725       0.833333                 0.851190   \n",
      "47  0.001159    0.006132       0.900000                 0.902222   \n",
      "48  0.001221    0.006065       0.833333                 0.834821   \n",
      "49  0.001198    0.006039       0.933333                 0.941176   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.800000          0.800000      0.861607   SVM-linear-scale-1  \n",
      "1               0.866667          0.866667      0.828054   SVM-linear-scale-1  \n",
      "2               0.800000          0.800000      0.857143   SVM-linear-scale-1  \n",
      "3               0.766667          0.766407      0.768889   SVM-linear-scale-1  \n",
      "4               0.700000          0.696970      0.826667   SVM-linear-scale-1  \n",
      "5               0.900000          0.900111      0.848214     SVM-poly-scale-1  \n",
      "6               0.833333          0.833890      0.841629     SVM-poly-scale-1  \n",
      "7               0.933333          0.933333      0.924107     SVM-poly-scale-1  \n",
      "8               0.866667          0.866667      0.866667     SVM-poly-scale-1  \n",
      "9               0.900000          0.899889      0.977778     SVM-poly-scale-1  \n",
      "10              0.866667          0.866667      0.910714      SVM-rbf-scale-1  \n",
      "11              0.800000          0.800000      0.914027      SVM-rbf-scale-1  \n",
      "12              0.866667          0.866667      0.919643      SVM-rbf-scale-1  \n",
      "13              0.800000          0.799107      0.902222      SVM-rbf-scale-1  \n",
      "14              0.933333          0.933333      0.986667      SVM-rbf-scale-1  \n",
      "15              0.600000          0.596380      0.580357  SVM-sigmoid-scale-1  \n",
      "16              0.433333          0.430182      0.389140  SVM-sigmoid-scale-1  \n",
      "17              0.466667          0.437037      0.366071  SVM-sigmoid-scale-1  \n",
      "18              0.633333          0.632925      0.653333  SVM-sigmoid-scale-1  \n",
      "19              0.633333          0.629630      0.631111  SVM-sigmoid-scale-1  \n",
      "20              0.800000          0.800000      0.861607    SVM-linear-auto-1  \n",
      "21              0.866667          0.866667      0.828054    SVM-linear-auto-1  \n",
      "22              0.800000          0.800000      0.857143    SVM-linear-auto-1  \n",
      "23              0.766667          0.766407      0.768889    SVM-linear-auto-1  \n",
      "24              0.700000          0.696970      0.826667    SVM-linear-auto-1  \n",
      "25              0.866667          0.866667      0.834821      SVM-poly-auto-1  \n",
      "26              0.833333          0.832381      0.841629      SVM-poly-auto-1  \n",
      "27              0.833333          0.833519      0.852679      SVM-poly-auto-1  \n",
      "28              0.700000          0.696970      0.697778      SVM-poly-auto-1  \n",
      "29              0.833333          0.831650      0.875556      SVM-poly-auto-1  \n",
      "30              0.533333          0.371014      0.593750       SVM-rbf-auto-1  \n",
      "31              0.566667          0.409929      0.558824       SVM-rbf-auto-1  \n",
      "32              0.466667          0.296970      0.531250       SVM-rbf-auto-1  \n",
      "33              0.500000          0.333333      0.566667       SVM-rbf-auto-1  \n",
      "34              0.500000          0.333333      0.500000       SVM-rbf-auto-1  \n",
      "35              0.533333          0.371014      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.433333          0.262016      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.466667          0.296970      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.500000          0.333333      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.500000          0.333333      0.500000   SVM-sigmoid-auto-1  \n",
      "40              0.800000          0.800000      0.861607   SVM-linear-scale-2  \n",
      "41              0.866667          0.866667      0.828054   SVM-linear-scale-2  \n",
      "42              0.800000          0.800000      0.857143   SVM-linear-scale-2  \n",
      "43              0.766667          0.766407      0.768889   SVM-linear-scale-2  \n",
      "44              0.700000          0.696970      0.826667   SVM-linear-scale-2  \n",
      "45              0.866667          0.866667      0.852679     SVM-poly-scale-2  \n",
      "46              0.833333          0.833890      0.837104     SVM-poly-scale-2  \n",
      "47              0.900000          0.900111      0.915179     SVM-poly-scale-2  \n",
      "48              0.833333          0.833148      0.880000     SVM-poly-scale-2  \n",
      "49              0.933333          0.933036      0.991111     SVM-poly-scale-2  \n",
      "SVM-rbf-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.85      1.00      0.92        23\n",
      "      benign       1.00      0.85      0.92        27\n",
      "\n",
      "    accuracy                           0.92        50\n",
      "   macro avg       0.93      0.93      0.92        50\n",
      "weighted avg       0.93      0.92      0.92        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.003488    0.007741       0.800000                 0.800000   \n",
      "1   0.003334    0.006048       0.866667                 0.866667   \n",
      "2   0.002480    0.005830       0.800000                 0.807143   \n",
      "3   0.003535    0.006545       0.766667                 0.767857   \n",
      "4   0.006017    0.006110       0.700000                 0.708333   \n",
      "5   0.001961    0.006303       0.900000                 0.902222   \n",
      "6   0.001191    0.005944       0.833333                 0.851190   \n",
      "7   0.001160    0.006181       0.933333                 0.933333   \n",
      "8   0.001349    0.006564       0.866667                 0.866667   \n",
      "9   0.001328    0.006661       0.900000                 0.901786   \n",
      "10  0.002751    0.006146       0.866667                 0.866667   \n",
      "11  0.001028    0.006298       0.800000                 0.800000   \n",
      "12  0.001002    0.006042       0.866667                 0.866667   \n",
      "13  0.000986    0.006017       0.800000                 0.805430   \n",
      "14  0.001088    0.006094       0.933333                 0.933333   \n",
      "15  0.002041    0.005966       0.600000                 0.598148   \n",
      "16  0.001482    0.006200       0.433333                 0.451852   \n",
      "17  0.001376    0.005934       0.466667                 0.478788   \n",
      "18  0.001431    0.006403       0.633333                 0.633929   \n",
      "19  0.001770    0.007085       0.633333                 0.638889   \n",
      "20  0.004808    0.006425       0.800000                 0.800000   \n",
      "21  0.003999    0.007776       0.866667                 0.866667   \n",
      "22  0.001664    0.006598       0.800000                 0.807143   \n",
      "23  0.003714    0.006263       0.766667                 0.767857   \n",
      "24  0.007159    0.006453       0.700000                 0.708333   \n",
      "25  0.002162    0.007679       0.866667                 0.874405   \n",
      "26  0.001603    0.008861       0.833333                 0.833333   \n",
      "27  0.001338    0.007427       0.833333                 0.835556   \n",
      "28  0.001296    0.007241       0.700000                 0.708333   \n",
      "29  0.001514    0.006548       0.833333                 0.847222   \n",
      "30  0.002358    0.006729       0.533333                 0.284444   \n",
      "31  0.001732    0.007047       0.566667                 0.321111   \n",
      "32  0.001492    0.007006       0.466667                 0.217778   \n",
      "33  0.001550    0.007166       0.500000                 0.250000   \n",
      "34  0.001464    0.007387       0.500000                 0.250000   \n",
      "35  0.002136    0.006567       0.533333                 0.284444   \n",
      "36  0.001074    0.006218       0.433333                 0.187778   \n",
      "37  0.001045    0.006675       0.466667                 0.217778   \n",
      "38  0.001083    0.006319       0.500000                 0.250000   \n",
      "39  0.001072    0.006569       0.500000                 0.250000   \n",
      "40  0.004372    0.006215       0.800000                 0.800000   \n",
      "41  0.003687    0.006250       0.866667                 0.866667   \n",
      "42  0.001746    0.006280       0.800000                 0.807143   \n",
      "43  0.003926    0.006144       0.766667                 0.767857   \n",
      "44  0.006424    0.006559       0.700000                 0.708333   \n",
      "45  0.002481    0.006235       0.866667                 0.874405   \n",
      "46  0.001231    0.006725       0.833333                 0.851190   \n",
      "47  0.001159    0.006132       0.900000                 0.902222   \n",
      "48  0.001221    0.006065       0.833333                 0.834821   \n",
      "49  0.001198    0.006039       0.933333                 0.941176   \n",
      "50  0.001704    0.007282       0.833333                 0.834087   \n",
      "51  0.001104    0.006099       0.833333                 0.836310   \n",
      "52  0.001053    0.006409       0.833333                 0.835556   \n",
      "53  0.001009    0.006118       0.800000                 0.805430   \n",
      "54  0.001318    0.008639       0.933333                 0.933333   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.800000          0.800000      0.861607   SVM-linear-scale-1  \n",
      "1               0.866667          0.866667      0.828054   SVM-linear-scale-1  \n",
      "2               0.800000          0.800000      0.857143   SVM-linear-scale-1  \n",
      "3               0.766667          0.766407      0.768889   SVM-linear-scale-1  \n",
      "4               0.700000          0.696970      0.826667   SVM-linear-scale-1  \n",
      "5               0.900000          0.900111      0.848214     SVM-poly-scale-1  \n",
      "6               0.833333          0.833890      0.841629     SVM-poly-scale-1  \n",
      "7               0.933333          0.933333      0.924107     SVM-poly-scale-1  \n",
      "8               0.866667          0.866667      0.866667     SVM-poly-scale-1  \n",
      "9               0.900000          0.899889      0.977778     SVM-poly-scale-1  \n",
      "10              0.866667          0.866667      0.910714      SVM-rbf-scale-1  \n",
      "11              0.800000          0.800000      0.914027      SVM-rbf-scale-1  \n",
      "12              0.866667          0.866667      0.919643      SVM-rbf-scale-1  \n",
      "13              0.800000          0.799107      0.902222      SVM-rbf-scale-1  \n",
      "14              0.933333          0.933333      0.986667      SVM-rbf-scale-1  \n",
      "15              0.600000          0.596380      0.580357  SVM-sigmoid-scale-1  \n",
      "16              0.433333          0.430182      0.389140  SVM-sigmoid-scale-1  \n",
      "17              0.466667          0.437037      0.366071  SVM-sigmoid-scale-1  \n",
      "18              0.633333          0.632925      0.653333  SVM-sigmoid-scale-1  \n",
      "19              0.633333          0.629630      0.631111  SVM-sigmoid-scale-1  \n",
      "20              0.800000          0.800000      0.861607    SVM-linear-auto-1  \n",
      "21              0.866667          0.866667      0.828054    SVM-linear-auto-1  \n",
      "22              0.800000          0.800000      0.857143    SVM-linear-auto-1  \n",
      "23              0.766667          0.766407      0.768889    SVM-linear-auto-1  \n",
      "24              0.700000          0.696970      0.826667    SVM-linear-auto-1  \n",
      "25              0.866667          0.866667      0.834821      SVM-poly-auto-1  \n",
      "26              0.833333          0.832381      0.841629      SVM-poly-auto-1  \n",
      "27              0.833333          0.833519      0.852679      SVM-poly-auto-1  \n",
      "28              0.700000          0.696970      0.697778      SVM-poly-auto-1  \n",
      "29              0.833333          0.831650      0.875556      SVM-poly-auto-1  \n",
      "30              0.533333          0.371014      0.593750       SVM-rbf-auto-1  \n",
      "31              0.566667          0.409929      0.558824       SVM-rbf-auto-1  \n",
      "32              0.466667          0.296970      0.531250       SVM-rbf-auto-1  \n",
      "33              0.500000          0.333333      0.566667       SVM-rbf-auto-1  \n",
      "34              0.500000          0.333333      0.500000       SVM-rbf-auto-1  \n",
      "35              0.533333          0.371014      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.433333          0.262016      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.466667          0.296970      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.500000          0.333333      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.500000          0.333333      0.500000   SVM-sigmoid-auto-1  \n",
      "40              0.800000          0.800000      0.861607   SVM-linear-scale-2  \n",
      "41              0.866667          0.866667      0.828054   SVM-linear-scale-2  \n",
      "42              0.800000          0.800000      0.857143   SVM-linear-scale-2  \n",
      "43              0.766667          0.766407      0.768889   SVM-linear-scale-2  \n",
      "44              0.700000          0.696970      0.826667   SVM-linear-scale-2  \n",
      "45              0.866667          0.866667      0.852679     SVM-poly-scale-2  \n",
      "46              0.833333          0.833890      0.837104     SVM-poly-scale-2  \n",
      "47              0.900000          0.900111      0.915179     SVM-poly-scale-2  \n",
      "48              0.833333          0.833148      0.880000     SVM-poly-scale-2  \n",
      "49              0.933333          0.933036      0.991111     SVM-poly-scale-2  \n",
      "50              0.833333          0.832772      0.888393      SVM-rbf-scale-2  \n",
      "51              0.833333          0.833895      0.918552      SVM-rbf-scale-2  \n",
      "52              0.833333          0.833519      0.910714      SVM-rbf-scale-2  \n",
      "53              0.800000          0.799107      0.911111      SVM-rbf-scale-2  \n",
      "54              0.933333          0.933333      0.986667      SVM-rbf-scale-2  \n",
      "SVM-sigmoid-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.70      0.83      0.76        23\n",
      "      benign       0.83      0.70      0.76        27\n",
      "\n",
      "    accuracy                           0.76        50\n",
      "   macro avg       0.76      0.76      0.76        50\n",
      "weighted avg       0.77      0.76      0.76        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.003488    0.007741       0.800000                 0.800000   \n",
      "1   0.003334    0.006048       0.866667                 0.866667   \n",
      "2   0.002480    0.005830       0.800000                 0.807143   \n",
      "3   0.003535    0.006545       0.766667                 0.767857   \n",
      "4   0.006017    0.006110       0.700000                 0.708333   \n",
      "5   0.001961    0.006303       0.900000                 0.902222   \n",
      "6   0.001191    0.005944       0.833333                 0.851190   \n",
      "7   0.001160    0.006181       0.933333                 0.933333   \n",
      "8   0.001349    0.006564       0.866667                 0.866667   \n",
      "9   0.001328    0.006661       0.900000                 0.901786   \n",
      "10  0.002751    0.006146       0.866667                 0.866667   \n",
      "11  0.001028    0.006298       0.800000                 0.800000   \n",
      "12  0.001002    0.006042       0.866667                 0.866667   \n",
      "13  0.000986    0.006017       0.800000                 0.805430   \n",
      "14  0.001088    0.006094       0.933333                 0.933333   \n",
      "15  0.002041    0.005966       0.600000                 0.598148   \n",
      "16  0.001482    0.006200       0.433333                 0.451852   \n",
      "17  0.001376    0.005934       0.466667                 0.478788   \n",
      "18  0.001431    0.006403       0.633333                 0.633929   \n",
      "19  0.001770    0.007085       0.633333                 0.638889   \n",
      "20  0.004808    0.006425       0.800000                 0.800000   \n",
      "21  0.003999    0.007776       0.866667                 0.866667   \n",
      "22  0.001664    0.006598       0.800000                 0.807143   \n",
      "23  0.003714    0.006263       0.766667                 0.767857   \n",
      "24  0.007159    0.006453       0.700000                 0.708333   \n",
      "25  0.002162    0.007679       0.866667                 0.874405   \n",
      "26  0.001603    0.008861       0.833333                 0.833333   \n",
      "27  0.001338    0.007427       0.833333                 0.835556   \n",
      "28  0.001296    0.007241       0.700000                 0.708333   \n",
      "29  0.001514    0.006548       0.833333                 0.847222   \n",
      "30  0.002358    0.006729       0.533333                 0.284444   \n",
      "31  0.001732    0.007047       0.566667                 0.321111   \n",
      "32  0.001492    0.007006       0.466667                 0.217778   \n",
      "33  0.001550    0.007166       0.500000                 0.250000   \n",
      "34  0.001464    0.007387       0.500000                 0.250000   \n",
      "35  0.002136    0.006567       0.533333                 0.284444   \n",
      "36  0.001074    0.006218       0.433333                 0.187778   \n",
      "37  0.001045    0.006675       0.466667                 0.217778   \n",
      "38  0.001083    0.006319       0.500000                 0.250000   \n",
      "39  0.001072    0.006569       0.500000                 0.250000   \n",
      "40  0.004372    0.006215       0.800000                 0.800000   \n",
      "41  0.003687    0.006250       0.866667                 0.866667   \n",
      "42  0.001746    0.006280       0.800000                 0.807143   \n",
      "43  0.003926    0.006144       0.766667                 0.767857   \n",
      "44  0.006424    0.006559       0.700000                 0.708333   \n",
      "45  0.002481    0.006235       0.866667                 0.874405   \n",
      "46  0.001231    0.006725       0.833333                 0.851190   \n",
      "47  0.001159    0.006132       0.900000                 0.902222   \n",
      "48  0.001221    0.006065       0.833333                 0.834821   \n",
      "49  0.001198    0.006039       0.933333                 0.941176   \n",
      "50  0.001704    0.007282       0.833333                 0.834087   \n",
      "51  0.001104    0.006099       0.833333                 0.836310   \n",
      "52  0.001053    0.006409       0.833333                 0.835556   \n",
      "53  0.001009    0.006118       0.800000                 0.805430   \n",
      "54  0.001318    0.008639       0.933333                 0.933333   \n",
      "55  0.002603    0.006564       0.566667                 0.565008   \n",
      "56  0.000994    0.005859       0.833333                 0.843333   \n",
      "57  0.000964    0.006097       0.866667                 0.874405   \n",
      "58  0.001390    0.006416       0.600000                 0.600000   \n",
      "59  0.001407    0.006195       0.633333                 0.638889   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.800000          0.800000      0.861607   SVM-linear-scale-1  \n",
      "1               0.866667          0.866667      0.828054   SVM-linear-scale-1  \n",
      "2               0.800000          0.800000      0.857143   SVM-linear-scale-1  \n",
      "3               0.766667          0.766407      0.768889   SVM-linear-scale-1  \n",
      "4               0.700000          0.696970      0.826667   SVM-linear-scale-1  \n",
      "5               0.900000          0.900111      0.848214     SVM-poly-scale-1  \n",
      "6               0.833333          0.833890      0.841629     SVM-poly-scale-1  \n",
      "7               0.933333          0.933333      0.924107     SVM-poly-scale-1  \n",
      "8               0.866667          0.866667      0.866667     SVM-poly-scale-1  \n",
      "9               0.900000          0.899889      0.977778     SVM-poly-scale-1  \n",
      "10              0.866667          0.866667      0.910714      SVM-rbf-scale-1  \n",
      "11              0.800000          0.800000      0.914027      SVM-rbf-scale-1  \n",
      "12              0.866667          0.866667      0.919643      SVM-rbf-scale-1  \n",
      "13              0.800000          0.799107      0.902222      SVM-rbf-scale-1  \n",
      "14              0.933333          0.933333      0.986667      SVM-rbf-scale-1  \n",
      "15              0.600000          0.596380      0.580357  SVM-sigmoid-scale-1  \n",
      "16              0.433333          0.430182      0.389140  SVM-sigmoid-scale-1  \n",
      "17              0.466667          0.437037      0.366071  SVM-sigmoid-scale-1  \n",
      "18              0.633333          0.632925      0.653333  SVM-sigmoid-scale-1  \n",
      "19              0.633333          0.629630      0.631111  SVM-sigmoid-scale-1  \n",
      "20              0.800000          0.800000      0.861607    SVM-linear-auto-1  \n",
      "21              0.866667          0.866667      0.828054    SVM-linear-auto-1  \n",
      "22              0.800000          0.800000      0.857143    SVM-linear-auto-1  \n",
      "23              0.766667          0.766407      0.768889    SVM-linear-auto-1  \n",
      "24              0.700000          0.696970      0.826667    SVM-linear-auto-1  \n",
      "25              0.866667          0.866667      0.834821      SVM-poly-auto-1  \n",
      "26              0.833333          0.832381      0.841629      SVM-poly-auto-1  \n",
      "27              0.833333          0.833519      0.852679      SVM-poly-auto-1  \n",
      "28              0.700000          0.696970      0.697778      SVM-poly-auto-1  \n",
      "29              0.833333          0.831650      0.875556      SVM-poly-auto-1  \n",
      "30              0.533333          0.371014      0.593750       SVM-rbf-auto-1  \n",
      "31              0.566667          0.409929      0.558824       SVM-rbf-auto-1  \n",
      "32              0.466667          0.296970      0.531250       SVM-rbf-auto-1  \n",
      "33              0.500000          0.333333      0.566667       SVM-rbf-auto-1  \n",
      "34              0.500000          0.333333      0.500000       SVM-rbf-auto-1  \n",
      "35              0.533333          0.371014      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.433333          0.262016      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.466667          0.296970      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.500000          0.333333      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.500000          0.333333      0.500000   SVM-sigmoid-auto-1  \n",
      "40              0.800000          0.800000      0.861607   SVM-linear-scale-2  \n",
      "41              0.866667          0.866667      0.828054   SVM-linear-scale-2  \n",
      "42              0.800000          0.800000      0.857143   SVM-linear-scale-2  \n",
      "43              0.766667          0.766407      0.768889   SVM-linear-scale-2  \n",
      "44              0.700000          0.696970      0.826667   SVM-linear-scale-2  \n",
      "45              0.866667          0.866667      0.852679     SVM-poly-scale-2  \n",
      "46              0.833333          0.833890      0.837104     SVM-poly-scale-2  \n",
      "47              0.900000          0.900111      0.915179     SVM-poly-scale-2  \n",
      "48              0.833333          0.833148      0.880000     SVM-poly-scale-2  \n",
      "49              0.933333          0.933036      0.991111     SVM-poly-scale-2  \n",
      "50              0.833333          0.832772      0.888393      SVM-rbf-scale-2  \n",
      "51              0.833333          0.833895      0.918552      SVM-rbf-scale-2  \n",
      "52              0.833333          0.833519      0.910714      SVM-rbf-scale-2  \n",
      "53              0.800000          0.799107      0.911111      SVM-rbf-scale-2  \n",
      "54              0.933333          0.933333      0.986667      SVM-rbf-scale-2  \n",
      "55              0.566667          0.565208      0.571429  SVM-sigmoid-scale-2  \n",
      "56              0.833333          0.829221      0.778281  SVM-sigmoid-scale-2  \n",
      "57              0.866667          0.866667      0.897321  SVM-sigmoid-scale-2  \n",
      "58              0.600000          0.600000      0.644444  SVM-sigmoid-scale-2  \n",
      "59              0.633333          0.629630      0.617778  SVM-sigmoid-scale-2  \n",
      "SVM-linear-auto-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.77      0.87      0.82        23\n",
      "      benign       0.88      0.78      0.82        27\n",
      "\n",
      "    accuracy                           0.82        50\n",
      "   macro avg       0.82      0.82      0.82        50\n",
      "weighted avg       0.83      0.82      0.82        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.003488    0.007741       0.800000                 0.800000   \n",
      "1   0.003334    0.006048       0.866667                 0.866667   \n",
      "2   0.002480    0.005830       0.800000                 0.807143   \n",
      "3   0.003535    0.006545       0.766667                 0.767857   \n",
      "4   0.006017    0.006110       0.700000                 0.708333   \n",
      "..       ...         ...            ...                      ...   \n",
      "60  0.003976    0.006075       0.800000                 0.800000   \n",
      "61  0.003550    0.006180       0.866667                 0.866667   \n",
      "62  0.001643    0.006056       0.800000                 0.807143   \n",
      "63  0.003682    0.006063       0.766667                 0.767857   \n",
      "64  0.006224    0.006496       0.700000                 0.708333   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               0.800000          0.800000      0.861607  SVM-linear-scale-1  \n",
      "1               0.866667          0.866667      0.828054  SVM-linear-scale-1  \n",
      "2               0.800000          0.800000      0.857143  SVM-linear-scale-1  \n",
      "3               0.766667          0.766407      0.768889  SVM-linear-scale-1  \n",
      "4               0.700000          0.696970      0.826667  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "60              0.800000          0.800000      0.861607   SVM-linear-auto-2  \n",
      "61              0.866667          0.866667      0.828054   SVM-linear-auto-2  \n",
      "62              0.800000          0.800000      0.857143   SVM-linear-auto-2  \n",
      "63              0.766667          0.766407      0.768889   SVM-linear-auto-2  \n",
      "64              0.700000          0.696970      0.826667   SVM-linear-auto-2  \n",
      "\n",
      "[65 rows x 8 columns]\n",
      "SVM-poly-auto-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.77      0.87      0.82        23\n",
      "      benign       0.88      0.78      0.82        27\n",
      "\n",
      "    accuracy                           0.82        50\n",
      "   macro avg       0.82      0.82      0.82        50\n",
      "weighted avg       0.83      0.82      0.82        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.003488    0.007741       0.800000                 0.800000   \n",
      "1   0.003334    0.006048       0.866667                 0.866667   \n",
      "2   0.002480    0.005830       0.800000                 0.807143   \n",
      "3   0.003535    0.006545       0.766667                 0.767857   \n",
      "4   0.006017    0.006110       0.700000                 0.708333   \n",
      "..       ...         ...            ...                      ...   \n",
      "65  0.002083    0.006315       0.866667                 0.874405   \n",
      "66  0.001485    0.006053       0.833333                 0.833333   \n",
      "67  0.001493    0.006425       0.833333                 0.835556   \n",
      "68  0.001207    0.006403       0.700000                 0.708333   \n",
      "69  0.001709    0.006134       0.833333                 0.847222   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               0.800000          0.800000      0.861607  SVM-linear-scale-1  \n",
      "1               0.866667          0.866667      0.828054  SVM-linear-scale-1  \n",
      "2               0.800000          0.800000      0.857143  SVM-linear-scale-1  \n",
      "3               0.766667          0.766407      0.768889  SVM-linear-scale-1  \n",
      "4               0.700000          0.696970      0.826667  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "65              0.866667          0.866667      0.834821     SVM-poly-auto-2  \n",
      "66              0.833333          0.832381      0.841629     SVM-poly-auto-2  \n",
      "67              0.833333          0.833519      0.852679     SVM-poly-auto-2  \n",
      "68              0.700000          0.696970      0.697778     SVM-poly-auto-2  \n",
      "69              0.833333          0.831650      0.875556     SVM-poly-auto-2  \n",
      "\n",
      "[70 rows x 8 columns]\n",
      "SVM-rbf-auto-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.47      1.00      0.64        23\n",
      "      benign       1.00      0.04      0.07        27\n",
      "\n",
      "    accuracy                           0.48        50\n",
      "   macro avg       0.73      0.52      0.36        50\n",
      "weighted avg       0.76      0.48      0.33        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.003488    0.007741       0.800000                 0.800000   \n",
      "1   0.003334    0.006048       0.866667                 0.866667   \n",
      "2   0.002480    0.005830       0.800000                 0.807143   \n",
      "3   0.003535    0.006545       0.766667                 0.767857   \n",
      "4   0.006017    0.006110       0.700000                 0.708333   \n",
      "..       ...         ...            ...                      ...   \n",
      "70  0.002142    0.007591       0.533333                 0.284444   \n",
      "71  0.001396    0.006681       0.566667                 0.321111   \n",
      "72  0.001528    0.007421       0.466667                 0.217778   \n",
      "73  0.001554    0.006700       0.500000                 0.250000   \n",
      "74  0.001594    0.008270       0.500000                 0.250000   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               0.800000          0.800000      0.861607  SVM-linear-scale-1  \n",
      "1               0.866667          0.866667      0.828054  SVM-linear-scale-1  \n",
      "2               0.800000          0.800000      0.857143  SVM-linear-scale-1  \n",
      "3               0.766667          0.766407      0.768889  SVM-linear-scale-1  \n",
      "4               0.700000          0.696970      0.826667  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "70              0.533333          0.371014      0.593750      SVM-rbf-auto-2  \n",
      "71              0.566667          0.409929      0.558824      SVM-rbf-auto-2  \n",
      "72              0.466667          0.296970      0.531250      SVM-rbf-auto-2  \n",
      "73              0.500000          0.333333      0.566667      SVM-rbf-auto-2  \n",
      "74              0.500000          0.333333      0.500000      SVM-rbf-auto-2  \n",
      "\n",
      "[75 rows x 8 columns]\n",
      "SVM-sigmoid-auto-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.46      1.00      0.63        23\n",
      "      benign       0.00      0.00      0.00        27\n",
      "\n",
      "    accuracy                           0.46        50\n",
      "   macro avg       0.23      0.50      0.32        50\n",
      "weighted avg       0.21      0.46      0.29        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.003488    0.007741       0.800000                 0.800000   \n",
      "1   0.003334    0.006048       0.866667                 0.866667   \n",
      "2   0.002480    0.005830       0.800000                 0.807143   \n",
      "3   0.003535    0.006545       0.766667                 0.767857   \n",
      "4   0.006017    0.006110       0.700000                 0.708333   \n",
      "..       ...         ...            ...                      ...   \n",
      "75  0.002301    0.006271       0.533333                 0.284444   \n",
      "76  0.001545    0.006227       0.433333                 0.187778   \n",
      "77  0.001119    0.006244       0.466667                 0.217778   \n",
      "78  0.001231    0.006226       0.500000                 0.250000   \n",
      "79  0.001030    0.006365       0.500000                 0.250000   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               0.800000          0.800000      0.861607  SVM-linear-scale-1  \n",
      "1               0.866667          0.866667      0.828054  SVM-linear-scale-1  \n",
      "2               0.800000          0.800000      0.857143  SVM-linear-scale-1  \n",
      "3               0.766667          0.766407      0.768889  SVM-linear-scale-1  \n",
      "4               0.700000          0.696970      0.826667  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "75              0.533333          0.371014      0.500000  SVM-sigmoid-auto-2  \n",
      "76              0.433333          0.262016      0.500000  SVM-sigmoid-auto-2  \n",
      "77              0.466667          0.296970      0.500000  SVM-sigmoid-auto-2  \n",
      "78              0.500000          0.333333      0.500000  SVM-sigmoid-auto-2  \n",
      "79              0.500000          0.333333      0.500000  SVM-sigmoid-auto-2  \n",
      "\n",
      "[80 rows x 8 columns]\n",
      "13.25071960000787\n"
     ]
    }
   ],
   "source": [
    "## S0: All Combined \n",
    " \n",
    "df_malicious = pd.concat([df1,df2,df3,df4,df5,df6,df7,df32,df33,df34,df35])[:1000]\n",
    " \n",
    "df_benign = pd.concat([df8,df9,df11,df10,df12,df13,df15,df16,df17,df18,df19,df20,df21,df22,df23,df24,df25,df30,df27,df29])[:1000]\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_all_combined_s0 = run_process(df_malicious,df_benign,df_results)\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nectar-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
