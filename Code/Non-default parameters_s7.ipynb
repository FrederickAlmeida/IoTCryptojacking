{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "858a88da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T15:26:53.546085Z",
     "iopub.status.busy": "2025-08-09T15:26:53.545871Z",
     "iopub.status.idle": "2025-08-09T15:27:03.544152Z",
     "shell.execute_reply": "2025-08-09T15:27:03.543664Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tsfresh\n",
    "import os\n",
    "import json\n",
    "import scapy\n",
    "import numpy as np\n",
    "import warnings\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from scapy.all import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") #ignore warnings caused by \n",
    "\n",
    "\n",
    "#################################################################\n",
    "#                                                               #\n",
    "#               malicious csv files import                      #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "\n",
    "df1 = pd.read_csv('../Data/malicious/WebOS_binary.csv') #\n",
    "df2 = pd.read_csv('../Data/malicious/Server_Binary.csv') #\n",
    "df3 = pd.read_csv('../Data/malicious/Raspberry_Webmine_Robust.csv')\n",
    "df4 = pd.read_csv('../Data/malicious/Raspberry_Binary.csv') #\n",
    "df5 = pd.read_csv('../Data/malicious/Raspberry_Webmine_Aggressive.csv')\n",
    "df6 = pd.read_csv('../Data/malicious/Raspberry_WebminePool_Aggressive.csv')\n",
    "df7 = pd.read_csv('../Data/malicious/Server_WebminePool_Aggressive.csv') #\n",
    "df32 = pd.read_csv('../Data/malicious/Server_WebminePool_Robust.csv') #\n",
    "df33 = pd.read_csv('../Data/malicious/Raspberry_WebminePool_Stealthy.csv') #\n",
    "df34 = pd.read_csv('../Data/malicious/Raspberry_WebminePool_Robust.csv') #\n",
    "df35 = pd.read_csv('../Data/malicious/Desktop_WebminePool_Aggressive.csv') #\n",
    "\n",
    "\n",
    "#################################################################\n",
    "#                                                               #\n",
    "#               benign-1 csv files import                         #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "df8 = pd.read_csv('../Data/benign-1/interactive_01.csv') #\n",
    "df9 = pd.read_csv('../Data/benign-1/interactive_02.csv') #\n",
    "df10 = pd.read_csv('../Data/benign-1/interactive_03.csv') #\n",
    "df11 = pd.read_csv('../Data/benign-1/interactive_04.csv') #\n",
    "df12 = pd.read_csv('../Data/benign-1/interactive_05.csv') #\n",
    "df13 = pd.read_csv('../Data/benign-1/interactive_06.csv') #\n",
    "df14 = pd.read_csv('../Data/benign-1/web_1page_01.csv') #\n",
    "df15 = pd.read_csv('../Data/benign-1/web_1page_02.csv') #\n",
    "df16 = pd.read_csv('../Data/benign-1/web_1page_03.csv') #\n",
    "df17 = pd.read_csv('../Data/benign-1/web_1page_04.csv') #\n",
    "df18 = pd.read_csv('../Data/benign-1/web_1page_05.csv') #\n",
    "df19 = pd.read_csv('../Data/benign-1/bulk_xs_04.csv') #\n",
    "df20 = pd.read_csv('../Data/benign-1/bulk_xs_05.csv') #\n",
    "df21 = pd.read_csv('../Data/benign-1/video_180s480p_01.csv') #\n",
    "df22 = pd.read_csv('../Data/benign-1/video_180s480p_02.csv') #\n",
    "df23 = pd.read_csv('../Data/benign-1/video_x1_04.csv') #\n",
    "df24 = pd.read_csv('../Data/benign-1/web_multiple_04.csv') #\n",
    "df25 = pd.read_csv('../Data/benign-1/bulk_xs_01.csv') #\n",
    "df26 = pd.read_csv('../Data/benign-1/bulk_xs_09.csv') #\n",
    "df27 = pd.read_csv('../Data/benign-1/bulk_xs_06.csv') #\n",
    "df28 = pd.read_csv('../Data/benign-1/bulk_xs_03.csv') #\n",
    "df29 = pd.read_csv('../Data/benign-1/web_multiple_03.csv') #\n",
    "df30 = pd.read_csv('../Data/benign-1/web_multiple_05.csv') #\n",
    "df31 = pd.read_csv('../Data/benign-1/web_multiple_06.csv') #\n",
    "\n",
    "df_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7720b262",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T15:27:03.545998Z",
     "iopub.status.busy": "2025-08-09T15:27:03.545879Z",
     "iopub.status.idle": "2025-08-09T15:27:03.552612Z",
     "shell.execute_reply": "2025-08-09T15:27:03.552222Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 -->> 43173\n",
      "df2 -->> 1213354\n",
      "df3 -->> 3621\n",
      "df4 -->> 22111\n",
      "df5 -->> 14156\n",
      "df6 -->> 24476\n",
      "df7 -->> 3106\n",
      "df32 -->> 18460\n",
      "df33 -->> 10285\n",
      "df34 -->> 7708\n",
      "df35 -->> 234892\n",
      "/////////////////////////////////////////////////\n",
      "df8 -->> 4550\n",
      "df9 -->> 3869\n",
      "df10 -->> 5327\n",
      "df11 -->> 4727\n",
      "df12 -->> 4190\n",
      "df13 -->> 3481\n",
      "df14 -->> 38576\n",
      "df15 -->> 5961\n",
      "df16 -->> 1803\n",
      "df17 -->> 7029\n",
      "df18 -->> 1012\n",
      "df19 -->> 96545\n",
      "df20 -->> 108065\n",
      "df21 -->> 25138\n",
      "df22 -->> 91274\n",
      "df23 -->> 23597\n",
      "df24 -->> 59635\n",
      "df25 -->> 625216\n",
      "df26 -->> 266935\n",
      "df27 -->> 453471\n",
      "df28 -->> 654495\n",
      "df29 -->> 6764\n",
      "df30 -->> 25300\n",
      "df31 -->> 3689\n"
     ]
    }
   ],
   "source": [
    "print(\"df1 -->> {}\".format(len(df1)))\n",
    "print(\"df2 -->> {}\".format(len(df2)))\n",
    "print(\"df3 -->> {}\".format(len(df3)))\n",
    "print(\"df4 -->> {}\".format(len(df4)))\n",
    "print(\"df5 -->> {}\".format(len(df5)))\n",
    "print(\"df6 -->> {}\".format(len(df6)))\n",
    "print(\"df7 -->> {}\".format(len(df7)))\n",
    "print(\"df32 -->> {}\".format(len(df32)))\n",
    "print(\"df33 -->> {}\".format(len(df33)))\n",
    "print(\"df34 -->> {}\".format(len(df34)))\n",
    "print(\"df35 -->> {}\".format(len(df35)))\n",
    "print(\"/////////////////////////////////////////////////\")\n",
    "\n",
    "\n",
    "print(\"df8 -->> {}\".format(len(df8)))\n",
    "print(\"df9 -->> {}\".format(len(df9)))\n",
    "print(\"df10 -->> {}\".format(len(df10)))\n",
    "print(\"df11 -->> {}\".format(len(df11)))\n",
    "print(\"df12 -->> {}\".format(len(df12)))\n",
    "print(\"df13 -->> {}\".format(len(df13)))\n",
    "print(\"df14 -->> {}\".format(len(df14)))\n",
    "print(\"df15 -->> {}\".format(len(df15)))\n",
    "print(\"df16 -->> {}\".format(len(df16)))\n",
    "print(\"df17 -->> {}\".format(len(df17)))\n",
    "print(\"df18 -->> {}\".format(len(df18)))\n",
    "print(\"df19 -->> {}\".format(len(df19)))\n",
    "print(\"df20 -->> {}\".format(len(df20)))\n",
    "print(\"df21 -->> {}\".format(len(df21)))\n",
    "print(\"df22 -->> {}\".format(len(df22)))\n",
    "print(\"df23 -->> {}\".format(len(df23)))\n",
    "print(\"df24 -->> {}\".format(len(df24)))\n",
    "print(\"df25 -->> {}\".format(len(df25)))\n",
    "print(\"df26 -->> {}\".format(len(df26)))\n",
    "print(\"df27 -->> {}\".format(len(df27)))\n",
    "print(\"df28 -->> {}\".format(len(df28)))\n",
    "print(\"df29 -->> {}\".format(len(df29)))\n",
    "print(\"df30 -->> {}\".format(len(df30)))\n",
    "print(\"df31 -->> {}\".format(len(df31)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74bb6960",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T15:27:03.554287Z",
     "iopub.status.busy": "2025-08-09T15:27:03.554176Z",
     "iopub.status.idle": "2025-08-09T15:27:03.804490Z",
     "shell.execute_reply": "2025-08-09T15:27:03.803998Z"
    }
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#                                                               #\n",
    "#                     Filtering                                 #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "# For WebOS = 18:56:80:17:d0:ef\n",
    "index_names = df1[((df1['HW_dst'] != '18:56:80:17:d0:ef') & (df1['Hw_src'] != '18:56:80:17:d0:ef'))].index\n",
    "df1.drop(index_names, inplace = True)\n",
    "\n",
    "# Big_Server_Monero_mining_data = a4:bb:6d:ac:e1:fd\n",
    "\n",
    "index_names = df2[((df2['HW_dst'] != 'a4:bb:6d:ac:e1:fd') & (df2['Hw_src'] != 'a4:bb:6d:ac:e1:fd'))].index\n",
    "df2.drop(index_names, inplace = True)\n",
    "\n",
    "# ege_data_rasberry = dc:a6:32:67:66:4b\t\n",
    "\n",
    "index_names = df3[((df3['HW_dst'] != 'dc:a6:32:67:66:4b') & (df3['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df3.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_binary_monero_mining = dc:a6:32:68:35:8a\n",
    "\n",
    "index_names = df4[((df4['HW_dst'] != 'dc:a6:32:68:35:8a') & (df4['Hw_src'] != 'dc:a6:32:68:35:8a'))].index\n",
    "df4.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_network_data_2 = dc:a6:32:67:66:4b\n",
    "\n",
    "index_names = df5[((df5['HW_dst'] != 'dc:a6:32:67:66:4b') & (df5['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df5.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry-Webmine = dc:a6:32:67:66:4b\n",
    "index_names = df6[((df6['HW_dst'] != 'dc:a6:32:67:66:4b') & (df6['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df6.drop(index_names, inplace = True)\n",
    "\n",
    "# Server_Webmine_Network_data = a4:bb:6d:ac:e1:fd\n",
    "\n",
    "index_names = df7[((df7['HW_dst'] != 'a4:bb:6d:ac:e1:fd') & (df7['Hw_src'] != 'a4:bb:6d:ac:e1:fd'))].index\n",
    "df7.drop(index_names, inplace = True)\n",
    "\n",
    "# Server_%50_Mining = a4:bb:6d:ac:e1:fd\n",
    "\n",
    "index_names = df32[((df32['HW_dst'] != 'a4:bb:6d:ac:e1:fd') & (df32['Hw_src'] != 'a4:bb:6d:ac:e1:fd'))].index\n",
    "df32.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_webmine_%10 = dc:a6:32:67:66:4b\n",
    "\n",
    "index_names = df33[((df33['HW_dst'] != 'dc:a6:32:67:66:4b') & (df33['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df33.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_webmine_%50 = dc:a6:32:68:35:8a\n",
    "\n",
    "index_names = df34[((df34['HW_dst'] != 'dc:a6:32:68:35:8a') & (df34['Hw_src'] != 'dc:a6:32:68:35:8a'))].index\n",
    "df34.drop(index_names, inplace = True)\n",
    "\n",
    "# Desktop_Webmine_%100 = dc:a6:32:68:35:8a\n",
    "\n",
    "index_names = df35[((df35['HW_dst'] != 'd8:3b:bf:8f:ba:ba') & (df35['Hw_src'] != 'd8:3b:bf:8f:ba:ba'))].index\n",
    "df35.drop(index_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2909ac24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T15:27:03.806650Z",
     "iopub.status.busy": "2025-08-09T15:27:03.806528Z",
     "iopub.status.idle": "2025-08-09T15:27:03.817604Z",
     "shell.execute_reply": "2025-08-09T15:27:03.817108Z"
    }
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#                                                               #\n",
    "#      Labeling Features for further calculations               #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "df1.insert(7, \"Is_malicious\", 1)\n",
    "df2.insert(7, \"Is_malicious\", 1)\n",
    "df3.insert(7, \"Is_malicious\", 1)\n",
    "df4.insert(7, \"Is_malicious\", 1)\n",
    "df5.insert(7, \"Is_malicious\", 1)\n",
    "df6.insert(7, \"Is_malicious\", 1)\n",
    "df7.insert(7, \"Is_malicious\", 1)\n",
    "\n",
    "# ========================================================\n",
    "\n",
    "df8.insert(7, \"Is_malicious\", 0)\n",
    "df9.insert(7, \"Is_malicious\", 0)\n",
    "df10.insert(7, \"Is_malicious\", 0)\n",
    "df11.insert(7, \"Is_malicious\", 0)\n",
    "df12.insert(7, \"Is_malicious\", 0)\n",
    "df13.insert(7, \"Is_malicious\", 0)\n",
    "df14.insert(7, \"Is_malicious\", 0)\n",
    "df15.insert(7, \"Is_malicious\", 0)\n",
    "df16.insert(7, \"Is_malicious\", 0)\n",
    "df17.insert(7, \"Is_malicious\", 0)\n",
    "df18.insert(7, \"Is_malicious\", 0)\n",
    "df19.insert(7, \"Is_malicious\", 0)\n",
    "df20.insert(7, \"Is_malicious\", 0)\n",
    "df21.insert(7, \"Is_malicious\", 0)\n",
    "df22.insert(7, \"Is_malicious\", 0)\n",
    "df23.insert(7, \"Is_malicious\", 0)\n",
    "df24.insert(7, \"Is_malicious\", 0)\n",
    "\n",
    "\n",
    "# ========================================================\n",
    "\n",
    "df25.insert(7, \"Is_malicious\", 0)\n",
    "df26.insert(7, \"Is_malicious\", 0)\n",
    "df27.insert(7, \"Is_malicious\", 0)\n",
    "df28.insert(7, \"Is_malicious\", 0)\n",
    "df29.insert(7, \"Is_malicious\", 0)\n",
    "df30.insert(7, \"Is_malicious\", 0)\n",
    "df31.insert(7, \"Is_malicious\", 0)\n",
    "\n",
    "df32.insert(7, \"Is_malicious\", 1)\n",
    "df33.insert(7, \"Is_malicious\", 1)\n",
    "df34.insert(7, \"Is_malicious\", 1)\n",
    "df35.insert(7, \"Is_malicious\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a212f52c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T15:27:03.819549Z",
     "iopub.status.busy": "2025-08-09T15:27:03.819430Z",
     "iopub.status.idle": "2025-08-09T15:27:04.393573Z",
     "shell.execute_reply": "2025-08-09T15:27:04.393117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 -->> 41572\n",
      "df2 -->> 1198039\n",
      "df3 -->> 3519\n",
      "df4 -->> 11745\n",
      "df5 -->> 12871\n",
      "df6 -->> 19643\n",
      "df7 -->> 2539\n",
      "df8 -->> 4550\n",
      "df9 -->> 3869\n",
      "df10 -->> 5327\n",
      "df11 -->> 4727\n",
      "df12 -->> 4190\n",
      "df13 -->> 3481\n",
      "df14 -->> 38576\n",
      "df15 -->> 5961\n",
      "df16 -->> 1803\n",
      "df17 -->> 7029\n",
      "df18 -->> 1012\n",
      "df19 -->> 96545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df20 -->> 108065\n",
      "df21 -->> 25138\n",
      "df22 -->> 91274\n",
      "df23 -->> 23597\n",
      "df24 -->> 59619\n",
      "df25 -->> 625194\n",
      "df26 -->> 266935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df27 -->> 453466\n",
      "df28 -->> 654479\n",
      "df29 -->> 6764\n",
      "df30 -->> 25288\n",
      "df31 -->> 3689\n",
      "df32 -->> 16744\n",
      "df33 -->> 9880\n",
      "df34 -->> 6406\n",
      "df35 -->> 234272\n"
     ]
    }
   ],
   "source": [
    "print(\"df1 -->> {}\".format(len(df1.dropna())))\n",
    "print(\"df2 -->> {}\".format(len(df2.dropna())))\n",
    "print(\"df3 -->> {}\".format(len(df3.dropna())))\n",
    "print(\"df4 -->> {}\".format(len(df4.dropna())))\n",
    "print(\"df5 -->> {}\".format(len(df5.dropna())))\n",
    "print(\"df6 -->> {}\".format(len(df6.dropna())))\n",
    "print(\"df7 -->> {}\".format(len(df7.dropna())))\n",
    "print(\"df8 -->> {}\".format(len(df8.dropna())))\n",
    "print(\"df9 -->> {}\".format(len(df9.dropna())))\n",
    "print(\"df10 -->> {}\".format(len(df10.dropna())))\n",
    "print(\"df11 -->> {}\".format(len(df11.dropna())))\n",
    "print(\"df12 -->> {}\".format(len(df12.dropna())))\n",
    "print(\"df13 -->> {}\".format(len(df13.dropna())))\n",
    "print(\"df14 -->> {}\".format(len(df14.dropna())))\n",
    "print(\"df15 -->> {}\".format(len(df15.dropna())))\n",
    "print(\"df16 -->> {}\".format(len(df16.dropna())))\n",
    "print(\"df17 -->> {}\".format(len(df17.dropna())))\n",
    "print(\"df18 -->> {}\".format(len(df18.dropna())))\n",
    "print(\"df19 -->> {}\".format(len(df19.dropna())))\n",
    "print(\"df20 -->> {}\".format(len(df20.dropna())))\n",
    "print(\"df21 -->> {}\".format(len(df21.dropna())))\n",
    "print(\"df22 -->> {}\".format(len(df22.dropna())))\n",
    "print(\"df23 -->> {}\".format(len(df23.dropna())))\n",
    "print(\"df24 -->> {}\".format(len(df24.dropna())))\n",
    "print(\"df25 -->> {}\".format(len(df25.dropna())))\n",
    "print(\"df26 -->> {}\".format(len(df26.dropna())))\n",
    "print(\"df27 -->> {}\".format(len(df27.dropna())))\n",
    "print(\"df28 -->> {}\".format(len(df28.dropna())))\n",
    "print(\"df29 -->> {}\".format(len(df29.dropna())))\n",
    "print(\"df30 -->> {}\".format(len(df30.dropna())))\n",
    "print(\"df31 -->> {}\".format(len(df31.dropna())))\n",
    "print(\"df32 -->> {}\".format(len(df32.dropna())))\n",
    "print(\"df33 -->> {}\".format(len(df33.dropna())))\n",
    "print(\"df34 -->> {}\".format(len(df34.dropna())))\n",
    "print(\"df35 -->> {}\".format(len(df35.dropna())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dffa476a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T15:27:04.395386Z",
     "iopub.status.busy": "2025-08-09T15:27:04.395267Z",
     "iopub.status.idle": "2025-08-09T15:27:04.400110Z",
     "shell.execute_reply": "2025-08-09T15:27:04.399729Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_process(a,b,x):\n",
    "    \n",
    "    df_malicious = a.copy()\n",
    "    df_benign    = b.copy()\n",
    "    \n",
    "    from tsfresh import extract_features, select_features\n",
    "    from tsfresh.utilities.dataframe_functions import impute\n",
    "    from tsfresh import extract_features\n",
    "    from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "\n",
    "\n",
    "    df_malicious.reset_index(drop=True, inplace=True) #reset index\n",
    "    df_malicious['id']= np.floor(df_malicious.index.array/10)\n",
    "    df_benign.reset_index(drop=True, inplace=True) #reset index\n",
    "    df_benign['id']= np.floor(df_benign.index.array/10)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    tf1=tsfresh.extract_features(df_malicious,impute_function=impute, column_kind='Is_malicious',\n",
    "                                 column_id='id',column_sort=\"Time\",column_value = \"Length\")\n",
    "    tf1['class']= 1\n",
    "\n",
    "    \n",
    "    \n",
    "    tf2=tsfresh.extract_features(df_benign,impute_function=impute, column_kind='Is_malicious',\n",
    "                                 column_id='id',column_sort=\"Time\",column_value = \"Length\")\n",
    "    tf2['class']= 0\n",
    "\n",
    "\n",
    "    tf2.columns = tf1.columns\n",
    "\n",
    "    features=pd.concat([tf1,tf2])\n",
    "\n",
    "\n",
    "    features2 = features.copy()\n",
    "    features2.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    y = pd.Series(data = features2['class'], index=features2.index)\n",
    "    \n",
    "    from tsfresh.examples import load_robot_execution_failures\n",
    "    from tsfresh import extract_features, select_features\n",
    "    from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "\n",
    "    relevance_table = calculate_relevance_table(features2, y)\n",
    "    relevance_table = relevance_table[relevance_table.relevant]\n",
    "    relevance_table.sort_values(\"p_value\", inplace=True)\n",
    "\n",
    "    relevance_table\n",
    "    \n",
    "    best_features = relevance_table[relevance_table['p_value'] <= 0.05]\n",
    "\n",
    "    df_ML = pd.DataFrame()\n",
    "\n",
    "    for pkt in best_features:\n",
    "        df_ML[best_features.feature] = features[best_features.feature]\n",
    "\n",
    "    final = ML_Process(df_ML,x)\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc3bddd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T15:27:04.401844Z",
     "iopub.status.busy": "2025-08-09T15:27:04.401734Z",
     "iopub.status.idle": "2025-08-09T15:27:04.408884Z",
     "shell.execute_reply": "2025-08-09T15:27:04.408503Z"
    }
   },
   "outputs": [],
   "source": [
    "def ML_Process(df_ML,x):\n",
    "    df_results = x.copy() \n",
    "    print('let the ml starts')\n",
    "  \n",
    "    from sklearn import neighbors, metrics\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    #X = df_finalized[['Time', 'Length','Protocol']].values\n",
    "    X = df_ML.drop('class',axis=1).to_numpy()\n",
    "    #y = df_finalized[['Is_malicious']]\n",
    "    y = df_ML['class'].to_numpy()\n",
    "\n",
    "\n",
    "    #print(X,y)\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    Le = LabelEncoder()\n",
    "    for i in range(len(X[0])):\n",
    "        X[:, i] = Le.fit_transform(X[:, i])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=8675309)\n",
    "\n",
    "    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    #from xgboost import XGBClassifier\n",
    "    from sklearn import model_selection\n",
    "    from sklearn.utils import class_weight\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    y_train = y_train.ravel()\n",
    "    dfs = []\n",
    "    models = [\n",
    "        ('SVM-linear-scale-1', SVC(C = 1, kernel = 'linear',gamma ='scale')),\n",
    "        ('SVM-poly-scale-1', SVC(C = 1, kernel = 'poly',gamma ='scale')),\n",
    "        ('SVM-rbf-scale-1', SVC(C = 1, kernel = 'rbf',gamma ='scale')),\n",
    "        ('SVM-sigmoid-scale-1', SVC(C = 1, kernel = 'sigmoid',gamma ='scale')),\n",
    "        ('SVM-linear-auto-1', SVC(C = 1, kernel = 'linear',gamma ='auto')),\n",
    "        ('SVM-poly-auto-1', SVC(C = 1, kernel = 'poly',gamma ='auto')),\n",
    "        ('SVM-rbf-auto-1', SVC(C = 1, kernel = 'rbf',gamma ='auto')),\n",
    "        ('SVM-sigmoid-auto-1', SVC(C = 1, kernel = 'sigmoid',gamma ='auto')),\n",
    "        ('SVM-linear-scale-2', SVC(C = 2, kernel = 'linear',gamma ='scale')),\n",
    "        ('SVM-poly-scale-2', SVC(C = 2, kernel = 'poly',gamma ='scale')),\n",
    "        ('SVM-rbf-scale-2', SVC(C = 2, kernel = 'rbf',gamma ='scale')),\n",
    "        ('SVM-sigmoid-scale-2', SVC(C = 2, kernel = 'sigmoid',gamma ='scale')),\n",
    "        ('SVM-linear-auto-2', SVC(C = 2, kernel = 'linear',gamma ='auto')),\n",
    "        ('SVM-poly-auto-2', SVC(C = 2, kernel = 'poly',gamma ='auto')),\n",
    "        ('SVM-rbf-auto-2', SVC(C = 2, kernel = 'rbf',gamma ='auto')),\n",
    "        ('SVM-sigmoid-auto-2', SVC(C = 2, kernel = 'sigmoid',gamma ='auto'))\n",
    "            ]\n",
    "    results = []\n",
    "    names = []\n",
    "    scoring = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted', 'roc_auc']\n",
    "    target_names = ['malignant', 'benign']\n",
    "    for name, model in models:\n",
    "        kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state=90210)\n",
    "        cv_results = model_selection.cross_validate(model, X_train, y_train, cv=kfold, \n",
    "                                                    scoring=scoring)\n",
    "\n",
    "        clf = model.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(name)\n",
    "        print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        this_df = pd.DataFrame(cv_results)\n",
    "        this_df['model'] = name\n",
    "        dfs.append(this_df)\n",
    "        final = pd.concat(dfs, ignore_index=True)\n",
    "        print(final)\n",
    "\n",
    "    return(final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50ce98f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T15:27:04.410581Z",
     "iopub.status.busy": "2025-08-09T15:27:04.410465Z",
     "iopub.status.idle": "2025-08-09T15:35:45.352745Z",
     "shell.execute_reply": "2025-08-09T15:35:45.352226Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 47978\n",
      "benign: 47801\n",
      "0 NAN in malicious!\n",
      "0 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 47978\n",
      "benign: 47801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:   0%|          | 0/160 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:   1%|          | 1/160 [00:02<05:49,  2.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:   4%|▍         | 7/160 [00:02<00:37,  4.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:   9%|▉         | 14/160 [00:02<00:15,  9.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  12%|█▏        | 19/160 [00:02<00:10, 13.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  15%|█▌        | 24/160 [00:02<00:07, 17.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  18%|█▊        | 29/160 [00:02<00:06, 21.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  21%|██▏       | 34/160 [00:04<00:15,  8.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  23%|██▎       | 37/160 [00:04<00:14,  8.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  26%|██▋       | 42/160 [00:04<00:09, 11.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  30%|███       | 48/160 [00:04<00:06, 16.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  33%|███▎      | 53/160 [00:04<00:05, 20.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  36%|███▌      | 57/160 [00:04<00:04, 22.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  39%|███▉      | 63/160 [00:05<00:03, 27.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  42%|████▏     | 67/160 [00:06<00:09,  9.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  44%|████▍     | 70/160 [00:06<00:09,  9.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  46%|████▋     | 74/160 [00:06<00:06, 12.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  49%|████▉     | 79/160 [00:06<00:05, 15.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  52%|█████▏    | 83/160 [00:06<00:04, 18.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  54%|█████▍    | 87/160 [00:07<00:03, 20.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  57%|█████▊    | 92/160 [00:07<00:02, 24.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  60%|██████    | 96/160 [00:07<00:02, 25.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  62%|██████▎   | 100/160 [00:08<00:05, 10.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  64%|██████▍   | 103/160 [00:08<00:05, 10.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  66%|██████▋   | 106/160 [00:08<00:04, 11.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  68%|██████▊   | 109/160 [00:08<00:03, 13.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  70%|███████   | 112/160 [00:09<00:03, 15.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  72%|███████▏  | 115/160 [00:09<00:03, 14.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  74%|███████▍  | 119/160 [00:09<00:02, 17.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  79%|███████▉  | 126/160 [00:09<00:01, 25.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  81%|████████▏ | 130/160 [00:10<00:02, 13.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  83%|████████▎ | 133/160 [00:10<00:01, 13.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  85%|████████▌ | 136/160 [00:10<00:01, 14.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  87%|████████▋ | 139/160 [00:10<00:01, 15.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  89%|████████▉ | 142/160 [00:10<00:01, 14.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  92%|█████████▏| 147/160 [00:11<00:00, 20.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  96%|█████████▌| 153/160 [00:11<00:00, 24.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction: 100%|██████████| 160/160 [00:11<00:00, 31.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction: 100%|██████████| 160/160 [00:11<00:00, 14.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:   0%|          | 0/160 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:   1%|          | 1/160 [00:02<05:43,  2.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:   2%|▏         | 3/160 [00:02<01:34,  1.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:   5%|▌         | 8/160 [00:02<00:27,  5.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:   9%|▉         | 14/160 [00:02<00:13, 10.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  12%|█▏        | 19/160 [00:02<00:09, 15.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  15%|█▌        | 24/160 [00:02<00:06, 19.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  18%|█▊        | 29/160 [00:02<00:05, 22.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  21%|██        | 33/160 [00:04<00:13,  9.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  22%|██▎       | 36/160 [00:04<00:13,  9.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  24%|██▍       | 39/160 [00:04<00:11, 10.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  26%|██▋       | 42/160 [00:04<00:09, 12.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  29%|██▉       | 46/160 [00:04<00:06, 16.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  31%|███       | 49/160 [00:04<00:05, 18.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  35%|███▌      | 56/160 [00:04<00:03, 26.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  38%|███▊      | 60/160 [00:05<00:03, 26.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  40%|████      | 64/160 [00:05<00:03, 28.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  42%|████▎     | 68/160 [00:06<00:10,  8.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  44%|████▍     | 71/160 [00:06<00:09,  9.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  48%|████▊     | 77/160 [00:06<00:06, 13.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  51%|█████     | 81/160 [00:06<00:04, 16.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  53%|█████▎    | 85/160 [00:07<00:03, 19.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  56%|█████▌    | 89/160 [00:07<00:03, 22.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  59%|█████▉    | 94/160 [00:07<00:02, 26.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  61%|██████▏   | 98/160 [00:08<00:05, 11.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  63%|██████▎   | 101/160 [00:08<00:05, 10.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  65%|██████▌   | 104/160 [00:08<00:05, 10.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  68%|██████▊   | 108/160 [00:08<00:03, 14.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  69%|██████▉   | 111/160 [00:09<00:03, 15.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  72%|███████▎  | 116/160 [00:09<00:02, 18.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  76%|███████▌  | 121/160 [00:09<00:01, 24.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  78%|███████▊  | 125/160 [00:09<00:01, 26.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  81%|████████  | 129/160 [00:10<00:02, 11.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  82%|████████▎ | 132/160 [00:10<00:02, 13.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  84%|████████▍ | 135/160 [00:10<00:02, 12.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  86%|████████▋ | 138/160 [00:10<00:01, 12.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  91%|█████████ | 145/160 [00:10<00:00, 20.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  93%|█████████▎| 149/160 [00:11<00:00, 22.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:  98%|█████████▊| 157/160 [00:11<00:00, 32.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction: 100%|██████████| 160/160 [00:11<00:00, 14.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let the ml starts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-linear-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      1.00      1.00      1206\n",
      "      benign       1.00      1.00      1.00      1189\n",
      "\n",
      "    accuracy                           1.00      2395\n",
      "   macro avg       1.00      1.00      1.00      2395\n",
      "weighted avg       1.00      1.00      1.00      2395\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  13.070609    0.024099       0.996521                 0.996521   \n",
      "1   9.711740    0.019658       0.997912                 0.997921   \n",
      "2  14.511508    0.020273       0.997912                 0.997913   \n",
      "3  14.517469    0.020155       0.998608                 0.998608   \n",
      "4  14.464727    0.020044       0.997911                 0.997912   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0              0.996521          0.996520      0.999382  SVM-linear-scale-1  \n",
      "1              0.997912          0.997912      0.999399  SVM-linear-scale-1  \n",
      "2              0.997912          0.997912      0.999663  SVM-linear-scale-1  \n",
      "3              0.998608          0.998608      0.999965  SVM-linear-scale-1  \n",
      "4              0.997911          0.997911      0.999984  SVM-linear-scale-1  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-poly-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.93      0.90      0.92      1206\n",
      "      benign       0.90      0.93      0.92      1189\n",
      "\n",
      "    accuracy                           0.92      2395\n",
      "   macro avg       0.92      0.92      0.92      2395\n",
      "weighted avg       0.92      0.92      0.92      2395\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  13.070609    0.024099       0.996521                 0.996521   \n",
      "1   9.711740    0.019658       0.997912                 0.997921   \n",
      "2  14.511508    0.020273       0.997912                 0.997913   \n",
      "3  14.517469    0.020155       0.998608                 0.998608   \n",
      "4  14.464727    0.020044       0.997911                 0.997912   \n",
      "5   0.529043    0.187621       0.895616                 0.896316   \n",
      "6   0.537017    0.189729       0.905358                 0.905413   \n",
      "7   0.534464    0.189005       0.910926                 0.911788   \n",
      "8   0.526324    0.188620       0.904662                 0.906144   \n",
      "9   0.533755    0.191532       0.908774                 0.909259   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0              0.996521          0.996520      0.999382  SVM-linear-scale-1  \n",
      "1              0.997912          0.997912      0.999399  SVM-linear-scale-1  \n",
      "2              0.997912          0.997912      0.999663  SVM-linear-scale-1  \n",
      "3              0.998608          0.998608      0.999965  SVM-linear-scale-1  \n",
      "4              0.997911          0.997911      0.999984  SVM-linear-scale-1  \n",
      "5              0.895616          0.895626      0.963038    SVM-poly-scale-1  \n",
      "6              0.905358          0.905323      0.966928    SVM-poly-scale-1  \n",
      "7              0.910926          0.910905      0.964612    SVM-poly-scale-1  \n",
      "8              0.904662          0.904591      0.960394    SVM-poly-scale-1  \n",
      "9              0.908774          0.908694      0.964185    SVM-poly-scale-1  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-rbf-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.93      0.90      0.91      1206\n",
      "      benign       0.90      0.93      0.91      1189\n",
      "\n",
      "    accuracy                           0.91      2395\n",
      "   macro avg       0.91      0.91      0.91      2395\n",
      "weighted avg       0.91      0.91      0.91      2395\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   13.070609    0.024099       0.996521                 0.996521   \n",
      "1    9.711740    0.019658       0.997912                 0.997921   \n",
      "2   14.511508    0.020273       0.997912                 0.997913   \n",
      "3   14.517469    0.020155       0.998608                 0.998608   \n",
      "4   14.464727    0.020044       0.997911                 0.997912   \n",
      "5    0.529043    0.187621       0.895616                 0.896316   \n",
      "6    0.537017    0.189729       0.905358                 0.905413   \n",
      "7    0.534464    0.189005       0.910926                 0.911788   \n",
      "8    0.526324    0.188620       0.904662                 0.906144   \n",
      "9    0.533755    0.191532       0.908774                 0.909259   \n",
      "10   0.609767    0.680569       0.889353                 0.889696   \n",
      "11   0.617697    0.662725       0.901183                 0.901181   \n",
      "12   0.614171    0.624558       0.899095                 0.899620   \n",
      "13   0.610335    0.624422       0.897704                 0.899444   \n",
      "14   0.623346    0.637969       0.898329                 0.898680   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               0.996521          0.996520      0.999382  SVM-linear-scale-1  \n",
      "1               0.997912          0.997912      0.999399  SVM-linear-scale-1  \n",
      "2               0.997912          0.997912      0.999663  SVM-linear-scale-1  \n",
      "3               0.998608          0.998608      0.999965  SVM-linear-scale-1  \n",
      "4               0.997911          0.997911      0.999984  SVM-linear-scale-1  \n",
      "5               0.895616          0.895626      0.963038    SVM-poly-scale-1  \n",
      "6               0.905358          0.905323      0.966928    SVM-poly-scale-1  \n",
      "7               0.910926          0.910905      0.964612    SVM-poly-scale-1  \n",
      "8               0.904662          0.904591      0.960394    SVM-poly-scale-1  \n",
      "9               0.908774          0.908694      0.964185    SVM-poly-scale-1  \n",
      "10              0.889353          0.889369      0.961441     SVM-rbf-scale-1  \n",
      "11              0.901183          0.901166      0.963524     SVM-rbf-scale-1  \n",
      "12              0.899095          0.899086      0.960990     SVM-rbf-scale-1  \n",
      "13              0.897704          0.897610      0.959948     SVM-rbf-scale-1  \n",
      "14              0.898329          0.898253      0.965835     SVM-rbf-scale-1  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-sigmoid-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.68      0.68      0.68      1206\n",
      "      benign       0.67      0.67      0.67      1189\n",
      "\n",
      "    accuracy                           0.68      2395\n",
      "   macro avg       0.68      0.68      0.68      2395\n",
      "weighted avg       0.68      0.68      0.68      2395\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   13.070609    0.024099       0.996521                 0.996521   \n",
      "1    9.711740    0.019658       0.997912                 0.997921   \n",
      "2   14.511508    0.020273       0.997912                 0.997913   \n",
      "3   14.517469    0.020155       0.998608                 0.998608   \n",
      "4   14.464727    0.020044       0.997911                 0.997912   \n",
      "5    0.529043    0.187621       0.895616                 0.896316   \n",
      "6    0.537017    0.189729       0.905358                 0.905413   \n",
      "7    0.534464    0.189005       0.910926                 0.911788   \n",
      "8    0.526324    0.188620       0.904662                 0.906144   \n",
      "9    0.533755    0.191532       0.908774                 0.909259   \n",
      "10   0.609767    0.680569       0.889353                 0.889696   \n",
      "11   0.617697    0.662725       0.901183                 0.901181   \n",
      "12   0.614171    0.624558       0.899095                 0.899620   \n",
      "13   0.610335    0.624422       0.897704                 0.899444   \n",
      "14   0.623346    0.637969       0.898329                 0.898680   \n",
      "15   0.820542    0.369597       0.634656                 0.635180   \n",
      "16   0.838500    0.375888       0.660404                 0.660404   \n",
      "17   0.830165    0.374487       0.668754                 0.668754   \n",
      "18   0.835088    0.374505       0.672234                 0.672266   \n",
      "19   0.849976    0.380830       0.679666                 0.680642   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.996521          0.996520      0.999382   SVM-linear-scale-1  \n",
      "1               0.997912          0.997912      0.999399   SVM-linear-scale-1  \n",
      "2               0.997912          0.997912      0.999663   SVM-linear-scale-1  \n",
      "3               0.998608          0.998608      0.999965   SVM-linear-scale-1  \n",
      "4               0.997911          0.997911      0.999984   SVM-linear-scale-1  \n",
      "5               0.895616          0.895626      0.963038     SVM-poly-scale-1  \n",
      "6               0.905358          0.905323      0.966928     SVM-poly-scale-1  \n",
      "7               0.910926          0.910905      0.964612     SVM-poly-scale-1  \n",
      "8               0.904662          0.904591      0.960394     SVM-poly-scale-1  \n",
      "9               0.908774          0.908694      0.964185     SVM-poly-scale-1  \n",
      "10              0.889353          0.889369      0.961441      SVM-rbf-scale-1  \n",
      "11              0.901183          0.901166      0.963524      SVM-rbf-scale-1  \n",
      "12              0.899095          0.899086      0.960990      SVM-rbf-scale-1  \n",
      "13              0.897704          0.897610      0.959948      SVM-rbf-scale-1  \n",
      "14              0.898329          0.898253      0.965835      SVM-rbf-scale-1  \n",
      "15              0.634656          0.634694      0.749618  SVM-sigmoid-scale-1  \n",
      "16              0.660404          0.660404      0.769587  SVM-sigmoid-scale-1  \n",
      "17              0.668754          0.668754      0.766135  SVM-sigmoid-scale-1  \n",
      "18              0.672234          0.672234      0.779114  SVM-sigmoid-scale-1  \n",
      "19              0.679666          0.679678      0.788847  SVM-sigmoid-scale-1  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-linear-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      1.00      1.00      1206\n",
      "      benign       1.00      1.00      1.00      1189\n",
      "\n",
      "    accuracy                           1.00      2395\n",
      "   macro avg       1.00      1.00      1.00      2395\n",
      "weighted avg       1.00      1.00      1.00      2395\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   13.070609    0.024099       0.996521                 0.996521   \n",
      "1    9.711740    0.019658       0.997912                 0.997921   \n",
      "2   14.511508    0.020273       0.997912                 0.997913   \n",
      "3   14.517469    0.020155       0.998608                 0.998608   \n",
      "4   14.464727    0.020044       0.997911                 0.997912   \n",
      "5    0.529043    0.187621       0.895616                 0.896316   \n",
      "6    0.537017    0.189729       0.905358                 0.905413   \n",
      "7    0.534464    0.189005       0.910926                 0.911788   \n",
      "8    0.526324    0.188620       0.904662                 0.906144   \n",
      "9    0.533755    0.191532       0.908774                 0.909259   \n",
      "10   0.609767    0.680569       0.889353                 0.889696   \n",
      "11   0.617697    0.662725       0.901183                 0.901181   \n",
      "12   0.614171    0.624558       0.899095                 0.899620   \n",
      "13   0.610335    0.624422       0.897704                 0.899444   \n",
      "14   0.623346    0.637969       0.898329                 0.898680   \n",
      "15   0.820542    0.369597       0.634656                 0.635180   \n",
      "16   0.838500    0.375888       0.660404                 0.660404   \n",
      "17   0.830165    0.374487       0.668754                 0.668754   \n",
      "18   0.835088    0.374505       0.672234                 0.672266   \n",
      "19   0.849976    0.380830       0.679666                 0.680642   \n",
      "20  12.898104    0.020578       0.996521                 0.996521   \n",
      "21   9.584034    0.019736       0.997912                 0.997921   \n",
      "22  14.347562    0.020744       0.997912                 0.997913   \n",
      "23  14.385022    0.020319       0.998608                 0.998608   \n",
      "24  14.318004    0.020903       0.997911                 0.997912   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.996521          0.996520      0.999382   SVM-linear-scale-1  \n",
      "1               0.997912          0.997912      0.999399   SVM-linear-scale-1  \n",
      "2               0.997912          0.997912      0.999663   SVM-linear-scale-1  \n",
      "3               0.998608          0.998608      0.999965   SVM-linear-scale-1  \n",
      "4               0.997911          0.997911      0.999984   SVM-linear-scale-1  \n",
      "5               0.895616          0.895626      0.963038     SVM-poly-scale-1  \n",
      "6               0.905358          0.905323      0.966928     SVM-poly-scale-1  \n",
      "7               0.910926          0.910905      0.964612     SVM-poly-scale-1  \n",
      "8               0.904662          0.904591      0.960394     SVM-poly-scale-1  \n",
      "9               0.908774          0.908694      0.964185     SVM-poly-scale-1  \n",
      "10              0.889353          0.889369      0.961441      SVM-rbf-scale-1  \n",
      "11              0.901183          0.901166      0.963524      SVM-rbf-scale-1  \n",
      "12              0.899095          0.899086      0.960990      SVM-rbf-scale-1  \n",
      "13              0.897704          0.897610      0.959948      SVM-rbf-scale-1  \n",
      "14              0.898329          0.898253      0.965835      SVM-rbf-scale-1  \n",
      "15              0.634656          0.634694      0.749618  SVM-sigmoid-scale-1  \n",
      "16              0.660404          0.660404      0.769587  SVM-sigmoid-scale-1  \n",
      "17              0.668754          0.668754      0.766135  SVM-sigmoid-scale-1  \n",
      "18              0.672234          0.672234      0.779114  SVM-sigmoid-scale-1  \n",
      "19              0.679666          0.679678      0.788847  SVM-sigmoid-scale-1  \n",
      "20              0.996521          0.996520      0.999382    SVM-linear-auto-1  \n",
      "21              0.997912          0.997912      0.999399    SVM-linear-auto-1  \n",
      "22              0.997912          0.997912      0.999663    SVM-linear-auto-1  \n",
      "23              0.998608          0.998608      0.999965    SVM-linear-auto-1  \n",
      "24              0.997911          0.997911      0.999984    SVM-linear-auto-1  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-poly-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.96      0.96      0.96      1206\n",
      "      benign       0.96      0.96      0.96      1189\n",
      "\n",
      "    accuracy                           0.96      2395\n",
      "   macro avg       0.96      0.96      0.96      2395\n",
      "weighted avg       0.96      0.96      0.96      2395\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   13.070609    0.024099       0.996521                 0.996521   \n",
      "1    9.711740    0.019658       0.997912                 0.997921   \n",
      "2   14.511508    0.020273       0.997912                 0.997913   \n",
      "3   14.517469    0.020155       0.998608                 0.998608   \n",
      "4   14.464727    0.020044       0.997911                 0.997912   \n",
      "5    0.529043    0.187621       0.895616                 0.896316   \n",
      "6    0.537017    0.189729       0.905358                 0.905413   \n",
      "7    0.534464    0.189005       0.910926                 0.911788   \n",
      "8    0.526324    0.188620       0.904662                 0.906144   \n",
      "9    0.533755    0.191532       0.908774                 0.909259   \n",
      "10   0.609767    0.680569       0.889353                 0.889696   \n",
      "11   0.617697    0.662725       0.901183                 0.901181   \n",
      "12   0.614171    0.624558       0.899095                 0.899620   \n",
      "13   0.610335    0.624422       0.897704                 0.899444   \n",
      "14   0.623346    0.637969       0.898329                 0.898680   \n",
      "15   0.820542    0.369597       0.634656                 0.635180   \n",
      "16   0.838500    0.375888       0.660404                 0.660404   \n",
      "17   0.830165    0.374487       0.668754                 0.668754   \n",
      "18   0.835088    0.374505       0.672234                 0.672266   \n",
      "19   0.849976    0.380830       0.679666                 0.680642   \n",
      "20  12.898104    0.020578       0.996521                 0.996521   \n",
      "21   9.584034    0.019736       0.997912                 0.997921   \n",
      "22  14.347562    0.020744       0.997912                 0.997913   \n",
      "23  14.385022    0.020319       0.998608                 0.998608   \n",
      "24  14.318004    0.020903       0.997911                 0.997912   \n",
      "25   1.073252    0.105080       0.951983                 0.952038   \n",
      "26   1.028346    0.102073       0.955463                 0.955471   \n",
      "27   1.023922    0.099164       0.951287                 0.951289   \n",
      "28   1.015513    0.103400       0.950592                 0.950615   \n",
      "29   1.013220    0.100466       0.956825                 0.957022   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.996521          0.996520      0.999382   SVM-linear-scale-1  \n",
      "1               0.997912          0.997912      0.999399   SVM-linear-scale-1  \n",
      "2               0.997912          0.997912      0.999663   SVM-linear-scale-1  \n",
      "3               0.998608          0.998608      0.999965   SVM-linear-scale-1  \n",
      "4               0.997911          0.997911      0.999984   SVM-linear-scale-1  \n",
      "5               0.895616          0.895626      0.963038     SVM-poly-scale-1  \n",
      "6               0.905358          0.905323      0.966928     SVM-poly-scale-1  \n",
      "7               0.910926          0.910905      0.964612     SVM-poly-scale-1  \n",
      "8               0.904662          0.904591      0.960394     SVM-poly-scale-1  \n",
      "9               0.908774          0.908694      0.964185     SVM-poly-scale-1  \n",
      "10              0.889353          0.889369      0.961441      SVM-rbf-scale-1  \n",
      "11              0.901183          0.901166      0.963524      SVM-rbf-scale-1  \n",
      "12              0.899095          0.899086      0.960990      SVM-rbf-scale-1  \n",
      "13              0.897704          0.897610      0.959948      SVM-rbf-scale-1  \n",
      "14              0.898329          0.898253      0.965835      SVM-rbf-scale-1  \n",
      "15              0.634656          0.634694      0.749618  SVM-sigmoid-scale-1  \n",
      "16              0.660404          0.660404      0.769587  SVM-sigmoid-scale-1  \n",
      "17              0.668754          0.668754      0.766135  SVM-sigmoid-scale-1  \n",
      "18              0.672234          0.672234      0.779114  SVM-sigmoid-scale-1  \n",
      "19              0.679666          0.679678      0.788847  SVM-sigmoid-scale-1  \n",
      "20              0.996521          0.996520      0.999382    SVM-linear-auto-1  \n",
      "21              0.997912          0.997912      0.999399    SVM-linear-auto-1  \n",
      "22              0.997912          0.997912      0.999663    SVM-linear-auto-1  \n",
      "23              0.998608          0.998608      0.999965    SVM-linear-auto-1  \n",
      "24              0.997911          0.997911      0.999984    SVM-linear-auto-1  \n",
      "25              0.951983          0.951988      0.986791      SVM-poly-auto-1  \n",
      "26              0.955463          0.955465      0.988034      SVM-poly-auto-1  \n",
      "27              0.951287          0.951287      0.984311      SVM-poly-auto-1  \n",
      "28              0.950592          0.950592      0.984365      SVM-poly-auto-1  \n",
      "29              0.956825          0.956832      0.988102      SVM-poly-auto-1  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-rbf-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      0.41      0.58      1206\n",
      "      benign       0.62      1.00      0.77      1189\n",
      "\n",
      "    accuracy                           0.70      2395\n",
      "   macro avg       0.81      0.70      0.67      2395\n",
      "weighted avg       0.81      0.70      0.67      2395\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   13.070609    0.024099       0.996521                 0.996521   \n",
      "1    9.711740    0.019658       0.997912                 0.997921   \n",
      "2   14.511508    0.020273       0.997912                 0.997913   \n",
      "3   14.517469    0.020155       0.998608                 0.998608   \n",
      "4   14.464727    0.020044       0.997911                 0.997912   \n",
      "5    0.529043    0.187621       0.895616                 0.896316   \n",
      "6    0.537017    0.189729       0.905358                 0.905413   \n",
      "7    0.534464    0.189005       0.910926                 0.911788   \n",
      "8    0.526324    0.188620       0.904662                 0.906144   \n",
      "9    0.533755    0.191532       0.908774                 0.909259   \n",
      "10   0.609767    0.680569       0.889353                 0.889696   \n",
      "11   0.617697    0.662725       0.901183                 0.901181   \n",
      "12   0.614171    0.624558       0.899095                 0.899620   \n",
      "13   0.610335    0.624422       0.897704                 0.899444   \n",
      "14   0.623346    0.637969       0.898329                 0.898680   \n",
      "15   0.820542    0.369597       0.634656                 0.635180   \n",
      "16   0.838500    0.375888       0.660404                 0.660404   \n",
      "17   0.830165    0.374487       0.668754                 0.668754   \n",
      "18   0.835088    0.374505       0.672234                 0.672266   \n",
      "19   0.849976    0.380830       0.679666                 0.680642   \n",
      "20  12.898104    0.020578       0.996521                 0.996521   \n",
      "21   9.584034    0.019736       0.997912                 0.997921   \n",
      "22  14.347562    0.020744       0.997912                 0.997913   \n",
      "23  14.385022    0.020319       0.998608                 0.998608   \n",
      "24  14.318004    0.020903       0.997911                 0.997912   \n",
      "25   1.073252    0.105080       0.951983                 0.952038   \n",
      "26   1.028346    0.102073       0.955463                 0.955471   \n",
      "27   1.023922    0.099164       0.951287                 0.951289   \n",
      "28   1.015513    0.103400       0.950592                 0.950615   \n",
      "29   1.013220    0.100466       0.956825                 0.957022   \n",
      "30   2.218849    1.957116       0.675017                 0.804955   \n",
      "31   2.173508    1.877644       0.700070                 0.809993   \n",
      "32   2.209839    1.943826       0.678497                 0.805233   \n",
      "33   2.204757    1.968885       0.693807                 0.810452   \n",
      "34   2.207199    1.913747       0.708914                 0.814168   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.996521          0.996520      0.999382   SVM-linear-scale-1  \n",
      "1               0.997912          0.997912      0.999399   SVM-linear-scale-1  \n",
      "2               0.997912          0.997912      0.999663   SVM-linear-scale-1  \n",
      "3               0.998608          0.998608      0.999965   SVM-linear-scale-1  \n",
      "4               0.997911          0.997911      0.999984   SVM-linear-scale-1  \n",
      "5               0.895616          0.895626      0.963038     SVM-poly-scale-1  \n",
      "6               0.905358          0.905323      0.966928     SVM-poly-scale-1  \n",
      "7               0.910926          0.910905      0.964612     SVM-poly-scale-1  \n",
      "8               0.904662          0.904591      0.960394     SVM-poly-scale-1  \n",
      "9               0.908774          0.908694      0.964185     SVM-poly-scale-1  \n",
      "10              0.889353          0.889369      0.961441      SVM-rbf-scale-1  \n",
      "11              0.901183          0.901166      0.963524      SVM-rbf-scale-1  \n",
      "12              0.899095          0.899086      0.960990      SVM-rbf-scale-1  \n",
      "13              0.897704          0.897610      0.959948      SVM-rbf-scale-1  \n",
      "14              0.898329          0.898253      0.965835      SVM-rbf-scale-1  \n",
      "15              0.634656          0.634694      0.749618  SVM-sigmoid-scale-1  \n",
      "16              0.660404          0.660404      0.769587  SVM-sigmoid-scale-1  \n",
      "17              0.668754          0.668754      0.766135  SVM-sigmoid-scale-1  \n",
      "18              0.672234          0.672234      0.779114  SVM-sigmoid-scale-1  \n",
      "19              0.679666          0.679678      0.788847  SVM-sigmoid-scale-1  \n",
      "20              0.996521          0.996520      0.999382    SVM-linear-auto-1  \n",
      "21              0.997912          0.997912      0.999399    SVM-linear-auto-1  \n",
      "22              0.997912          0.997912      0.999663    SVM-linear-auto-1  \n",
      "23              0.998608          0.998608      0.999965    SVM-linear-auto-1  \n",
      "24              0.997911          0.997911      0.999984    SVM-linear-auto-1  \n",
      "25              0.951983          0.951988      0.986791      SVM-poly-auto-1  \n",
      "26              0.955463          0.955465      0.988034      SVM-poly-auto-1  \n",
      "27              0.951287          0.951287      0.984311      SVM-poly-auto-1  \n",
      "28              0.950592          0.950592      0.984365      SVM-poly-auto-1  \n",
      "29              0.956825          0.956832      0.988102      SVM-poly-auto-1  \n",
      "30              0.675017          0.640113      0.711763       SVM-rbf-auto-1  \n",
      "31              0.700070          0.665893      0.713997       SVM-rbf-auto-1  \n",
      "32              0.678497          0.643093      0.706106       SVM-rbf-auto-1  \n",
      "33              0.693807          0.662735      0.725510       SVM-rbf-auto-1  \n",
      "34              0.708914          0.678829      0.729960       SVM-rbf-auto-1  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-sigmoid-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.00      0.00      0.00      1206\n",
      "      benign       0.50      1.00      0.66      1189\n",
      "\n",
      "    accuracy                           0.50      2395\n",
      "   macro avg       0.25      0.50      0.33      2395\n",
      "weighted avg       0.25      0.50      0.33      2395\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   13.070609    0.024099       0.996521                 0.996521   \n",
      "1    9.711740    0.019658       0.997912                 0.997921   \n",
      "2   14.511508    0.020273       0.997912                 0.997913   \n",
      "3   14.517469    0.020155       0.998608                 0.998608   \n",
      "4   14.464727    0.020044       0.997911                 0.997912   \n",
      "5    0.529043    0.187621       0.895616                 0.896316   \n",
      "6    0.537017    0.189729       0.905358                 0.905413   \n",
      "7    0.534464    0.189005       0.910926                 0.911788   \n",
      "8    0.526324    0.188620       0.904662                 0.906144   \n",
      "9    0.533755    0.191532       0.908774                 0.909259   \n",
      "10   0.609767    0.680569       0.889353                 0.889696   \n",
      "11   0.617697    0.662725       0.901183                 0.901181   \n",
      "12   0.614171    0.624558       0.899095                 0.899620   \n",
      "13   0.610335    0.624422       0.897704                 0.899444   \n",
      "14   0.623346    0.637969       0.898329                 0.898680   \n",
      "15   0.820542    0.369597       0.634656                 0.635180   \n",
      "16   0.838500    0.375888       0.660404                 0.660404   \n",
      "17   0.830165    0.374487       0.668754                 0.668754   \n",
      "18   0.835088    0.374505       0.672234                 0.672266   \n",
      "19   0.849976    0.380830       0.679666                 0.680642   \n",
      "20  12.898104    0.020578       0.996521                 0.996521   \n",
      "21   9.584034    0.019736       0.997912                 0.997921   \n",
      "22  14.347562    0.020744       0.997912                 0.997913   \n",
      "23  14.385022    0.020319       0.998608                 0.998608   \n",
      "24  14.318004    0.020903       0.997911                 0.997912   \n",
      "25   1.073252    0.105080       0.951983                 0.952038   \n",
      "26   1.028346    0.102073       0.955463                 0.955471   \n",
      "27   1.023922    0.099164       0.951287                 0.951289   \n",
      "28   1.015513    0.103400       0.950592                 0.950615   \n",
      "29   1.013220    0.100466       0.956825                 0.957022   \n",
      "30   2.218849    1.957116       0.675017                 0.804955   \n",
      "31   2.173508    1.877644       0.700070                 0.809993   \n",
      "32   2.209839    1.943826       0.678497                 0.805233   \n",
      "33   2.204757    1.968885       0.693807                 0.810452   \n",
      "34   2.207199    1.913747       0.708914                 0.814168   \n",
      "35   1.787085    0.735081       0.487822                 0.237970   \n",
      "36   1.799464    0.748200       0.481559                 0.231899   \n",
      "37   1.794208    0.737927       0.494085                 0.244120   \n",
      "38   1.802169    0.589145       0.497564                 0.247570   \n",
      "39   1.794830    0.593680       0.486072                 0.236266   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.996521          0.996520      0.999382   SVM-linear-scale-1  \n",
      "1               0.997912          0.997912      0.999399   SVM-linear-scale-1  \n",
      "2               0.997912          0.997912      0.999663   SVM-linear-scale-1  \n",
      "3               0.998608          0.998608      0.999965   SVM-linear-scale-1  \n",
      "4               0.997911          0.997911      0.999984   SVM-linear-scale-1  \n",
      "5               0.895616          0.895626      0.963038     SVM-poly-scale-1  \n",
      "6               0.905358          0.905323      0.966928     SVM-poly-scale-1  \n",
      "7               0.910926          0.910905      0.964612     SVM-poly-scale-1  \n",
      "8               0.904662          0.904591      0.960394     SVM-poly-scale-1  \n",
      "9               0.908774          0.908694      0.964185     SVM-poly-scale-1  \n",
      "10              0.889353          0.889369      0.961441      SVM-rbf-scale-1  \n",
      "11              0.901183          0.901166      0.963524      SVM-rbf-scale-1  \n",
      "12              0.899095          0.899086      0.960990      SVM-rbf-scale-1  \n",
      "13              0.897704          0.897610      0.959948      SVM-rbf-scale-1  \n",
      "14              0.898329          0.898253      0.965835      SVM-rbf-scale-1  \n",
      "15              0.634656          0.634694      0.749618  SVM-sigmoid-scale-1  \n",
      "16              0.660404          0.660404      0.769587  SVM-sigmoid-scale-1  \n",
      "17              0.668754          0.668754      0.766135  SVM-sigmoid-scale-1  \n",
      "18              0.672234          0.672234      0.779114  SVM-sigmoid-scale-1  \n",
      "19              0.679666          0.679678      0.788847  SVM-sigmoid-scale-1  \n",
      "20              0.996521          0.996520      0.999382    SVM-linear-auto-1  \n",
      "21              0.997912          0.997912      0.999399    SVM-linear-auto-1  \n",
      "22              0.997912          0.997912      0.999663    SVM-linear-auto-1  \n",
      "23              0.998608          0.998608      0.999965    SVM-linear-auto-1  \n",
      "24              0.997911          0.997911      0.999984    SVM-linear-auto-1  \n",
      "25              0.951983          0.951988      0.986791      SVM-poly-auto-1  \n",
      "26              0.955463          0.955465      0.988034      SVM-poly-auto-1  \n",
      "27              0.951287          0.951287      0.984311      SVM-poly-auto-1  \n",
      "28              0.950592          0.950592      0.984365      SVM-poly-auto-1  \n",
      "29              0.956825          0.956832      0.988102      SVM-poly-auto-1  \n",
      "30              0.675017          0.640113      0.711763       SVM-rbf-auto-1  \n",
      "31              0.700070          0.665893      0.713997       SVM-rbf-auto-1  \n",
      "32              0.678497          0.643093      0.706106       SVM-rbf-auto-1  \n",
      "33              0.693807          0.662735      0.725510       SVM-rbf-auto-1  \n",
      "34              0.708914          0.678829      0.729960       SVM-rbf-auto-1  \n",
      "35              0.487822          0.319891      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.481559          0.313047      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.494085          0.326782      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.497564          0.330631      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.486072          0.317974      0.500000   SVM-sigmoid-auto-1  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-linear-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      1.00      1.00      1206\n",
      "      benign       1.00      1.00      1.00      1189\n",
      "\n",
      "    accuracy                           1.00      2395\n",
      "   macro avg       1.00      1.00      1.00      2395\n",
      "weighted avg       1.00      1.00      1.00      2395\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   13.070609    0.024099       0.996521                 0.996521   \n",
      "1    9.711740    0.019658       0.997912                 0.997921   \n",
      "2   14.511508    0.020273       0.997912                 0.997913   \n",
      "3   14.517469    0.020155       0.998608                 0.998608   \n",
      "4   14.464727    0.020044       0.997911                 0.997912   \n",
      "5    0.529043    0.187621       0.895616                 0.896316   \n",
      "6    0.537017    0.189729       0.905358                 0.905413   \n",
      "7    0.534464    0.189005       0.910926                 0.911788   \n",
      "8    0.526324    0.188620       0.904662                 0.906144   \n",
      "9    0.533755    0.191532       0.908774                 0.909259   \n",
      "10   0.609767    0.680569       0.889353                 0.889696   \n",
      "11   0.617697    0.662725       0.901183                 0.901181   \n",
      "12   0.614171    0.624558       0.899095                 0.899620   \n",
      "13   0.610335    0.624422       0.897704                 0.899444   \n",
      "14   0.623346    0.637969       0.898329                 0.898680   \n",
      "15   0.820542    0.369597       0.634656                 0.635180   \n",
      "16   0.838500    0.375888       0.660404                 0.660404   \n",
      "17   0.830165    0.374487       0.668754                 0.668754   \n",
      "18   0.835088    0.374505       0.672234                 0.672266   \n",
      "19   0.849976    0.380830       0.679666                 0.680642   \n",
      "20  12.898104    0.020578       0.996521                 0.996521   \n",
      "21   9.584034    0.019736       0.997912                 0.997921   \n",
      "22  14.347562    0.020744       0.997912                 0.997913   \n",
      "23  14.385022    0.020319       0.998608                 0.998608   \n",
      "24  14.318004    0.020903       0.997911                 0.997912   \n",
      "25   1.073252    0.105080       0.951983                 0.952038   \n",
      "26   1.028346    0.102073       0.955463                 0.955471   \n",
      "27   1.023922    0.099164       0.951287                 0.951289   \n",
      "28   1.015513    0.103400       0.950592                 0.950615   \n",
      "29   1.013220    0.100466       0.956825                 0.957022   \n",
      "30   2.218849    1.957116       0.675017                 0.804955   \n",
      "31   2.173508    1.877644       0.700070                 0.809993   \n",
      "32   2.209839    1.943826       0.678497                 0.805233   \n",
      "33   2.204757    1.968885       0.693807                 0.810452   \n",
      "34   2.207199    1.913747       0.708914                 0.814168   \n",
      "35   1.787085    0.735081       0.487822                 0.237970   \n",
      "36   1.799464    0.748200       0.481559                 0.231899   \n",
      "37   1.794208    0.737927       0.494085                 0.244120   \n",
      "38   1.802169    0.589145       0.497564                 0.247570   \n",
      "39   1.794830    0.593680       0.486072                 0.236266   \n",
      "40  12.909968    0.020766       0.996521                 0.996521   \n",
      "41   9.583655    0.019883       0.997912                 0.997921   \n",
      "42  14.379267    0.020542       0.997912                 0.997913   \n",
      "43  14.366107    0.020505       0.998608                 0.998608   \n",
      "44  14.315476    0.020669       0.997911                 0.997912   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.996521          0.996520      0.999382   SVM-linear-scale-1  \n",
      "1               0.997912          0.997912      0.999399   SVM-linear-scale-1  \n",
      "2               0.997912          0.997912      0.999663   SVM-linear-scale-1  \n",
      "3               0.998608          0.998608      0.999965   SVM-linear-scale-1  \n",
      "4               0.997911          0.997911      0.999984   SVM-linear-scale-1  \n",
      "5               0.895616          0.895626      0.963038     SVM-poly-scale-1  \n",
      "6               0.905358          0.905323      0.966928     SVM-poly-scale-1  \n",
      "7               0.910926          0.910905      0.964612     SVM-poly-scale-1  \n",
      "8               0.904662          0.904591      0.960394     SVM-poly-scale-1  \n",
      "9               0.908774          0.908694      0.964185     SVM-poly-scale-1  \n",
      "10              0.889353          0.889369      0.961441      SVM-rbf-scale-1  \n",
      "11              0.901183          0.901166      0.963524      SVM-rbf-scale-1  \n",
      "12              0.899095          0.899086      0.960990      SVM-rbf-scale-1  \n",
      "13              0.897704          0.897610      0.959948      SVM-rbf-scale-1  \n",
      "14              0.898329          0.898253      0.965835      SVM-rbf-scale-1  \n",
      "15              0.634656          0.634694      0.749618  SVM-sigmoid-scale-1  \n",
      "16              0.660404          0.660404      0.769587  SVM-sigmoid-scale-1  \n",
      "17              0.668754          0.668754      0.766135  SVM-sigmoid-scale-1  \n",
      "18              0.672234          0.672234      0.779114  SVM-sigmoid-scale-1  \n",
      "19              0.679666          0.679678      0.788847  SVM-sigmoid-scale-1  \n",
      "20              0.996521          0.996520      0.999382    SVM-linear-auto-1  \n",
      "21              0.997912          0.997912      0.999399    SVM-linear-auto-1  \n",
      "22              0.997912          0.997912      0.999663    SVM-linear-auto-1  \n",
      "23              0.998608          0.998608      0.999965    SVM-linear-auto-1  \n",
      "24              0.997911          0.997911      0.999984    SVM-linear-auto-1  \n",
      "25              0.951983          0.951988      0.986791      SVM-poly-auto-1  \n",
      "26              0.955463          0.955465      0.988034      SVM-poly-auto-1  \n",
      "27              0.951287          0.951287      0.984311      SVM-poly-auto-1  \n",
      "28              0.950592          0.950592      0.984365      SVM-poly-auto-1  \n",
      "29              0.956825          0.956832      0.988102      SVM-poly-auto-1  \n",
      "30              0.675017          0.640113      0.711763       SVM-rbf-auto-1  \n",
      "31              0.700070          0.665893      0.713997       SVM-rbf-auto-1  \n",
      "32              0.678497          0.643093      0.706106       SVM-rbf-auto-1  \n",
      "33              0.693807          0.662735      0.725510       SVM-rbf-auto-1  \n",
      "34              0.708914          0.678829      0.729960       SVM-rbf-auto-1  \n",
      "35              0.487822          0.319891      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.481559          0.313047      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.494085          0.326782      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.497564          0.330631      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.486072          0.317974      0.500000   SVM-sigmoid-auto-1  \n",
      "40              0.996521          0.996520      0.999382   SVM-linear-scale-2  \n",
      "41              0.997912          0.997912      0.999399   SVM-linear-scale-2  \n",
      "42              0.997912          0.997912      0.999663   SVM-linear-scale-2  \n",
      "43              0.998608          0.998608      0.999965   SVM-linear-scale-2  \n",
      "44              0.997911          0.997911      0.999984   SVM-linear-scale-2  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-poly-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.94      0.91      0.93      1206\n",
      "      benign       0.91      0.95      0.93      1189\n",
      "\n",
      "    accuracy                           0.93      2395\n",
      "   macro avg       0.93      0.93      0.93      2395\n",
      "weighted avg       0.93      0.93      0.93      2395\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   13.070609    0.024099       0.996521                 0.996521   \n",
      "1    9.711740    0.019658       0.997912                 0.997921   \n",
      "2   14.511508    0.020273       0.997912                 0.997913   \n",
      "3   14.517469    0.020155       0.998608                 0.998608   \n",
      "4   14.464727    0.020044       0.997911                 0.997912   \n",
      "5    0.529043    0.187621       0.895616                 0.896316   \n",
      "6    0.537017    0.189729       0.905358                 0.905413   \n",
      "7    0.534464    0.189005       0.910926                 0.911788   \n",
      "8    0.526324    0.188620       0.904662                 0.906144   \n",
      "9    0.533755    0.191532       0.908774                 0.909259   \n",
      "10   0.609767    0.680569       0.889353                 0.889696   \n",
      "11   0.617697    0.662725       0.901183                 0.901181   \n",
      "12   0.614171    0.624558       0.899095                 0.899620   \n",
      "13   0.610335    0.624422       0.897704                 0.899444   \n",
      "14   0.623346    0.637969       0.898329                 0.898680   \n",
      "15   0.820542    0.369597       0.634656                 0.635180   \n",
      "16   0.838500    0.375888       0.660404                 0.660404   \n",
      "17   0.830165    0.374487       0.668754                 0.668754   \n",
      "18   0.835088    0.374505       0.672234                 0.672266   \n",
      "19   0.849976    0.380830       0.679666                 0.680642   \n",
      "20  12.898104    0.020578       0.996521                 0.996521   \n",
      "21   9.584034    0.019736       0.997912                 0.997921   \n",
      "22  14.347562    0.020744       0.997912                 0.997913   \n",
      "23  14.385022    0.020319       0.998608                 0.998608   \n",
      "24  14.318004    0.020903       0.997911                 0.997912   \n",
      "25   1.073252    0.105080       0.951983                 0.952038   \n",
      "26   1.028346    0.102073       0.955463                 0.955471   \n",
      "27   1.023922    0.099164       0.951287                 0.951289   \n",
      "28   1.015513    0.103400       0.950592                 0.950615   \n",
      "29   1.013220    0.100466       0.956825                 0.957022   \n",
      "30   2.218849    1.957116       0.675017                 0.804955   \n",
      "31   2.173508    1.877644       0.700070                 0.809993   \n",
      "32   2.209839    1.943826       0.678497                 0.805233   \n",
      "33   2.204757    1.968885       0.693807                 0.810452   \n",
      "34   2.207199    1.913747       0.708914                 0.814168   \n",
      "35   1.787085    0.735081       0.487822                 0.237970   \n",
      "36   1.799464    0.748200       0.481559                 0.231899   \n",
      "37   1.794208    0.737927       0.494085                 0.244120   \n",
      "38   1.802169    0.589145       0.497564                 0.247570   \n",
      "39   1.794830    0.593680       0.486072                 0.236266   \n",
      "40  12.909968    0.020766       0.996521                 0.996521   \n",
      "41   9.583655    0.019883       0.997912                 0.997921   \n",
      "42  14.379267    0.020542       0.997912                 0.997913   \n",
      "43  14.366107    0.020505       0.998608                 0.998608   \n",
      "44  14.315476    0.020669       0.997911                 0.997912   \n",
      "45   0.516047    0.177921       0.908838                 0.909803   \n",
      "46   0.527778    0.180408       0.915797                 0.915877   \n",
      "47   0.528493    0.181401       0.917189                 0.917728   \n",
      "48   0.511628    0.177653       0.917884                 0.919205   \n",
      "49   0.527612    0.181893       0.912256                 0.912637   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.996521          0.996520      0.999382   SVM-linear-scale-1  \n",
      "1               0.997912          0.997912      0.999399   SVM-linear-scale-1  \n",
      "2               0.997912          0.997912      0.999663   SVM-linear-scale-1  \n",
      "3               0.998608          0.998608      0.999965   SVM-linear-scale-1  \n",
      "4               0.997911          0.997911      0.999984   SVM-linear-scale-1  \n",
      "5               0.895616          0.895626      0.963038     SVM-poly-scale-1  \n",
      "6               0.905358          0.905323      0.966928     SVM-poly-scale-1  \n",
      "7               0.910926          0.910905      0.964612     SVM-poly-scale-1  \n",
      "8               0.904662          0.904591      0.960394     SVM-poly-scale-1  \n",
      "9               0.908774          0.908694      0.964185     SVM-poly-scale-1  \n",
      "10              0.889353          0.889369      0.961441      SVM-rbf-scale-1  \n",
      "11              0.901183          0.901166      0.963524      SVM-rbf-scale-1  \n",
      "12              0.899095          0.899086      0.960990      SVM-rbf-scale-1  \n",
      "13              0.897704          0.897610      0.959948      SVM-rbf-scale-1  \n",
      "14              0.898329          0.898253      0.965835      SVM-rbf-scale-1  \n",
      "15              0.634656          0.634694      0.749618  SVM-sigmoid-scale-1  \n",
      "16              0.660404          0.660404      0.769587  SVM-sigmoid-scale-1  \n",
      "17              0.668754          0.668754      0.766135  SVM-sigmoid-scale-1  \n",
      "18              0.672234          0.672234      0.779114  SVM-sigmoid-scale-1  \n",
      "19              0.679666          0.679678      0.788847  SVM-sigmoid-scale-1  \n",
      "20              0.996521          0.996520      0.999382    SVM-linear-auto-1  \n",
      "21              0.997912          0.997912      0.999399    SVM-linear-auto-1  \n",
      "22              0.997912          0.997912      0.999663    SVM-linear-auto-1  \n",
      "23              0.998608          0.998608      0.999965    SVM-linear-auto-1  \n",
      "24              0.997911          0.997911      0.999984    SVM-linear-auto-1  \n",
      "25              0.951983          0.951988      0.986791      SVM-poly-auto-1  \n",
      "26              0.955463          0.955465      0.988034      SVM-poly-auto-1  \n",
      "27              0.951287          0.951287      0.984311      SVM-poly-auto-1  \n",
      "28              0.950592          0.950592      0.984365      SVM-poly-auto-1  \n",
      "29              0.956825          0.956832      0.988102      SVM-poly-auto-1  \n",
      "30              0.675017          0.640113      0.711763       SVM-rbf-auto-1  \n",
      "31              0.700070          0.665893      0.713997       SVM-rbf-auto-1  \n",
      "32              0.678497          0.643093      0.706106       SVM-rbf-auto-1  \n",
      "33              0.693807          0.662735      0.725510       SVM-rbf-auto-1  \n",
      "34              0.708914          0.678829      0.729960       SVM-rbf-auto-1  \n",
      "35              0.487822          0.319891      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.481559          0.313047      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.494085          0.326782      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.497564          0.330631      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.486072          0.317974      0.500000   SVM-sigmoid-auto-1  \n",
      "40              0.996521          0.996520      0.999382   SVM-linear-scale-2  \n",
      "41              0.997912          0.997912      0.999399   SVM-linear-scale-2  \n",
      "42              0.997912          0.997912      0.999663   SVM-linear-scale-2  \n",
      "43              0.998608          0.998608      0.999965   SVM-linear-scale-2  \n",
      "44              0.997911          0.997911      0.999984   SVM-linear-scale-2  \n",
      "45              0.908838          0.908841      0.971774     SVM-poly-scale-2  \n",
      "46              0.915797          0.915762      0.973422     SVM-poly-scale-2  \n",
      "47              0.917189          0.917181      0.970025     SVM-poly-scale-2  \n",
      "48              0.917884          0.917832      0.967294     SVM-poly-scale-2  \n",
      "49              0.912256          0.912191      0.969875     SVM-poly-scale-2  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-rbf-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.94      0.90      0.92      1206\n",
      "      benign       0.90      0.94      0.92      1189\n",
      "\n",
      "    accuracy                           0.92      2395\n",
      "   macro avg       0.92      0.92      0.92      2395\n",
      "weighted avg       0.92      0.92      0.92      2395\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   13.070609    0.024099       0.996521                 0.996521   \n",
      "1    9.711740    0.019658       0.997912                 0.997921   \n",
      "2   14.511508    0.020273       0.997912                 0.997913   \n",
      "3   14.517469    0.020155       0.998608                 0.998608   \n",
      "4   14.464727    0.020044       0.997911                 0.997912   \n",
      "5    0.529043    0.187621       0.895616                 0.896316   \n",
      "6    0.537017    0.189729       0.905358                 0.905413   \n",
      "7    0.534464    0.189005       0.910926                 0.911788   \n",
      "8    0.526324    0.188620       0.904662                 0.906144   \n",
      "9    0.533755    0.191532       0.908774                 0.909259   \n",
      "10   0.609767    0.680569       0.889353                 0.889696   \n",
      "11   0.617697    0.662725       0.901183                 0.901181   \n",
      "12   0.614171    0.624558       0.899095                 0.899620   \n",
      "13   0.610335    0.624422       0.897704                 0.899444   \n",
      "14   0.623346    0.637969       0.898329                 0.898680   \n",
      "15   0.820542    0.369597       0.634656                 0.635180   \n",
      "16   0.838500    0.375888       0.660404                 0.660404   \n",
      "17   0.830165    0.374487       0.668754                 0.668754   \n",
      "18   0.835088    0.374505       0.672234                 0.672266   \n",
      "19   0.849976    0.380830       0.679666                 0.680642   \n",
      "20  12.898104    0.020578       0.996521                 0.996521   \n",
      "21   9.584034    0.019736       0.997912                 0.997921   \n",
      "22  14.347562    0.020744       0.997912                 0.997913   \n",
      "23  14.385022    0.020319       0.998608                 0.998608   \n",
      "24  14.318004    0.020903       0.997911                 0.997912   \n",
      "25   1.073252    0.105080       0.951983                 0.952038   \n",
      "26   1.028346    0.102073       0.955463                 0.955471   \n",
      "27   1.023922    0.099164       0.951287                 0.951289   \n",
      "28   1.015513    0.103400       0.950592                 0.950615   \n",
      "29   1.013220    0.100466       0.956825                 0.957022   \n",
      "30   2.218849    1.957116       0.675017                 0.804955   \n",
      "31   2.173508    1.877644       0.700070                 0.809993   \n",
      "32   2.209839    1.943826       0.678497                 0.805233   \n",
      "33   2.204757    1.968885       0.693807                 0.810452   \n",
      "34   2.207199    1.913747       0.708914                 0.814168   \n",
      "35   1.787085    0.735081       0.487822                 0.237970   \n",
      "36   1.799464    0.748200       0.481559                 0.231899   \n",
      "37   1.794208    0.737927       0.494085                 0.244120   \n",
      "38   1.802169    0.589145       0.497564                 0.247570   \n",
      "39   1.794830    0.593680       0.486072                 0.236266   \n",
      "40  12.909968    0.020766       0.996521                 0.996521   \n",
      "41   9.583655    0.019883       0.997912                 0.997921   \n",
      "42  14.379267    0.020542       0.997912                 0.997913   \n",
      "43  14.366107    0.020505       0.998608                 0.998608   \n",
      "44  14.315476    0.020669       0.997911                 0.997912   \n",
      "45   0.516047    0.177921       0.908838                 0.909803   \n",
      "46   0.527778    0.180408       0.915797                 0.915877   \n",
      "47   0.528493    0.181401       0.917189                 0.917728   \n",
      "48   0.511628    0.177653       0.917884                 0.919205   \n",
      "49   0.527612    0.181893       0.912256                 0.912637   \n",
      "50   0.583889    0.585503       0.903967                 0.904345   \n",
      "51   0.590897    0.606785       0.910230                 0.910382   \n",
      "52   0.582302    0.598125       0.915101                 0.916195   \n",
      "53   0.584170    0.583513       0.910230                 0.911226   \n",
      "54   0.593927    0.593113       0.911560                 0.911733   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.996521          0.996520      0.999382   SVM-linear-scale-1  \n",
      "1               0.997912          0.997912      0.999399   SVM-linear-scale-1  \n",
      "2               0.997912          0.997912      0.999663   SVM-linear-scale-1  \n",
      "3               0.998608          0.998608      0.999965   SVM-linear-scale-1  \n",
      "4               0.997911          0.997911      0.999984   SVM-linear-scale-1  \n",
      "5               0.895616          0.895626      0.963038     SVM-poly-scale-1  \n",
      "6               0.905358          0.905323      0.966928     SVM-poly-scale-1  \n",
      "7               0.910926          0.910905      0.964612     SVM-poly-scale-1  \n",
      "8               0.904662          0.904591      0.960394     SVM-poly-scale-1  \n",
      "9               0.908774          0.908694      0.964185     SVM-poly-scale-1  \n",
      "10              0.889353          0.889369      0.961441      SVM-rbf-scale-1  \n",
      "11              0.901183          0.901166      0.963524      SVM-rbf-scale-1  \n",
      "12              0.899095          0.899086      0.960990      SVM-rbf-scale-1  \n",
      "13              0.897704          0.897610      0.959948      SVM-rbf-scale-1  \n",
      "14              0.898329          0.898253      0.965835      SVM-rbf-scale-1  \n",
      "15              0.634656          0.634694      0.749618  SVM-sigmoid-scale-1  \n",
      "16              0.660404          0.660404      0.769587  SVM-sigmoid-scale-1  \n",
      "17              0.668754          0.668754      0.766135  SVM-sigmoid-scale-1  \n",
      "18              0.672234          0.672234      0.779114  SVM-sigmoid-scale-1  \n",
      "19              0.679666          0.679678      0.788847  SVM-sigmoid-scale-1  \n",
      "20              0.996521          0.996520      0.999382    SVM-linear-auto-1  \n",
      "21              0.997912          0.997912      0.999399    SVM-linear-auto-1  \n",
      "22              0.997912          0.997912      0.999663    SVM-linear-auto-1  \n",
      "23              0.998608          0.998608      0.999965    SVM-linear-auto-1  \n",
      "24              0.997911          0.997911      0.999984    SVM-linear-auto-1  \n",
      "25              0.951983          0.951988      0.986791      SVM-poly-auto-1  \n",
      "26              0.955463          0.955465      0.988034      SVM-poly-auto-1  \n",
      "27              0.951287          0.951287      0.984311      SVM-poly-auto-1  \n",
      "28              0.950592          0.950592      0.984365      SVM-poly-auto-1  \n",
      "29              0.956825          0.956832      0.988102      SVM-poly-auto-1  \n",
      "30              0.675017          0.640113      0.711763       SVM-rbf-auto-1  \n",
      "31              0.700070          0.665893      0.713997       SVM-rbf-auto-1  \n",
      "32              0.678497          0.643093      0.706106       SVM-rbf-auto-1  \n",
      "33              0.693807          0.662735      0.725510       SVM-rbf-auto-1  \n",
      "34              0.708914          0.678829      0.729960       SVM-rbf-auto-1  \n",
      "35              0.487822          0.319891      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.481559          0.313047      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.494085          0.326782      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.497564          0.330631      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.486072          0.317974      0.500000   SVM-sigmoid-auto-1  \n",
      "40              0.996521          0.996520      0.999382   SVM-linear-scale-2  \n",
      "41              0.997912          0.997912      0.999399   SVM-linear-scale-2  \n",
      "42              0.997912          0.997912      0.999663   SVM-linear-scale-2  \n",
      "43              0.998608          0.998608      0.999965   SVM-linear-scale-2  \n",
      "44              0.997911          0.997911      0.999984   SVM-linear-scale-2  \n",
      "45              0.908838          0.908841      0.971774     SVM-poly-scale-2  \n",
      "46              0.915797          0.915762      0.973422     SVM-poly-scale-2  \n",
      "47              0.917189          0.917181      0.970025     SVM-poly-scale-2  \n",
      "48              0.917884          0.917832      0.967294     SVM-poly-scale-2  \n",
      "49              0.912256          0.912191      0.969875     SVM-poly-scale-2  \n",
      "50              0.903967          0.903981      0.969428      SVM-rbf-scale-2  \n",
      "51              0.910230          0.910178      0.970309      SVM-rbf-scale-2  \n",
      "52              0.915101          0.915073      0.967447      SVM-rbf-scale-2  \n",
      "53              0.910230          0.910187      0.966984      SVM-rbf-scale-2  \n",
      "54              0.911560          0.911518      0.971318      SVM-rbf-scale-2  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-sigmoid-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.68      0.67      0.68      1206\n",
      "      benign       0.67      0.67      0.67      1189\n",
      "\n",
      "    accuracy                           0.67      2395\n",
      "   macro avg       0.67      0.67      0.67      2395\n",
      "weighted avg       0.67      0.67      0.67      2395\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   13.070609    0.024099       0.996521                 0.996521   \n",
      "1    9.711740    0.019658       0.997912                 0.997921   \n",
      "2   14.511508    0.020273       0.997912                 0.997913   \n",
      "3   14.517469    0.020155       0.998608                 0.998608   \n",
      "4   14.464727    0.020044       0.997911                 0.997912   \n",
      "5    0.529043    0.187621       0.895616                 0.896316   \n",
      "6    0.537017    0.189729       0.905358                 0.905413   \n",
      "7    0.534464    0.189005       0.910926                 0.911788   \n",
      "8    0.526324    0.188620       0.904662                 0.906144   \n",
      "9    0.533755    0.191532       0.908774                 0.909259   \n",
      "10   0.609767    0.680569       0.889353                 0.889696   \n",
      "11   0.617697    0.662725       0.901183                 0.901181   \n",
      "12   0.614171    0.624558       0.899095                 0.899620   \n",
      "13   0.610335    0.624422       0.897704                 0.899444   \n",
      "14   0.623346    0.637969       0.898329                 0.898680   \n",
      "15   0.820542    0.369597       0.634656                 0.635180   \n",
      "16   0.838500    0.375888       0.660404                 0.660404   \n",
      "17   0.830165    0.374487       0.668754                 0.668754   \n",
      "18   0.835088    0.374505       0.672234                 0.672266   \n",
      "19   0.849976    0.380830       0.679666                 0.680642   \n",
      "20  12.898104    0.020578       0.996521                 0.996521   \n",
      "21   9.584034    0.019736       0.997912                 0.997921   \n",
      "22  14.347562    0.020744       0.997912                 0.997913   \n",
      "23  14.385022    0.020319       0.998608                 0.998608   \n",
      "24  14.318004    0.020903       0.997911                 0.997912   \n",
      "25   1.073252    0.105080       0.951983                 0.952038   \n",
      "26   1.028346    0.102073       0.955463                 0.955471   \n",
      "27   1.023922    0.099164       0.951287                 0.951289   \n",
      "28   1.015513    0.103400       0.950592                 0.950615   \n",
      "29   1.013220    0.100466       0.956825                 0.957022   \n",
      "30   2.218849    1.957116       0.675017                 0.804955   \n",
      "31   2.173508    1.877644       0.700070                 0.809993   \n",
      "32   2.209839    1.943826       0.678497                 0.805233   \n",
      "33   2.204757    1.968885       0.693807                 0.810452   \n",
      "34   2.207199    1.913747       0.708914                 0.814168   \n",
      "35   1.787085    0.735081       0.487822                 0.237970   \n",
      "36   1.799464    0.748200       0.481559                 0.231899   \n",
      "37   1.794208    0.737927       0.494085                 0.244120   \n",
      "38   1.802169    0.589145       0.497564                 0.247570   \n",
      "39   1.794830    0.593680       0.486072                 0.236266   \n",
      "40  12.909968    0.020766       0.996521                 0.996521   \n",
      "41   9.583655    0.019883       0.997912                 0.997921   \n",
      "42  14.379267    0.020542       0.997912                 0.997913   \n",
      "43  14.366107    0.020505       0.998608                 0.998608   \n",
      "44  14.315476    0.020669       0.997911                 0.997912   \n",
      "45   0.516047    0.177921       0.908838                 0.909803   \n",
      "46   0.527778    0.180408       0.915797                 0.915877   \n",
      "47   0.528493    0.181401       0.917189                 0.917728   \n",
      "48   0.511628    0.177653       0.917884                 0.919205   \n",
      "49   0.527612    0.181893       0.912256                 0.912637   \n",
      "50   0.583889    0.585503       0.903967                 0.904345   \n",
      "51   0.590897    0.606785       0.910230                 0.910382   \n",
      "52   0.582302    0.598125       0.915101                 0.916195   \n",
      "53   0.584170    0.583513       0.910230                 0.911226   \n",
      "54   0.593927    0.593113       0.911560                 0.911733   \n",
      "55   0.804452    0.364494       0.634656                 0.635290   \n",
      "56   0.823542    0.370371       0.654836                 0.654836   \n",
      "57   0.813472    0.368717       0.663187                 0.663165   \n",
      "58   0.823174    0.370412       0.667363                 0.667436   \n",
      "59   0.835232    0.374997       0.674095                 0.675063   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.996521          0.996520      0.999382   SVM-linear-scale-1  \n",
      "1               0.997912          0.997912      0.999399   SVM-linear-scale-1  \n",
      "2               0.997912          0.997912      0.999663   SVM-linear-scale-1  \n",
      "3               0.998608          0.998608      0.999965   SVM-linear-scale-1  \n",
      "4               0.997911          0.997911      0.999984   SVM-linear-scale-1  \n",
      "5               0.895616          0.895626      0.963038     SVM-poly-scale-1  \n",
      "6               0.905358          0.905323      0.966928     SVM-poly-scale-1  \n",
      "7               0.910926          0.910905      0.964612     SVM-poly-scale-1  \n",
      "8               0.904662          0.904591      0.960394     SVM-poly-scale-1  \n",
      "9               0.908774          0.908694      0.964185     SVM-poly-scale-1  \n",
      "10              0.889353          0.889369      0.961441      SVM-rbf-scale-1  \n",
      "11              0.901183          0.901166      0.963524      SVM-rbf-scale-1  \n",
      "12              0.899095          0.899086      0.960990      SVM-rbf-scale-1  \n",
      "13              0.897704          0.897610      0.959948      SVM-rbf-scale-1  \n",
      "14              0.898329          0.898253      0.965835      SVM-rbf-scale-1  \n",
      "15              0.634656          0.634694      0.749618  SVM-sigmoid-scale-1  \n",
      "16              0.660404          0.660404      0.769587  SVM-sigmoid-scale-1  \n",
      "17              0.668754          0.668754      0.766135  SVM-sigmoid-scale-1  \n",
      "18              0.672234          0.672234      0.779114  SVM-sigmoid-scale-1  \n",
      "19              0.679666          0.679678      0.788847  SVM-sigmoid-scale-1  \n",
      "20              0.996521          0.996520      0.999382    SVM-linear-auto-1  \n",
      "21              0.997912          0.997912      0.999399    SVM-linear-auto-1  \n",
      "22              0.997912          0.997912      0.999663    SVM-linear-auto-1  \n",
      "23              0.998608          0.998608      0.999965    SVM-linear-auto-1  \n",
      "24              0.997911          0.997911      0.999984    SVM-linear-auto-1  \n",
      "25              0.951983          0.951988      0.986791      SVM-poly-auto-1  \n",
      "26              0.955463          0.955465      0.988034      SVM-poly-auto-1  \n",
      "27              0.951287          0.951287      0.984311      SVM-poly-auto-1  \n",
      "28              0.950592          0.950592      0.984365      SVM-poly-auto-1  \n",
      "29              0.956825          0.956832      0.988102      SVM-poly-auto-1  \n",
      "30              0.675017          0.640113      0.711763       SVM-rbf-auto-1  \n",
      "31              0.700070          0.665893      0.713997       SVM-rbf-auto-1  \n",
      "32              0.678497          0.643093      0.706106       SVM-rbf-auto-1  \n",
      "33              0.693807          0.662735      0.725510       SVM-rbf-auto-1  \n",
      "34              0.708914          0.678829      0.729960       SVM-rbf-auto-1  \n",
      "35              0.487822          0.319891      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.481559          0.313047      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.494085          0.326782      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.497564          0.330631      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.486072          0.317974      0.500000   SVM-sigmoid-auto-1  \n",
      "40              0.996521          0.996520      0.999382   SVM-linear-scale-2  \n",
      "41              0.997912          0.997912      0.999399   SVM-linear-scale-2  \n",
      "42              0.997912          0.997912      0.999663   SVM-linear-scale-2  \n",
      "43              0.998608          0.998608      0.999965   SVM-linear-scale-2  \n",
      "44              0.997911          0.997911      0.999984   SVM-linear-scale-2  \n",
      "45              0.908838          0.908841      0.971774     SVM-poly-scale-2  \n",
      "46              0.915797          0.915762      0.973422     SVM-poly-scale-2  \n",
      "47              0.917189          0.917181      0.970025     SVM-poly-scale-2  \n",
      "48              0.917884          0.917832      0.967294     SVM-poly-scale-2  \n",
      "49              0.912256          0.912191      0.969875     SVM-poly-scale-2  \n",
      "50              0.903967          0.903981      0.969428      SVM-rbf-scale-2  \n",
      "51              0.910230          0.910178      0.970309      SVM-rbf-scale-2  \n",
      "52              0.915101          0.915073      0.967447      SVM-rbf-scale-2  \n",
      "53              0.910230          0.910187      0.966984      SVM-rbf-scale-2  \n",
      "54              0.911560          0.911518      0.971318      SVM-rbf-scale-2  \n",
      "55              0.634656          0.634677      0.746199  SVM-sigmoid-scale-2  \n",
      "56              0.654836          0.654836      0.766511  SVM-sigmoid-scale-2  \n",
      "57              0.663187          0.663165      0.763198  SVM-sigmoid-scale-2  \n",
      "58              0.667363          0.667353      0.776892  SVM-sigmoid-scale-2  \n",
      "59              0.674095          0.674107      0.785642  SVM-sigmoid-scale-2  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-linear-auto-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      1.00      1.00      1206\n",
      "      benign       1.00      1.00      1.00      1189\n",
      "\n",
      "    accuracy                           1.00      2395\n",
      "   macro avg       1.00      1.00      1.00      2395\n",
      "weighted avg       1.00      1.00      1.00      2395\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   13.070609    0.024099       0.996521                 0.996521   \n",
      "1    9.711740    0.019658       0.997912                 0.997921   \n",
      "2   14.511508    0.020273       0.997912                 0.997913   \n",
      "3   14.517469    0.020155       0.998608                 0.998608   \n",
      "4   14.464727    0.020044       0.997911                 0.997912   \n",
      "..        ...         ...            ...                      ...   \n",
      "60  12.910233    0.020019       0.996521                 0.996521   \n",
      "61   9.583290    0.019589       0.997912                 0.997921   \n",
      "62  14.362929    0.020131       0.997912                 0.997913   \n",
      "63  14.375376    0.019973       0.998608                 0.998608   \n",
      "64  14.305426    0.020181       0.997911                 0.997912   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               0.996521          0.996520      0.999382  SVM-linear-scale-1  \n",
      "1               0.997912          0.997912      0.999399  SVM-linear-scale-1  \n",
      "2               0.997912          0.997912      0.999663  SVM-linear-scale-1  \n",
      "3               0.998608          0.998608      0.999965  SVM-linear-scale-1  \n",
      "4               0.997911          0.997911      0.999984  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "60              0.996521          0.996520      0.999382   SVM-linear-auto-2  \n",
      "61              0.997912          0.997912      0.999399   SVM-linear-auto-2  \n",
      "62              0.997912          0.997912      0.999663   SVM-linear-auto-2  \n",
      "63              0.998608          0.998608      0.999965   SVM-linear-auto-2  \n",
      "64              0.997911          0.997911      0.999984   SVM-linear-auto-2  \n",
      "\n",
      "[65 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-poly-auto-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.96      0.96      0.96      1206\n",
      "      benign       0.96      0.96      0.96      1189\n",
      "\n",
      "    accuracy                           0.96      2395\n",
      "   macro avg       0.96      0.96      0.96      2395\n",
      "weighted avg       0.96      0.96      0.96      2395\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   13.070609    0.024099       0.996521                 0.996521   \n",
      "1    9.711740    0.019658       0.997912                 0.997921   \n",
      "2   14.511508    0.020273       0.997912                 0.997913   \n",
      "3   14.517469    0.020155       0.998608                 0.998608   \n",
      "4   14.464727    0.020044       0.997911                 0.997912   \n",
      "..        ...         ...            ...                      ...   \n",
      "65   1.077188    0.104982       0.951983                 0.952038   \n",
      "66   1.030411    0.101712       0.955463                 0.955471   \n",
      "67   1.026784    0.099129       0.951287                 0.951289   \n",
      "68   1.018904    0.103191       0.950592                 0.950615   \n",
      "69   1.017946    0.100343       0.956825                 0.957022   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               0.996521          0.996520      0.999382  SVM-linear-scale-1  \n",
      "1               0.997912          0.997912      0.999399  SVM-linear-scale-1  \n",
      "2               0.997912          0.997912      0.999663  SVM-linear-scale-1  \n",
      "3               0.998608          0.998608      0.999965  SVM-linear-scale-1  \n",
      "4               0.997911          0.997911      0.999984  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "65              0.951983          0.951988      0.986791     SVM-poly-auto-2  \n",
      "66              0.955463          0.955465      0.988034     SVM-poly-auto-2  \n",
      "67              0.951287          0.951287      0.984311     SVM-poly-auto-2  \n",
      "68              0.950592          0.950592      0.984365     SVM-poly-auto-2  \n",
      "69              0.956825          0.956832      0.988102     SVM-poly-auto-2  \n",
      "\n",
      "[70 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-rbf-auto-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      0.41      0.58      1206\n",
      "      benign       0.62      1.00      0.77      1189\n",
      "\n",
      "    accuracy                           0.70      2395\n",
      "   macro avg       0.81      0.70      0.67      2395\n",
      "weighted avg       0.81      0.70      0.67      2395\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   13.070609    0.024099       0.996521                 0.996521   \n",
      "1    9.711740    0.019658       0.997912                 0.997921   \n",
      "2   14.511508    0.020273       0.997912                 0.997913   \n",
      "3   14.517469    0.020155       0.998608                 0.998608   \n",
      "4   14.464727    0.020044       0.997911                 0.997912   \n",
      "..        ...         ...            ...                      ...   \n",
      "70   2.164969    1.806813       0.675017                 0.804955   \n",
      "71   2.185591    1.856487       0.700070                 0.809993   \n",
      "72   2.149197    1.852050       0.678497                 0.805233   \n",
      "73   2.141423    1.884171       0.693807                 0.810452   \n",
      "74   2.196172    1.870628       0.708914                 0.814168   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               0.996521          0.996520      0.999382  SVM-linear-scale-1  \n",
      "1               0.997912          0.997912      0.999399  SVM-linear-scale-1  \n",
      "2               0.997912          0.997912      0.999663  SVM-linear-scale-1  \n",
      "3               0.998608          0.998608      0.999965  SVM-linear-scale-1  \n",
      "4               0.997911          0.997911      0.999984  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "70              0.675017          0.640113      0.711763      SVM-rbf-auto-2  \n",
      "71              0.700070          0.665893      0.713997      SVM-rbf-auto-2  \n",
      "72              0.678497          0.643093      0.706106      SVM-rbf-auto-2  \n",
      "73              0.693807          0.662735      0.725510      SVM-rbf-auto-2  \n",
      "74              0.708914          0.678829      0.729960      SVM-rbf-auto-2  \n",
      "\n",
      "[75 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-sigmoid-auto-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.00      0.00      0.00      1206\n",
      "      benign       0.50      1.00      0.66      1189\n",
      "\n",
      "    accuracy                           0.50      2395\n",
      "   macro avg       0.25      0.50      0.33      2395\n",
      "weighted avg       0.25      0.50      0.33      2395\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   13.070609    0.024099       0.996521                 0.996521   \n",
      "1    9.711740    0.019658       0.997912                 0.997921   \n",
      "2   14.511508    0.020273       0.997912                 0.997913   \n",
      "3   14.517469    0.020155       0.998608                 0.998608   \n",
      "4   14.464727    0.020044       0.997911                 0.997912   \n",
      "..        ...         ...            ...                      ...   \n",
      "75   1.446589    0.754837       0.487822                 0.237970   \n",
      "76   1.475444    0.771958       0.481559                 0.231899   \n",
      "77   1.477066    0.756155       0.494085                 0.244120   \n",
      "78   1.473755    0.754411       0.497564                 0.247570   \n",
      "79   1.491530    0.777684       0.486072                 0.236266   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               0.996521          0.996520      0.999382  SVM-linear-scale-1  \n",
      "1               0.997912          0.997912      0.999399  SVM-linear-scale-1  \n",
      "2               0.997912          0.997912      0.999663  SVM-linear-scale-1  \n",
      "3               0.998608          0.998608      0.999965  SVM-linear-scale-1  \n",
      "4               0.997911          0.997911      0.999984  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "75              0.487822          0.319891      0.500000  SVM-sigmoid-auto-2  \n",
      "76              0.481559          0.313047      0.500000  SVM-sigmoid-auto-2  \n",
      "77              0.494085          0.326782      0.500000  SVM-sigmoid-auto-2  \n",
      "78              0.497564          0.330631      0.500000  SVM-sigmoid-auto-2  \n",
      "79              0.486072          0.317974      0.500000  SVM-sigmoid-auto-2  \n",
      "\n",
      "[80 rows x 8 columns]\n",
      "520.9106043949723\n"
     ]
    }
   ],
   "source": [
    "## S7: IoT compromised (IoT + IoT)\n",
    " \n",
    "df_malicious = pd.concat([df1,df34])\n",
    " \n",
    "df_benign = pd.concat([df8,df9,df10,df11,df12,df21])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_all_combined_s0 = run_process(df_malicious,df_benign,df_results)\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nectar-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
